{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW, Optimizer, SGD\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from scratchers.transformer_config import TransformerConfig\n",
    "from scratchers.rotary_transformer.transformer import TransformerDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'scratchers' (namespace) from ['/Users/s-a-bakulin/mosquitto/ml/scratchers']>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scratchers\n",
    "importlib.reload(scratchers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_SEQ_LEN = 12\n",
    "TARGET_SEQ_LEN = 12\n",
    "\n",
    "DATA_SIZE = 1500\n",
    "TRAIN_SIZE = int(DATA_SIZE * 0.8)\n",
    "TEST_SIZE = DATA_SIZE - TRAIN_SIZE\n",
    "\n",
    "# radii = np.random.ranf((DATA_SIZE)) # * 9 + 1\n",
    "radii = np.ones((DATA_SIZE))\n",
    "starting_radian = np.random.ranf((DATA_SIZE)) * 2 * np.pi\n",
    "directions = np.random.randint(2, size=DATA_SIZE) * 2 - 1\n",
    "\n",
    "def to_cartesian(\n",
    "    radius: float,\n",
    "    start_radian: float, \n",
    "    direction: int\n",
    "):\n",
    "    delta = 2 * np.pi / (SOURCE_SEQ_LEN + TARGET_SEQ_LEN)\n",
    "    seq = np.array([\n",
    "        np.array([\n",
    "            radius * np.cos(start_radian + (i * direction * delta)),\n",
    "            radius * np.sin(start_radian + (i * direction * delta))\n",
    "        ])\n",
    "        for i in range(SOURCE_SEQ_LEN + TARGET_SEQ_LEN)\n",
    "    ])\n",
    "    source_seq = seq[:-1]\n",
    "    target_seq = seq[1:]\n",
    "    return source_seq, target_seq\n",
    "\n",
    "def make_circles_data():\n",
    "    X = np.empty((DATA_SIZE, (SOURCE_SEQ_LEN + TARGET_SEQ_LEN) - 1, 2))\n",
    "    Y = np.empty((DATA_SIZE, (SOURCE_SEQ_LEN + TARGET_SEQ_LEN) - 1, 2))\n",
    "    for idx, (radius, start_radian, direction) in enumerate(zip(radii, starting_radian, directions)):\n",
    "        x, y = to_cartesian(radius, start_radian, direction)\n",
    "        X[idx, :, :] = x\n",
    "        Y[idx, :, :] = y\n",
    "\n",
    "    return (\n",
    "        torch.from_numpy(X[:TRAIN_SIZE]).float(), \n",
    "        torch.from_numpy(Y[:TRAIN_SIZE]).float(),\n",
    "        torch.from_numpy(X[TRAIN_SIZE:]).float(), \n",
    "        torch.from_numpy(Y[TRAIN_SIZE:]).float()\n",
    "    )\n",
    "\n",
    "def make_squares_data():\n",
    "    X = np.empty((DATA_SIZE, (2 + 2) - 1, 2))\n",
    "    Y = np.empty((DATA_SIZE, (2 + 2) - 1, 2))\n",
    "\n",
    "    def map(elements):\n",
    "        res = []\n",
    "        for element in elements:\n",
    "            if element == 0:\n",
    "                res.append(np.array([-1, -1]))\n",
    "            elif element == 1:\n",
    "                res.append(np.array([1, -1]))\n",
    "            elif element == 2:\n",
    "                res.append(np.array([1, 1]))\n",
    "            elif element == 3:\n",
    "                res.append(np.array([-1, 1]))\n",
    "\n",
    "        return np.array(res)\n",
    "\n",
    "    first = np.random.randint(0, 4, size=(DATA_SIZE))\n",
    "    second = (first + 1) % 4\n",
    "    third = (second + 1) % 4\n",
    "    fourth = (third + 1) % 4\n",
    "    first = map(first)\n",
    "    second = map(second)\n",
    "    third = map(third)\n",
    "    fourth = map(fourth)\n",
    "\n",
    "    X[:, 0, :] = first\n",
    "    X[:, 1, :] = second\n",
    "    X[:, 2, :] = third\n",
    "    Y[:, 0, :] = second\n",
    "    Y[:, 1, :] = third\n",
    "    Y[:, 2, :] = fourth\n",
    "\n",
    "    return (\n",
    "        torch.from_numpy(X[:TRAIN_SIZE]).float(), \n",
    "        torch.from_numpy(Y[:TRAIN_SIZE]).float(),\n",
    "        torch.from_numpy(X[TRAIN_SIZE:]).float(), \n",
    "        torch.from_numpy(Y[TRAIN_SIZE:]).float()\n",
    "    )\n",
    "\n",
    "\n",
    "X_train, y_train, X_test, y_test = make_circles_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_circle(input, prediction, figsize=(6, 6)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(input)))\n",
    "    plt.scatter(\n",
    "        input[:, 0], input[:, 1], label=\"input\", marker=\"*\", s=250, alpha=0.5, color=colors\n",
    "    )\n",
    "    plt.scatter(prediction[:, 0], prediction[:, 1], label=\"prediction\", color=colors)\n",
    "    plt.legend()\n",
    "\n",
    "plot_circle(X_train[4], y_train[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = TransformerConfig(\n",
    "    input_size=2,\n",
    "    attn_d_k=64,\n",
    "    transformer_proj_dim=128,\n",
    "    dropout=0.2,\n",
    "    nlayers=3,\n",
    "    is_self_attn=False,\n",
    "    max_seq_len=TARGET_SEQ_LEN + SOURCE_SEQ_LEN,\n",
    "    nheads=2,\n",
    "    pre_layer_norm=True,\n",
    "    use_cache=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_data_loader: DataLoader,\n",
    "        test_data_loader: DataLoader,\n",
    "        optimizer: Optimizer,\n",
    "        model: nn.Module,\n",
    "        lr_scheduler = None,\n",
    "        epochs: int = 10,\n",
    "    ):\n",
    "        self.train_data_loader = train_data_loader\n",
    "        self.test_data_loader = test_data_loader\n",
    "        self.optimizer = optimizer\n",
    "        self.model = model\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def train(self, loss_fn: callable):\n",
    "        for epoch in range(self.epochs):\n",
    "            losses = []\n",
    "            self.model.train()\n",
    "            for x_batch, y_batch in self.train_data_loader:\n",
    "                out = self.model(x_batch)\n",
    "                loss = loss_fn(out, y_batch)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                losses.append(loss.detach().cpu().numpy())\n",
    "\n",
    "            if self.lr_scheduler is not None:\n",
    "                self.lr_scheduler.step()\n",
    "\n",
    "            print(f\"Train loss at epoch ({epoch}): \", np.array(losses).mean())\n",
    "\n",
    "            with torch.no_grad():\n",
    "                self.model.eval()\n",
    "                test_losses = []\n",
    "                for x_batch, y_batch in self.test_data_loader:\n",
    "                    out = self.model(x_batch)\n",
    "                    loss = loss_fn(out, y_batch)\n",
    "                    test_losses.append(loss.detach().cpu().numpy())\n",
    "\n",
    "                print(f\"Test loss at epoch ({epoch}): \", np.array(test_losses).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at epoch (0):  0.70765007\n",
      "Test loss at epoch (0):  0.52027094\n",
      "Train loss at epoch (1):  0.41045132\n",
      "Test loss at epoch (1):  0.25285766\n",
      "Train loss at epoch (2):  0.2535321\n",
      "Test loss at epoch (2):  0.16204353\n",
      "Train loss at epoch (3):  0.22055535\n",
      "Test loss at epoch (3):  0.14643192\n",
      "Train loss at epoch (4):  0.20892243\n",
      "Test loss at epoch (4):  0.13949476\n",
      "Train loss at epoch (5):  0.20202987\n",
      "Test loss at epoch (5):  0.13496643\n",
      "Train loss at epoch (6):  0.19772148\n",
      "Test loss at epoch (6):  0.13150518\n",
      "Train loss at epoch (7):  0.19183187\n",
      "Test loss at epoch (7):  0.12873119\n",
      "Train loss at epoch (8):  0.18803783\n",
      "Test loss at epoch (8):  0.12615804\n",
      "Train loss at epoch (9):  0.18432906\n",
      "Test loss at epoch (9):  0.12373648\n",
      "Train loss at epoch (10):  0.18032967\n",
      "Test loss at epoch (10):  0.1211935\n",
      "Train loss at epoch (11):  0.17784703\n",
      "Test loss at epoch (11):  0.11933499\n",
      "Train loss at epoch (12):  0.17381778\n",
      "Test loss at epoch (12):  0.11702117\n",
      "Train loss at epoch (13):  0.1711585\n",
      "Test loss at epoch (13):  0.11555582\n",
      "Train loss at epoch (14):  0.1676024\n",
      "Test loss at epoch (14):  0.11373658\n",
      "Train loss at epoch (15):  0.16499835\n",
      "Test loss at epoch (15):  0.11193041\n",
      "Train loss at epoch (16):  0.16322073\n",
      "Test loss at epoch (16):  0.11035879\n",
      "Train loss at epoch (17):  0.16082369\n",
      "Test loss at epoch (17):  0.10906539\n",
      "Train loss at epoch (18):  0.15897863\n",
      "Test loss at epoch (18):  0.1073993\n",
      "Train loss at epoch (19):  0.15625606\n",
      "Test loss at epoch (19):  0.10651735\n",
      "Train loss at epoch (20):  0.15460609\n",
      "Test loss at epoch (20):  0.1051731\n",
      "Train loss at epoch (21):  0.15268008\n",
      "Test loss at epoch (21):  0.1041393\n",
      "Train loss at epoch (22):  0.15057616\n",
      "Test loss at epoch (22):  0.1033703\n",
      "Train loss at epoch (23):  0.14860484\n",
      "Test loss at epoch (23):  0.10210033\n",
      "Train loss at epoch (24):  0.14804453\n",
      "Test loss at epoch (24):  0.10124887\n",
      "Train loss at epoch (25):  0.14516954\n",
      "Test loss at epoch (25):  0.10061826\n",
      "Train loss at epoch (26):  0.14403686\n",
      "Test loss at epoch (26):  0.09980707\n",
      "Train loss at epoch (27):  0.14301538\n",
      "Test loss at epoch (27):  0.09891384\n",
      "Train loss at epoch (28):  0.14161147\n",
      "Test loss at epoch (28):  0.09792976\n",
      "Train loss at epoch (29):  0.13998264\n",
      "Test loss at epoch (29):  0.09718539\n",
      "Train loss at epoch (30):  0.13911723\n",
      "Test loss at epoch (30):  0.09664454\n",
      "Train loss at epoch (31):  0.13836783\n",
      "Test loss at epoch (31):  0.09594605\n",
      "Train loss at epoch (32):  0.13767785\n",
      "Test loss at epoch (32):  0.0952232\n",
      "Train loss at epoch (33):  0.13591875\n",
      "Test loss at epoch (33):  0.09477669\n",
      "Train loss at epoch (34):  0.13569488\n",
      "Test loss at epoch (34):  0.09407003\n",
      "Train loss at epoch (35):  0.13394204\n",
      "Test loss at epoch (35):  0.09361792\n",
      "Train loss at epoch (36):  0.13340053\n",
      "Test loss at epoch (36):  0.09322415\n",
      "Train loss at epoch (37):  0.13216098\n",
      "Test loss at epoch (37):  0.09262597\n",
      "Train loss at epoch (38):  0.13076335\n",
      "Test loss at epoch (38):  0.092391826\n",
      "Train loss at epoch (39):  0.13107523\n",
      "Test loss at epoch (39):  0.091543496\n",
      "Train loss at epoch (40):  0.1298891\n",
      "Test loss at epoch (40):  0.09115528\n",
      "Train loss at epoch (41):  0.12824896\n",
      "Test loss at epoch (41):  0.090705216\n",
      "Train loss at epoch (42):  0.12836173\n",
      "Test loss at epoch (42):  0.09013465\n",
      "Train loss at epoch (43):  0.12755483\n",
      "Test loss at epoch (43):  0.08945621\n",
      "Train loss at epoch (44):  0.12655485\n",
      "Test loss at epoch (44):  0.08921279\n",
      "Train loss at epoch (45):  0.12563519\n",
      "Test loss at epoch (45):  0.08878261\n",
      "Train loss at epoch (46):  0.12563477\n",
      "Test loss at epoch (46):  0.0883331\n",
      "Train loss at epoch (47):  0.12447913\n",
      "Test loss at epoch (47):  0.0882893\n",
      "Train loss at epoch (48):  0.12421052\n",
      "Test loss at epoch (48):  0.088029005\n",
      "Train loss at epoch (49):  0.12330725\n",
      "Test loss at epoch (49):  0.087526955\n",
      "Train loss at epoch (50):  0.12236324\n",
      "Test loss at epoch (50):  0.087476194\n",
      "Train loss at epoch (51):  0.12177948\n",
      "Test loss at epoch (51):  0.08674014\n",
      "Train loss at epoch (52):  0.1212277\n",
      "Test loss at epoch (52):  0.08642763\n",
      "Train loss at epoch (53):  0.12101794\n",
      "Test loss at epoch (53):  0.08604067\n",
      "Train loss at epoch (54):  0.120418005\n",
      "Test loss at epoch (54):  0.085692815\n",
      "Train loss at epoch (55):  0.119982146\n",
      "Test loss at epoch (55):  0.08531376\n",
      "Train loss at epoch (56):  0.119571544\n",
      "Test loss at epoch (56):  0.08519919\n",
      "Train loss at epoch (57):  0.11884693\n",
      "Test loss at epoch (57):  0.08458923\n",
      "Train loss at epoch (58):  0.11821949\n",
      "Test loss at epoch (58):  0.08420471\n",
      "Train loss at epoch (59):  0.11763541\n",
      "Test loss at epoch (59):  0.08416208\n",
      "Train loss at epoch (60):  0.1178744\n",
      "Test loss at epoch (60):  0.083704084\n",
      "Train loss at epoch (61):  0.11735696\n",
      "Test loss at epoch (61):  0.08332622\n",
      "Train loss at epoch (62):  0.11651502\n",
      "Test loss at epoch (62):  0.082987025\n",
      "Train loss at epoch (63):  0.11551184\n",
      "Test loss at epoch (63):  0.082648225\n",
      "Train loss at epoch (64):  0.11549966\n",
      "Test loss at epoch (64):  0.082357176\n",
      "Train loss at epoch (65):  0.11461403\n",
      "Test loss at epoch (65):  0.08209886\n",
      "Train loss at epoch (66):  0.11433502\n",
      "Test loss at epoch (66):  0.082018316\n",
      "Train loss at epoch (67):  0.114658155\n",
      "Test loss at epoch (67):  0.08180428\n",
      "Train loss at epoch (68):  0.11383793\n",
      "Test loss at epoch (68):  0.08138202\n",
      "Train loss at epoch (69):  0.11380962\n",
      "Test loss at epoch (69):  0.08107171\n",
      "Train loss at epoch (70):  0.11329887\n",
      "Test loss at epoch (70):  0.0806823\n",
      "Train loss at epoch (71):  0.113498\n",
      "Test loss at epoch (71):  0.08052132\n",
      "Train loss at epoch (72):  0.11262996\n",
      "Test loss at epoch (72):  0.08009685\n",
      "Train loss at epoch (73):  0.11218381\n",
      "Test loss at epoch (73):  0.07998278\n",
      "Train loss at epoch (74):  0.1121536\n",
      "Test loss at epoch (74):  0.079847254\n",
      "Train loss at epoch (75):  0.11099254\n",
      "Test loss at epoch (75):  0.07948019\n",
      "Train loss at epoch (76):  0.111151695\n",
      "Test loss at epoch (76):  0.079164565\n",
      "Train loss at epoch (77):  0.11098552\n",
      "Test loss at epoch (77):  0.07892102\n",
      "Train loss at epoch (78):  0.1101821\n",
      "Test loss at epoch (78):  0.07857147\n",
      "Train loss at epoch (79):  0.110044174\n",
      "Test loss at epoch (79):  0.07829978\n",
      "Train loss at epoch (80):  0.10976282\n",
      "Test loss at epoch (80):  0.0779441\n",
      "Train loss at epoch (81):  0.10924836\n",
      "Test loss at epoch (81):  0.077658154\n",
      "Train loss at epoch (82):  0.10975622\n",
      "Test loss at epoch (82):  0.07771516\n",
      "Train loss at epoch (83):  0.108922295\n",
      "Test loss at epoch (83):  0.077239916\n",
      "Train loss at epoch (84):  0.10877041\n",
      "Test loss at epoch (84):  0.07719109\n",
      "Train loss at epoch (85):  0.10843736\n",
      "Test loss at epoch (85):  0.077099845\n",
      "Train loss at epoch (86):  0.10783361\n",
      "Test loss at epoch (86):  0.07623714\n",
      "Train loss at epoch (87):  0.10718131\n",
      "Test loss at epoch (87):  0.076161675\n",
      "Train loss at epoch (88):  0.10735285\n",
      "Test loss at epoch (88):  0.07603247\n",
      "Train loss at epoch (89):  0.107081465\n",
      "Test loss at epoch (89):  0.07556348\n",
      "Train loss at epoch (90):  0.10716127\n",
      "Test loss at epoch (90):  0.075737655\n",
      "Train loss at epoch (91):  0.10663964\n",
      "Test loss at epoch (91):  0.075239725\n",
      "Train loss at epoch (92):  0.106076814\n",
      "Test loss at epoch (92):  0.074855946\n",
      "Train loss at epoch (93):  0.10572917\n",
      "Test loss at epoch (93):  0.07471539\n",
      "Train loss at epoch (94):  0.10569563\n",
      "Test loss at epoch (94):  0.074596345\n",
      "Train loss at epoch (95):  0.10544275\n",
      "Test loss at epoch (95):  0.07426216\n",
      "Train loss at epoch (96):  0.10500514\n",
      "Test loss at epoch (96):  0.07387338\n",
      "Train loss at epoch (97):  0.10540148\n",
      "Test loss at epoch (97):  0.07368892\n",
      "Train loss at epoch (98):  0.10435703\n",
      "Test loss at epoch (98):  0.07339659\n",
      "Train loss at epoch (99):  0.104785606\n",
      "Test loss at epoch (99):  0.0729811\n",
      "Train loss at epoch (100):  0.10390965\n",
      "Test loss at epoch (100):  0.07293586\n",
      "Train loss at epoch (101):  0.10406159\n",
      "Test loss at epoch (101):  0.07262316\n",
      "Train loss at epoch (102):  0.103678524\n",
      "Test loss at epoch (102):  0.07231374\n",
      "Train loss at epoch (103):  0.103385605\n",
      "Test loss at epoch (103):  0.07239539\n",
      "Train loss at epoch (104):  0.1031878\n",
      "Test loss at epoch (104):  0.072082594\n",
      "Train loss at epoch (105):  0.10345607\n",
      "Test loss at epoch (105):  0.07193296\n",
      "Train loss at epoch (106):  0.10253466\n",
      "Test loss at epoch (106):  0.07140484\n",
      "Train loss at epoch (107):  0.1028819\n",
      "Test loss at epoch (107):  0.07104808\n",
      "Train loss at epoch (108):  0.10174955\n",
      "Test loss at epoch (108):  0.070988715\n",
      "Train loss at epoch (109):  0.10185684\n",
      "Test loss at epoch (109):  0.0708711\n",
      "Train loss at epoch (110):  0.101676606\n",
      "Test loss at epoch (110):  0.0705436\n",
      "Train loss at epoch (111):  0.101301126\n",
      "Test loss at epoch (111):  0.070602104\n",
      "Train loss at epoch (112):  0.10128134\n",
      "Test loss at epoch (112):  0.070134066\n",
      "Train loss at epoch (113):  0.100956485\n",
      "Test loss at epoch (113):  0.06987575\n",
      "Train loss at epoch (114):  0.100432426\n",
      "Test loss at epoch (114):  0.06959857\n",
      "Train loss at epoch (115):  0.09990524\n",
      "Test loss at epoch (115):  0.06930933\n",
      "Train loss at epoch (116):  0.10047641\n",
      "Test loss at epoch (116):  0.06883949\n",
      "Train loss at epoch (117):  0.10022787\n",
      "Test loss at epoch (117):  0.06887213\n",
      "Train loss at epoch (118):  0.09974768\n",
      "Test loss at epoch (118):  0.068931915\n",
      "Train loss at epoch (119):  0.09951098\n",
      "Test loss at epoch (119):  0.06832262\n",
      "Train loss at epoch (120):  0.09944031\n",
      "Test loss at epoch (120):  0.06808329\n",
      "Train loss at epoch (121):  0.09885578\n",
      "Test loss at epoch (121):  0.067778274\n",
      "Train loss at epoch (122):  0.09870744\n",
      "Test loss at epoch (122):  0.067846544\n",
      "Train loss at epoch (123):  0.09866052\n",
      "Test loss at epoch (123):  0.06799202\n",
      "Train loss at epoch (124):  0.09894127\n",
      "Test loss at epoch (124):  0.06726918\n",
      "Train loss at epoch (125):  0.09815522\n",
      "Test loss at epoch (125):  0.06721733\n",
      "Train loss at epoch (126):  0.09812999\n",
      "Test loss at epoch (126):  0.06677371\n",
      "Train loss at epoch (127):  0.09791089\n",
      "Test loss at epoch (127):  0.066661604\n",
      "Train loss at epoch (128):  0.097824134\n",
      "Test loss at epoch (128):  0.06674797\n",
      "Train loss at epoch (129):  0.097538814\n",
      "Test loss at epoch (129):  0.06621496\n",
      "Train loss at epoch (130):  0.097005635\n",
      "Test loss at epoch (130):  0.06610193\n",
      "Train loss at epoch (131):  0.09727064\n",
      "Test loss at epoch (131):  0.065777004\n",
      "Train loss at epoch (132):  0.096911326\n",
      "Test loss at epoch (132):  0.06562518\n",
      "Train loss at epoch (133):  0.09655645\n",
      "Test loss at epoch (133):  0.06593456\n",
      "Train loss at epoch (134):  0.09646962\n",
      "Test loss at epoch (134):  0.06509561\n",
      "Train loss at epoch (135):  0.096170746\n",
      "Test loss at epoch (135):  0.06544999\n",
      "Train loss at epoch (136):  0.09608917\n",
      "Test loss at epoch (136):  0.06471069\n",
      "Train loss at epoch (137):  0.09583984\n",
      "Test loss at epoch (137):  0.06498507\n",
      "Train loss at epoch (138):  0.09547556\n",
      "Test loss at epoch (138):  0.06433464\n",
      "Train loss at epoch (139):  0.09552229\n",
      "Test loss at epoch (139):  0.06415234\n",
      "Train loss at epoch (140):  0.09532236\n",
      "Test loss at epoch (140):  0.06373504\n",
      "Train loss at epoch (141):  0.09516726\n",
      "Test loss at epoch (141):  0.06364864\n",
      "Train loss at epoch (142):  0.09490695\n",
      "Test loss at epoch (142):  0.06335086\n",
      "Train loss at epoch (143):  0.09496843\n",
      "Test loss at epoch (143):  0.06363061\n",
      "Train loss at epoch (144):  0.094351746\n",
      "Test loss at epoch (144):  0.06284208\n",
      "Train loss at epoch (145):  0.09477999\n",
      "Test loss at epoch (145):  0.062953465\n",
      "Train loss at epoch (146):  0.09436991\n",
      "Test loss at epoch (146):  0.06250141\n",
      "Train loss at epoch (147):  0.09422791\n",
      "Test loss at epoch (147):  0.06252148\n",
      "Train loss at epoch (148):  0.093599044\n",
      "Test loss at epoch (148):  0.062631845\n",
      "Train loss at epoch (149):  0.09383336\n",
      "Test loss at epoch (149):  0.06238763\n",
      "Train loss at epoch (150):  0.09390069\n",
      "Test loss at epoch (150):  0.061921548\n",
      "Train loss at epoch (151):  0.09311768\n",
      "Test loss at epoch (151):  0.061657127\n",
      "Train loss at epoch (152):  0.0932988\n",
      "Test loss at epoch (152):  0.061616898\n",
      "Train loss at epoch (153):  0.09335802\n",
      "Test loss at epoch (153):  0.06134933\n",
      "Train loss at epoch (154):  0.09292083\n",
      "Test loss at epoch (154):  0.061406393\n",
      "Train loss at epoch (155):  0.093213715\n",
      "Test loss at epoch (155):  0.060954\n",
      "Train loss at epoch (156):  0.09242395\n",
      "Test loss at epoch (156):  0.06084067\n",
      "Train loss at epoch (157):  0.09265684\n",
      "Test loss at epoch (157):  0.060677398\n",
      "Train loss at epoch (158):  0.09203065\n",
      "Test loss at epoch (158):  0.060382057\n",
      "Train loss at epoch (159):  0.09227533\n",
      "Test loss at epoch (159):  0.06011212\n",
      "Train loss at epoch (160):  0.09189221\n",
      "Test loss at epoch (160):  0.06016337\n",
      "Train loss at epoch (161):  0.0915016\n",
      "Test loss at epoch (161):  0.060005967\n",
      "Train loss at epoch (162):  0.091547765\n",
      "Test loss at epoch (162):  0.059778426\n",
      "Train loss at epoch (163):  0.0913993\n",
      "Test loss at epoch (163):  0.059681322\n",
      "Train loss at epoch (164):  0.091321126\n",
      "Test loss at epoch (164):  0.05966933\n",
      "Train loss at epoch (165):  0.09141288\n",
      "Test loss at epoch (165):  0.059495457\n",
      "Train loss at epoch (166):  0.091167666\n",
      "Test loss at epoch (166):  0.059254616\n",
      "Train loss at epoch (167):  0.09087698\n",
      "Test loss at epoch (167):  0.058862373\n",
      "Train loss at epoch (168):  0.09054333\n",
      "Test loss at epoch (168):  0.058794223\n",
      "Train loss at epoch (169):  0.09081433\n",
      "Test loss at epoch (169):  0.058651466\n",
      "Train loss at epoch (170):  0.09067772\n",
      "Test loss at epoch (170):  0.058397274\n",
      "Train loss at epoch (171):  0.09047974\n",
      "Test loss at epoch (171):  0.058333892\n",
      "Train loss at epoch (172):  0.08995807\n",
      "Test loss at epoch (172):  0.057944242\n",
      "Train loss at epoch (173):  0.08978974\n",
      "Test loss at epoch (173):  0.057921063\n",
      "Train loss at epoch (174):  0.08938344\n",
      "Test loss at epoch (174):  0.057699636\n",
      "Train loss at epoch (175):  0.08961201\n",
      "Test loss at epoch (175):  0.057565287\n",
      "Train loss at epoch (176):  0.08973751\n",
      "Test loss at epoch (176):  0.057254974\n",
      "Train loss at epoch (177):  0.08957681\n",
      "Test loss at epoch (177):  0.057179093\n",
      "Train loss at epoch (178):  0.08959403\n",
      "Test loss at epoch (178):  0.05710873\n",
      "Train loss at epoch (179):  0.08914257\n",
      "Test loss at epoch (179):  0.05675848\n",
      "Train loss at epoch (180):  0.08924437\n",
      "Test loss at epoch (180):  0.056836467\n",
      "Train loss at epoch (181):  0.0888614\n",
      "Test loss at epoch (181):  0.056381434\n",
      "Train loss at epoch (182):  0.088895515\n",
      "Test loss at epoch (182):  0.056329075\n",
      "Train loss at epoch (183):  0.08841364\n",
      "Test loss at epoch (183):  0.056187555\n",
      "Train loss at epoch (184):  0.08862692\n",
      "Test loss at epoch (184):  0.056067567\n",
      "Train loss at epoch (185):  0.088156834\n",
      "Test loss at epoch (185):  0.05568861\n",
      "Train loss at epoch (186):  0.08808429\n",
      "Test loss at epoch (186):  0.05634062\n",
      "Train loss at epoch (187):  0.08777145\n",
      "Test loss at epoch (187):  0.05542359\n",
      "Train loss at epoch (188):  0.087415196\n",
      "Test loss at epoch (188):  0.055395\n",
      "Train loss at epoch (189):  0.087842226\n",
      "Test loss at epoch (189):  0.054998875\n",
      "Train loss at epoch (190):  0.08717999\n",
      "Test loss at epoch (190):  0.055369433\n",
      "Train loss at epoch (191):  0.087412484\n",
      "Test loss at epoch (191):  0.055080652\n",
      "Train loss at epoch (192):  0.08750145\n",
      "Test loss at epoch (192):  0.054711837\n",
      "Train loss at epoch (193):  0.08704276\n",
      "Test loss at epoch (193):  0.05454563\n",
      "Train loss at epoch (194):  0.08684178\n",
      "Test loss at epoch (194):  0.054267388\n",
      "Train loss at epoch (195):  0.086717\n",
      "Test loss at epoch (195):  0.054418236\n",
      "Train loss at epoch (196):  0.086556025\n",
      "Test loss at epoch (196):  0.05483849\n",
      "Train loss at epoch (197):  0.08613341\n",
      "Test loss at epoch (197):  0.05420026\n",
      "Train loss at epoch (198):  0.08623204\n",
      "Test loss at epoch (198):  0.05381\n",
      "Train loss at epoch (199):  0.08643758\n",
      "Test loss at epoch (199):  0.05380047\n",
      "Train loss at epoch (200):  0.08602076\n",
      "Test loss at epoch (200):  0.0536222\n",
      "Train loss at epoch (201):  0.08605128\n",
      "Test loss at epoch (201):  0.053595122\n",
      "Train loss at epoch (202):  0.08600822\n",
      "Test loss at epoch (202):  0.053751707\n",
      "Train loss at epoch (203):  0.08571023\n",
      "Test loss at epoch (203):  0.05333\n",
      "Train loss at epoch (204):  0.085686974\n",
      "Test loss at epoch (204):  0.05293134\n",
      "Train loss at epoch (205):  0.085360065\n",
      "Test loss at epoch (205):  0.053237915\n",
      "Train loss at epoch (206):  0.08485341\n",
      "Test loss at epoch (206):  0.05282874\n",
      "Train loss at epoch (207):  0.08502771\n",
      "Test loss at epoch (207):  0.052950133\n",
      "Train loss at epoch (208):  0.08526032\n",
      "Test loss at epoch (208):  0.052587897\n",
      "Train loss at epoch (209):  0.08509705\n",
      "Test loss at epoch (209):  0.052311882\n",
      "Train loss at epoch (210):  0.08463354\n",
      "Test loss at epoch (210):  0.05251027\n",
      "Train loss at epoch (211):  0.08430462\n",
      "Test loss at epoch (211):  0.05239319\n",
      "Train loss at epoch (212):  0.08422506\n",
      "Test loss at epoch (212):  0.051841\n",
      "Train loss at epoch (213):  0.084286116\n",
      "Test loss at epoch (213):  0.052060414\n",
      "Train loss at epoch (214):  0.083876014\n",
      "Test loss at epoch (214):  0.05181351\n",
      "Train loss at epoch (215):  0.08413745\n",
      "Test loss at epoch (215):  0.051624622\n",
      "Train loss at epoch (216):  0.0834897\n",
      "Test loss at epoch (216):  0.051888566\n",
      "Train loss at epoch (217):  0.08412213\n",
      "Test loss at epoch (217):  0.05143298\n",
      "Train loss at epoch (218):  0.08427357\n",
      "Test loss at epoch (218):  0.051403273\n",
      "Train loss at epoch (219):  0.08368779\n",
      "Test loss at epoch (219):  0.05155904\n",
      "Train loss at epoch (220):  0.08355468\n",
      "Test loss at epoch (220):  0.051081363\n",
      "Train loss at epoch (221):  0.08349672\n",
      "Test loss at epoch (221):  0.051000495\n",
      "Train loss at epoch (222):  0.08277197\n",
      "Test loss at epoch (222):  0.051086307\n",
      "Train loss at epoch (223):  0.08324458\n",
      "Test loss at epoch (223):  0.051074483\n",
      "Train loss at epoch (224):  0.08374086\n",
      "Test loss at epoch (224):  0.050777066\n",
      "Train loss at epoch (225):  0.08308046\n",
      "Test loss at epoch (225):  0.050665323\n",
      "Train loss at epoch (226):  0.08316752\n",
      "Test loss at epoch (226):  0.050466362\n",
      "Train loss at epoch (227):  0.08279155\n",
      "Test loss at epoch (227):  0.050490927\n",
      "Train loss at epoch (228):  0.08234966\n",
      "Test loss at epoch (228):  0.050156645\n",
      "Train loss at epoch (229):  0.082250886\n",
      "Test loss at epoch (229):  0.05002811\n",
      "Train loss at epoch (230):  0.08225114\n",
      "Test loss at epoch (230):  0.050634086\n",
      "Train loss at epoch (231):  0.082323276\n",
      "Test loss at epoch (231):  0.050007515\n",
      "Train loss at epoch (232):  0.08232894\n",
      "Test loss at epoch (232):  0.049818274\n",
      "Train loss at epoch (233):  0.081899844\n",
      "Test loss at epoch (233):  0.049445048\n",
      "Train loss at epoch (234):  0.08156834\n",
      "Test loss at epoch (234):  0.050100956\n",
      "Train loss at epoch (235):  0.08195767\n",
      "Test loss at epoch (235):  0.049256105\n",
      "Train loss at epoch (236):  0.08177152\n",
      "Test loss at epoch (236):  0.049099244\n",
      "Train loss at epoch (237):  0.0815964\n",
      "Test loss at epoch (237):  0.049246363\n",
      "Train loss at epoch (238):  0.08140583\n",
      "Test loss at epoch (238):  0.04907667\n",
      "Train loss at epoch (239):  0.08169383\n",
      "Test loss at epoch (239):  0.049365405\n",
      "Train loss at epoch (240):  0.080793396\n",
      "Test loss at epoch (240):  0.04896374\n",
      "Train loss at epoch (241):  0.080665976\n",
      "Test loss at epoch (241):  0.049183905\n",
      "Train loss at epoch (242):  0.081270754\n",
      "Test loss at epoch (242):  0.049010847\n",
      "Train loss at epoch (243):  0.08122165\n",
      "Test loss at epoch (243):  0.048244227\n",
      "Train loss at epoch (244):  0.0808042\n",
      "Test loss at epoch (244):  0.048683055\n",
      "Train loss at epoch (245):  0.0808533\n",
      "Test loss at epoch (245):  0.048607312\n",
      "Train loss at epoch (246):  0.080635965\n",
      "Test loss at epoch (246):  0.048402824\n",
      "Train loss at epoch (247):  0.08062748\n",
      "Test loss at epoch (247):  0.04808284\n",
      "Train loss at epoch (248):  0.080241226\n",
      "Test loss at epoch (248):  0.048226893\n",
      "Train loss at epoch (249):  0.080674276\n",
      "Test loss at epoch (249):  0.048203345\n",
      "Train loss at epoch (250):  0.08042903\n",
      "Test loss at epoch (250):  0.048143215\n",
      "Train loss at epoch (251):  0.07995542\n",
      "Test loss at epoch (251):  0.047633898\n",
      "Train loss at epoch (252):  0.079805\n",
      "Test loss at epoch (252):  0.047725\n",
      "Train loss at epoch (253):  0.079716176\n",
      "Test loss at epoch (253):  0.04778782\n",
      "Train loss at epoch (254):  0.079753086\n",
      "Test loss at epoch (254):  0.047603305\n",
      "Train loss at epoch (255):  0.07991352\n",
      "Test loss at epoch (255):  0.047737982\n",
      "Train loss at epoch (256):  0.07965921\n",
      "Test loss at epoch (256):  0.04810964\n",
      "Train loss at epoch (257):  0.07914083\n",
      "Test loss at epoch (257):  0.04720973\n",
      "Train loss at epoch (258):  0.07983131\n",
      "Test loss at epoch (258):  0.047248494\n",
      "Train loss at epoch (259):  0.079125136\n",
      "Test loss at epoch (259):  0.04720488\n",
      "Train loss at epoch (260):  0.0795353\n",
      "Test loss at epoch (260):  0.047287367\n",
      "Train loss at epoch (261):  0.07892537\n",
      "Test loss at epoch (261):  0.047006138\n",
      "Train loss at epoch (262):  0.07905697\n",
      "Test loss at epoch (262):  0.047033172\n",
      "Train loss at epoch (263):  0.07889264\n",
      "Test loss at epoch (263):  0.04748425\n",
      "Train loss at epoch (264):  0.07891247\n",
      "Test loss at epoch (264):  0.046738315\n",
      "Train loss at epoch (265):  0.078722715\n",
      "Test loss at epoch (265):  0.04677636\n",
      "Train loss at epoch (266):  0.07852118\n",
      "Test loss at epoch (266):  0.047151893\n",
      "Train loss at epoch (267):  0.078560546\n",
      "Test loss at epoch (267):  0.046567053\n",
      "Train loss at epoch (268):  0.07858628\n",
      "Test loss at epoch (268):  0.046478562\n",
      "Train loss at epoch (269):  0.07837565\n",
      "Test loss at epoch (269):  0.046448953\n",
      "Train loss at epoch (270):  0.078234\n",
      "Test loss at epoch (270):  0.04631049\n",
      "Train loss at epoch (271):  0.07841946\n",
      "Test loss at epoch (271):  0.046276905\n",
      "Train loss at epoch (272):  0.07812736\n",
      "Test loss at epoch (272):  0.04640922\n",
      "Train loss at epoch (273):  0.07801838\n",
      "Test loss at epoch (273):  0.046375778\n",
      "Train loss at epoch (274):  0.07789111\n",
      "Test loss at epoch (274):  0.046055533\n",
      "Train loss at epoch (275):  0.0780665\n",
      "Test loss at epoch (275):  0.04591201\n",
      "Train loss at epoch (276):  0.078052536\n",
      "Test loss at epoch (276):  0.045746624\n",
      "Train loss at epoch (277):  0.07777935\n",
      "Test loss at epoch (277):  0.045620665\n",
      "Train loss at epoch (278):  0.07800609\n",
      "Test loss at epoch (278):  0.045450233\n",
      "Train loss at epoch (279):  0.07764928\n",
      "Test loss at epoch (279):  0.04568789\n",
      "Train loss at epoch (280):  0.07730516\n",
      "Test loss at epoch (280):  0.04571174\n",
      "Train loss at epoch (281):  0.077511065\n",
      "Test loss at epoch (281):  0.045948867\n",
      "Train loss at epoch (282):  0.07730162\n",
      "Test loss at epoch (282):  0.045725293\n",
      "Train loss at epoch (283):  0.07722871\n",
      "Test loss at epoch (283):  0.04550007\n",
      "Train loss at epoch (284):  0.07739121\n",
      "Test loss at epoch (284):  0.04540415\n",
      "Train loss at epoch (285):  0.0767553\n",
      "Test loss at epoch (285):  0.045050323\n",
      "Train loss at epoch (286):  0.0768148\n",
      "Test loss at epoch (286):  0.04512953\n",
      "Train loss at epoch (287):  0.07680649\n",
      "Test loss at epoch (287):  0.045023736\n",
      "Train loss at epoch (288):  0.07652119\n",
      "Test loss at epoch (288):  0.04525308\n",
      "Train loss at epoch (289):  0.077355966\n",
      "Test loss at epoch (289):  0.045026015\n",
      "Train loss at epoch (290):  0.076745264\n",
      "Test loss at epoch (290):  0.044848625\n",
      "Train loss at epoch (291):  0.076437935\n",
      "Test loss at epoch (291):  0.04488162\n",
      "Train loss at epoch (292):  0.07638505\n",
      "Test loss at epoch (292):  0.04482704\n",
      "Train loss at epoch (293):  0.07609047\n",
      "Test loss at epoch (293):  0.044615828\n",
      "Train loss at epoch (294):  0.0763155\n",
      "Test loss at epoch (294):  0.044696357\n",
      "Train loss at epoch (295):  0.07660105\n",
      "Test loss at epoch (295):  0.04474641\n",
      "Train loss at epoch (296):  0.07584552\n",
      "Test loss at epoch (296):  0.044723205\n",
      "Train loss at epoch (297):  0.07605524\n",
      "Test loss at epoch (297):  0.044595834\n",
      "Train loss at epoch (298):  0.075566955\n",
      "Test loss at epoch (298):  0.044828635\n",
      "Train loss at epoch (299):  0.075631686\n",
      "Test loss at epoch (299):  0.04437314\n",
      "Train loss at epoch (300):  0.07562146\n",
      "Test loss at epoch (300):  0.044272438\n",
      "Train loss at epoch (301):  0.07529147\n",
      "Test loss at epoch (301):  0.044462968\n",
      "Train loss at epoch (302):  0.07526757\n",
      "Test loss at epoch (302):  0.04442322\n",
      "Train loss at epoch (303):  0.075555645\n",
      "Test loss at epoch (303):  0.044438113\n",
      "Train loss at epoch (304):  0.07525551\n",
      "Test loss at epoch (304):  0.044301733\n",
      "Train loss at epoch (305):  0.07522365\n",
      "Test loss at epoch (305):  0.044246618\n",
      "Train loss at epoch (306):  0.07523513\n",
      "Test loss at epoch (306):  0.044033132\n",
      "Train loss at epoch (307):  0.07499497\n",
      "Test loss at epoch (307):  0.04400107\n",
      "Train loss at epoch (308):  0.07507057\n",
      "Test loss at epoch (308):  0.04387995\n",
      "Train loss at epoch (309):  0.07514218\n",
      "Test loss at epoch (309):  0.043961287\n",
      "Train loss at epoch (310):  0.07502404\n",
      "Test loss at epoch (310):  0.04389343\n",
      "Train loss at epoch (311):  0.074999854\n",
      "Test loss at epoch (311):  0.043663073\n",
      "Train loss at epoch (312):  0.07463613\n",
      "Test loss at epoch (312):  0.043775566\n",
      "Train loss at epoch (313):  0.07485112\n",
      "Test loss at epoch (313):  0.043587435\n",
      "Train loss at epoch (314):  0.07483932\n",
      "Test loss at epoch (314):  0.043366384\n",
      "Train loss at epoch (315):  0.074478656\n",
      "Test loss at epoch (315):  0.043373466\n",
      "Train loss at epoch (316):  0.07461207\n",
      "Test loss at epoch (316):  0.043364413\n",
      "Train loss at epoch (317):  0.07425685\n",
      "Test loss at epoch (317):  0.04368453\n",
      "Train loss at epoch (318):  0.07439893\n",
      "Test loss at epoch (318):  0.043491077\n",
      "Train loss at epoch (319):  0.074252196\n",
      "Test loss at epoch (319):  0.043880623\n",
      "Train loss at epoch (320):  0.07421175\n",
      "Test loss at epoch (320):  0.043295942\n",
      "Train loss at epoch (321):  0.074139215\n",
      "Test loss at epoch (321):  0.04301128\n",
      "Train loss at epoch (322):  0.07385764\n",
      "Test loss at epoch (322):  0.04318197\n",
      "Train loss at epoch (323):  0.07420759\n",
      "Test loss at epoch (323):  0.04307053\n",
      "Train loss at epoch (324):  0.073610745\n",
      "Test loss at epoch (324):  0.04308688\n",
      "Train loss at epoch (325):  0.07361396\n",
      "Test loss at epoch (325):  0.042805083\n",
      "Train loss at epoch (326):  0.07389555\n",
      "Test loss at epoch (326):  0.04290566\n",
      "Train loss at epoch (327):  0.07394992\n",
      "Test loss at epoch (327):  0.042858448\n",
      "Train loss at epoch (328):  0.07365085\n",
      "Test loss at epoch (328):  0.04291903\n",
      "Train loss at epoch (329):  0.073532864\n",
      "Test loss at epoch (329):  0.043249678\n",
      "Train loss at epoch (330):  0.07336073\n",
      "Test loss at epoch (330):  0.04266756\n",
      "Train loss at epoch (331):  0.07361682\n",
      "Test loss at epoch (331):  0.043196246\n",
      "Train loss at epoch (332):  0.07389376\n",
      "Test loss at epoch (332):  0.04351996\n",
      "Train loss at epoch (333):  0.07325195\n",
      "Test loss at epoch (333):  0.043033108\n",
      "Train loss at epoch (334):  0.073449105\n",
      "Test loss at epoch (334):  0.042700257\n",
      "Train loss at epoch (335):  0.0730314\n",
      "Test loss at epoch (335):  0.042622283\n",
      "Train loss at epoch (336):  0.07281432\n",
      "Test loss at epoch (336):  0.04303101\n",
      "Train loss at epoch (337):  0.07296538\n",
      "Test loss at epoch (337):  0.042374898\n",
      "Train loss at epoch (338):  0.07326469\n",
      "Test loss at epoch (338):  0.04239737\n",
      "Train loss at epoch (339):  0.072596714\n",
      "Test loss at epoch (339):  0.04240698\n",
      "Train loss at epoch (340):  0.07275241\n",
      "Test loss at epoch (340):  0.04246484\n",
      "Train loss at epoch (341):  0.07285901\n",
      "Test loss at epoch (341):  0.042759687\n",
      "Train loss at epoch (342):  0.072703294\n",
      "Test loss at epoch (342):  0.042336375\n",
      "Train loss at epoch (343):  0.07244744\n",
      "Test loss at epoch (343):  0.042338587\n",
      "Train loss at epoch (344):  0.07248022\n",
      "Test loss at epoch (344):  0.042118836\n",
      "Train loss at epoch (345):  0.0722628\n",
      "Test loss at epoch (345):  0.042261884\n",
      "Train loss at epoch (346):  0.07229721\n",
      "Test loss at epoch (346):  0.04235345\n",
      "Train loss at epoch (347):  0.07224268\n",
      "Test loss at epoch (347):  0.04229101\n",
      "Train loss at epoch (348):  0.07252782\n",
      "Test loss at epoch (348):  0.04223393\n",
      "Train loss at epoch (349):  0.07215185\n",
      "Test loss at epoch (349):  0.041754488\n",
      "Train loss at epoch (350):  0.072065495\n",
      "Test loss at epoch (350):  0.042364497\n",
      "Train loss at epoch (351):  0.071765386\n",
      "Test loss at epoch (351):  0.041730452\n",
      "Train loss at epoch (352):  0.07185231\n",
      "Test loss at epoch (352):  0.04214673\n",
      "Train loss at epoch (353):  0.07198611\n",
      "Test loss at epoch (353):  0.041715294\n",
      "Train loss at epoch (354):  0.07191956\n",
      "Test loss at epoch (354):  0.04210187\n",
      "Train loss at epoch (355):  0.071822934\n",
      "Test loss at epoch (355):  0.04140706\n",
      "Train loss at epoch (356):  0.0719147\n",
      "Test loss at epoch (356):  0.041838925\n",
      "Train loss at epoch (357):  0.07124669\n",
      "Test loss at epoch (357):  0.041388225\n",
      "Train loss at epoch (358):  0.071434736\n",
      "Test loss at epoch (358):  0.04195425\n",
      "Train loss at epoch (359):  0.07162594\n",
      "Test loss at epoch (359):  0.041395176\n",
      "Train loss at epoch (360):  0.07150787\n",
      "Test loss at epoch (360):  0.041668802\n",
      "Train loss at epoch (361):  0.071706645\n",
      "Test loss at epoch (361):  0.0414292\n",
      "Train loss at epoch (362):  0.07114179\n",
      "Test loss at epoch (362):  0.041633133\n",
      "Train loss at epoch (363):  0.07136852\n",
      "Test loss at epoch (363):  0.041307293\n",
      "Train loss at epoch (364):  0.07149371\n",
      "Test loss at epoch (364):  0.041516185\n",
      "Train loss at epoch (365):  0.071384124\n",
      "Test loss at epoch (365):  0.041295793\n",
      "Train loss at epoch (366):  0.0707469\n",
      "Test loss at epoch (366):  0.04157759\n",
      "Train loss at epoch (367):  0.07105613\n",
      "Test loss at epoch (367):  0.041225437\n",
      "Train loss at epoch (368):  0.07108717\n",
      "Test loss at epoch (368):  0.041334823\n",
      "Train loss at epoch (369):  0.070836894\n",
      "Test loss at epoch (369):  0.04093876\n",
      "Train loss at epoch (370):  0.07139076\n",
      "Test loss at epoch (370):  0.040973973\n",
      "Train loss at epoch (371):  0.07070296\n",
      "Test loss at epoch (371):  0.040949985\n",
      "Train loss at epoch (372):  0.070734136\n",
      "Test loss at epoch (372):  0.04085354\n",
      "Train loss at epoch (373):  0.07027846\n",
      "Test loss at epoch (373):  0.04084162\n",
      "Train loss at epoch (374):  0.070581034\n",
      "Test loss at epoch (374):  0.040964022\n",
      "Train loss at epoch (375):  0.071147375\n",
      "Test loss at epoch (375):  0.040866338\n",
      "Train loss at epoch (376):  0.07106553\n",
      "Test loss at epoch (376):  0.040549148\n",
      "Train loss at epoch (377):  0.07081348\n",
      "Test loss at epoch (377):  0.040970422\n",
      "Train loss at epoch (378):  0.07043087\n",
      "Test loss at epoch (378):  0.04123484\n",
      "Train loss at epoch (379):  0.07030865\n",
      "Test loss at epoch (379):  0.04090309\n",
      "Train loss at epoch (380):  0.07023539\n",
      "Test loss at epoch (380):  0.041019212\n",
      "Train loss at epoch (381):  0.07043181\n",
      "Test loss at epoch (381):  0.040464234\n",
      "Train loss at epoch (382):  0.07051032\n",
      "Test loss at epoch (382):  0.04096484\n",
      "Train loss at epoch (383):  0.06993511\n",
      "Test loss at epoch (383):  0.040563513\n",
      "Train loss at epoch (384):  0.06985101\n",
      "Test loss at epoch (384):  0.04070157\n",
      "Train loss at epoch (385):  0.06990031\n",
      "Test loss at epoch (385):  0.040733214\n",
      "Train loss at epoch (386):  0.070188984\n",
      "Test loss at epoch (386):  0.040937215\n",
      "Train loss at epoch (387):  0.069959424\n",
      "Test loss at epoch (387):  0.040375255\n",
      "Train loss at epoch (388):  0.06961741\n",
      "Test loss at epoch (388):  0.040387914\n",
      "Train loss at epoch (389):  0.06982569\n",
      "Test loss at epoch (389):  0.040540464\n",
      "Train loss at epoch (390):  0.0697225\n",
      "Test loss at epoch (390):  0.04056667\n",
      "Train loss at epoch (391):  0.06984661\n",
      "Test loss at epoch (391):  0.040666647\n",
      "Train loss at epoch (392):  0.069627725\n",
      "Test loss at epoch (392):  0.040136136\n",
      "Train loss at epoch (393):  0.07001977\n",
      "Test loss at epoch (393):  0.040830523\n",
      "Train loss at epoch (394):  0.070261806\n",
      "Test loss at epoch (394):  0.040243283\n",
      "Train loss at epoch (395):  0.06988991\n",
      "Test loss at epoch (395):  0.040221572\n",
      "Train loss at epoch (396):  0.06966157\n",
      "Test loss at epoch (396):  0.040079273\n",
      "Train loss at epoch (397):  0.06948842\n",
      "Test loss at epoch (397):  0.040029332\n",
      "Train loss at epoch (398):  0.06923923\n",
      "Test loss at epoch (398):  0.0403489\n",
      "Train loss at epoch (399):  0.069401346\n",
      "Test loss at epoch (399):  0.040268835\n",
      "Train loss at epoch (400):  0.06916573\n",
      "Test loss at epoch (400):  0.04006206\n",
      "Train loss at epoch (401):  0.069404535\n",
      "Test loss at epoch (401):  0.040024444\n",
      "Train loss at epoch (402):  0.069160126\n",
      "Test loss at epoch (402):  0.039835654\n",
      "Train loss at epoch (403):  0.06870591\n",
      "Test loss at epoch (403):  0.03989922\n",
      "Train loss at epoch (404):  0.06890747\n",
      "Test loss at epoch (404):  0.040079646\n",
      "Train loss at epoch (405):  0.06898562\n",
      "Test loss at epoch (405):  0.040085386\n",
      "Train loss at epoch (406):  0.068996966\n",
      "Test loss at epoch (406):  0.04023208\n",
      "Train loss at epoch (407):  0.06880292\n",
      "Test loss at epoch (407):  0.039983574\n",
      "Train loss at epoch (408):  0.06890059\n",
      "Test loss at epoch (408):  0.04001227\n",
      "Train loss at epoch (409):  0.069086686\n",
      "Test loss at epoch (409):  0.039780114\n",
      "Train loss at epoch (410):  0.06876847\n",
      "Test loss at epoch (410):  0.04026822\n",
      "Train loss at epoch (411):  0.0681499\n",
      "Test loss at epoch (411):  0.039782673\n",
      "Train loss at epoch (412):  0.068647906\n",
      "Test loss at epoch (412):  0.039521564\n",
      "Train loss at epoch (413):  0.06812221\n",
      "Test loss at epoch (413):  0.03951928\n",
      "Train loss at epoch (414):  0.068340525\n",
      "Test loss at epoch (414):  0.039655402\n",
      "Train loss at epoch (415):  0.068091005\n",
      "Test loss at epoch (415):  0.039795768\n",
      "Train loss at epoch (416):  0.06840569\n",
      "Test loss at epoch (416):  0.039766777\n",
      "Train loss at epoch (417):  0.06856826\n",
      "Test loss at epoch (417):  0.039459202\n",
      "Train loss at epoch (418):  0.06852472\n",
      "Test loss at epoch (418):  0.03978683\n",
      "Train loss at epoch (419):  0.06838835\n",
      "Test loss at epoch (419):  0.03907974\n",
      "Train loss at epoch (420):  0.0683639\n",
      "Test loss at epoch (420):  0.039548438\n",
      "Train loss at epoch (421):  0.0684925\n",
      "Test loss at epoch (421):  0.039159965\n",
      "Train loss at epoch (422):  0.06843927\n",
      "Test loss at epoch (422):  0.039705027\n",
      "Train loss at epoch (423):  0.068362124\n",
      "Test loss at epoch (423):  0.039592292\n",
      "Train loss at epoch (424):  0.06814634\n",
      "Test loss at epoch (424):  0.03936017\n",
      "Train loss at epoch (425):  0.06780514\n",
      "Test loss at epoch (425):  0.038950432\n",
      "Train loss at epoch (426):  0.067960516\n",
      "Test loss at epoch (426):  0.039050665\n",
      "Train loss at epoch (427):  0.06793238\n",
      "Test loss at epoch (427):  0.039010074\n",
      "Train loss at epoch (428):  0.06759037\n",
      "Test loss at epoch (428):  0.039852645\n",
      "Train loss at epoch (429):  0.0680304\n",
      "Test loss at epoch (429):  0.039408408\n",
      "Train loss at epoch (430):  0.06742376\n",
      "Test loss at epoch (430):  0.03962322\n",
      "Train loss at epoch (431):  0.067760885\n",
      "Test loss at epoch (431):  0.039273027\n",
      "Train loss at epoch (432):  0.067334145\n",
      "Test loss at epoch (432):  0.039088055\n",
      "Train loss at epoch (433):  0.06768435\n",
      "Test loss at epoch (433):  0.039159823\n",
      "Train loss at epoch (434):  0.06766833\n",
      "Test loss at epoch (434):  0.03950651\n",
      "Train loss at epoch (435):  0.06730437\n",
      "Test loss at epoch (435):  0.038988594\n",
      "Train loss at epoch (436):  0.06779641\n",
      "Test loss at epoch (436):  0.03886549\n",
      "Train loss at epoch (437):  0.06709569\n",
      "Test loss at epoch (437):  0.039058916\n",
      "Train loss at epoch (438):  0.06738291\n",
      "Test loss at epoch (438):  0.039027642\n",
      "Train loss at epoch (439):  0.06716134\n",
      "Test loss at epoch (439):  0.039392743\n",
      "Train loss at epoch (440):  0.06753404\n",
      "Test loss at epoch (440):  0.039668605\n",
      "Train loss at epoch (441):  0.06692841\n",
      "Test loss at epoch (441):  0.038907878\n",
      "Train loss at epoch (442):  0.06708697\n",
      "Test loss at epoch (442):  0.03892885\n",
      "Train loss at epoch (443):  0.067464076\n",
      "Test loss at epoch (443):  0.039029904\n",
      "Train loss at epoch (444):  0.06709179\n",
      "Test loss at epoch (444):  0.038679592\n",
      "Train loss at epoch (445):  0.06735255\n",
      "Test loss at epoch (445):  0.038972326\n",
      "Train loss at epoch (446):  0.067105316\n",
      "Test loss at epoch (446):  0.038676247\n",
      "Train loss at epoch (447):  0.06719634\n",
      "Test loss at epoch (447):  0.03851536\n",
      "Train loss at epoch (448):  0.066739306\n",
      "Test loss at epoch (448):  0.038552396\n",
      "Train loss at epoch (449):  0.0666628\n",
      "Test loss at epoch (449):  0.038675547\n",
      "Train loss at epoch (450):  0.06659905\n",
      "Test loss at epoch (450):  0.038690954\n",
      "Train loss at epoch (451):  0.066632554\n",
      "Test loss at epoch (451):  0.038419895\n",
      "Train loss at epoch (452):  0.06689647\n",
      "Test loss at epoch (452):  0.03854462\n",
      "Train loss at epoch (453):  0.066981845\n",
      "Test loss at epoch (453):  0.038386635\n",
      "Train loss at epoch (454):  0.06620485\n",
      "Test loss at epoch (454):  0.038720682\n",
      "Train loss at epoch (455):  0.06719534\n",
      "Test loss at epoch (455):  0.03855348\n",
      "Train loss at epoch (456):  0.06645027\n",
      "Test loss at epoch (456):  0.03823821\n",
      "Train loss at epoch (457):  0.06682346\n",
      "Test loss at epoch (457):  0.038533725\n",
      "Train loss at epoch (458):  0.06648293\n",
      "Test loss at epoch (458):  0.03847116\n",
      "Train loss at epoch (459):  0.06621663\n",
      "Test loss at epoch (459):  0.038288973\n",
      "Train loss at epoch (460):  0.06655951\n",
      "Test loss at epoch (460):  0.038539406\n",
      "Train loss at epoch (461):  0.066429816\n",
      "Test loss at epoch (461):  0.03828467\n",
      "Train loss at epoch (462):  0.06637325\n",
      "Test loss at epoch (462):  0.0385565\n",
      "Train loss at epoch (463):  0.066170074\n",
      "Test loss at epoch (463):  0.038466644\n",
      "Train loss at epoch (464):  0.066651925\n",
      "Test loss at epoch (464):  0.038177125\n",
      "Train loss at epoch (465):  0.06672052\n",
      "Test loss at epoch (465):  0.038569383\n",
      "Train loss at epoch (466):  0.06617293\n",
      "Test loss at epoch (466):  0.038216893\n",
      "Train loss at epoch (467):  0.06573025\n",
      "Test loss at epoch (467):  0.038210448\n",
      "Train loss at epoch (468):  0.066450395\n",
      "Test loss at epoch (468):  0.038498364\n",
      "Train loss at epoch (469):  0.06571224\n",
      "Test loss at epoch (469):  0.038432408\n",
      "Train loss at epoch (470):  0.066202275\n",
      "Test loss at epoch (470):  0.038545467\n",
      "Train loss at epoch (471):  0.06620899\n",
      "Test loss at epoch (471):  0.03857368\n",
      "Train loss at epoch (472):  0.065776005\n",
      "Test loss at epoch (472):  0.038076755\n",
      "Train loss at epoch (473):  0.06564269\n",
      "Test loss at epoch (473):  0.037904955\n",
      "Train loss at epoch (474):  0.065711536\n",
      "Test loss at epoch (474):  0.038333967\n",
      "Train loss at epoch (475):  0.065536626\n",
      "Test loss at epoch (475):  0.037824336\n",
      "Train loss at epoch (476):  0.06544585\n",
      "Test loss at epoch (476):  0.03829119\n",
      "Train loss at epoch (477):  0.06584289\n",
      "Test loss at epoch (477):  0.03805672\n",
      "Train loss at epoch (478):  0.065746635\n",
      "Test loss at epoch (478):  0.037908867\n",
      "Train loss at epoch (479):  0.06548421\n",
      "Test loss at epoch (479):  0.037872285\n",
      "Train loss at epoch (480):  0.065424375\n",
      "Test loss at epoch (480):  0.038149912\n",
      "Train loss at epoch (481):  0.065469235\n",
      "Test loss at epoch (481):  0.037797343\n",
      "Train loss at epoch (482):  0.06557254\n",
      "Test loss at epoch (482):  0.037821904\n",
      "Train loss at epoch (483):  0.06552479\n",
      "Test loss at epoch (483):  0.038115595\n",
      "Train loss at epoch (484):  0.06536483\n",
      "Test loss at epoch (484):  0.038054477\n",
      "Train loss at epoch (485):  0.06515405\n",
      "Test loss at epoch (485):  0.03786808\n",
      "Train loss at epoch (486):  0.06532827\n",
      "Test loss at epoch (486):  0.038378403\n",
      "Train loss at epoch (487):  0.065422826\n",
      "Test loss at epoch (487):  0.037703186\n",
      "Train loss at epoch (488):  0.0649441\n",
      "Test loss at epoch (488):  0.038050484\n",
      "Train loss at epoch (489):  0.0653304\n",
      "Test loss at epoch (489):  0.037941992\n",
      "Train loss at epoch (490):  0.06553327\n",
      "Test loss at epoch (490):  0.038075842\n",
      "Train loss at epoch (491):  0.06524192\n",
      "Test loss at epoch (491):  0.037796635\n",
      "Train loss at epoch (492):  0.06480003\n",
      "Test loss at epoch (492):  0.03750339\n",
      "Train loss at epoch (493):  0.065239415\n",
      "Test loss at epoch (493):  0.038169276\n",
      "Train loss at epoch (494):  0.064746305\n",
      "Test loss at epoch (494):  0.037562784\n",
      "Train loss at epoch (495):  0.06521682\n",
      "Test loss at epoch (495):  0.03759249\n",
      "Train loss at epoch (496):  0.06460481\n",
      "Test loss at epoch (496):  0.037574697\n",
      "Train loss at epoch (497):  0.065066345\n",
      "Test loss at epoch (497):  0.037938308\n",
      "Train loss at epoch (498):  0.06488354\n",
      "Test loss at epoch (498):  0.03797069\n",
      "Train loss at epoch (499):  0.06494773\n",
      "Test loss at epoch (499):  0.037794646\n",
      "Train loss at epoch (500):  0.064842544\n",
      "Test loss at epoch (500):  0.03740702\n",
      "Train loss at epoch (501):  0.06496277\n",
      "Test loss at epoch (501):  0.03756074\n",
      "Train loss at epoch (502):  0.06511546\n",
      "Test loss at epoch (502):  0.037527848\n",
      "Train loss at epoch (503):  0.064907834\n",
      "Test loss at epoch (503):  0.03773505\n",
      "Train loss at epoch (504):  0.06478533\n",
      "Test loss at epoch (504):  0.037389282\n",
      "Train loss at epoch (505):  0.0643654\n",
      "Test loss at epoch (505):  0.03802806\n",
      "Train loss at epoch (506):  0.0645201\n",
      "Test loss at epoch (506):  0.037466157\n",
      "Train loss at epoch (507):  0.06487034\n",
      "Test loss at epoch (507):  0.03728337\n",
      "Train loss at epoch (508):  0.064623594\n",
      "Test loss at epoch (508):  0.037412226\n",
      "Train loss at epoch (509):  0.06488681\n",
      "Test loss at epoch (509):  0.037463933\n",
      "Train loss at epoch (510):  0.06430704\n",
      "Test loss at epoch (510):  0.037513915\n",
      "Train loss at epoch (511):  0.06405177\n",
      "Test loss at epoch (511):  0.037114475\n",
      "Train loss at epoch (512):  0.064451694\n",
      "Test loss at epoch (512):  0.037351876\n",
      "Train loss at epoch (513):  0.06446052\n",
      "Test loss at epoch (513):  0.037323926\n",
      "Train loss at epoch (514):  0.064052\n",
      "Test loss at epoch (514):  0.03723997\n",
      "Train loss at epoch (515):  0.0646616\n",
      "Test loss at epoch (515):  0.037228335\n",
      "Train loss at epoch (516):  0.06463153\n",
      "Test loss at epoch (516):  0.037582625\n",
      "Train loss at epoch (517):  0.06421656\n",
      "Test loss at epoch (517):  0.037482847\n",
      "Train loss at epoch (518):  0.0639224\n",
      "Test loss at epoch (518):  0.037773475\n",
      "Train loss at epoch (519):  0.064173065\n",
      "Test loss at epoch (519):  0.037384935\n",
      "Train loss at epoch (520):  0.06434757\n",
      "Test loss at epoch (520):  0.037167735\n",
      "Train loss at epoch (521):  0.06424436\n",
      "Test loss at epoch (521):  0.037293237\n",
      "Train loss at epoch (522):  0.06383036\n",
      "Test loss at epoch (522):  0.036872774\n",
      "Train loss at epoch (523):  0.0639399\n",
      "Test loss at epoch (523):  0.03706506\n",
      "Train loss at epoch (524):  0.06382143\n",
      "Test loss at epoch (524):  0.037259366\n",
      "Train loss at epoch (525):  0.06437295\n",
      "Test loss at epoch (525):  0.037043907\n",
      "Train loss at epoch (526):  0.06404024\n",
      "Test loss at epoch (526):  0.036956776\n",
      "Train loss at epoch (527):  0.063874125\n",
      "Test loss at epoch (527):  0.036840137\n",
      "Train loss at epoch (528):  0.06318481\n",
      "Test loss at epoch (528):  0.03689039\n",
      "Train loss at epoch (529):  0.06383104\n",
      "Test loss at epoch (529):  0.03689302\n",
      "Train loss at epoch (530):  0.0636723\n",
      "Test loss at epoch (530):  0.03741863\n",
      "Train loss at epoch (531):  0.063784145\n",
      "Test loss at epoch (531):  0.037219264\n",
      "Train loss at epoch (532):  0.06379366\n",
      "Test loss at epoch (532):  0.036949385\n",
      "Train loss at epoch (533):  0.06386945\n",
      "Test loss at epoch (533):  0.037051436\n",
      "Train loss at epoch (534):  0.063606165\n",
      "Test loss at epoch (534):  0.03735881\n",
      "Train loss at epoch (535):  0.06399539\n",
      "Test loss at epoch (535):  0.036791258\n",
      "Train loss at epoch (536):  0.06358457\n",
      "Test loss at epoch (536):  0.036841497\n",
      "Train loss at epoch (537):  0.06342287\n",
      "Test loss at epoch (537):  0.036874913\n",
      "Train loss at epoch (538):  0.06309731\n",
      "Test loss at epoch (538):  0.03666233\n",
      "Train loss at epoch (539):  0.06360999\n",
      "Test loss at epoch (539):  0.03685763\n",
      "Train loss at epoch (540):  0.06330256\n",
      "Test loss at epoch (540):  0.03722739\n",
      "Train loss at epoch (541):  0.06350405\n",
      "Test loss at epoch (541):  0.036876816\n",
      "Train loss at epoch (542):  0.06341732\n",
      "Test loss at epoch (542):  0.03677186\n",
      "Train loss at epoch (543):  0.06329105\n",
      "Test loss at epoch (543):  0.036847245\n",
      "Train loss at epoch (544):  0.062993936\n",
      "Test loss at epoch (544):  0.036890693\n",
      "Train loss at epoch (545):  0.06302005\n",
      "Test loss at epoch (545):  0.036808934\n",
      "Train loss at epoch (546):  0.06304383\n",
      "Test loss at epoch (546):  0.036781404\n",
      "Train loss at epoch (547):  0.063470505\n",
      "Test loss at epoch (547):  0.03665289\n",
      "Train loss at epoch (548):  0.06325237\n",
      "Test loss at epoch (548):  0.036708254\n",
      "Train loss at epoch (549):  0.06312033\n",
      "Test loss at epoch (549):  0.0368287\n",
      "Train loss at epoch (550):  0.0634415\n",
      "Test loss at epoch (550):  0.03671212\n",
      "Train loss at epoch (551):  0.06289558\n",
      "Test loss at epoch (551):  0.037144627\n",
      "Train loss at epoch (552):  0.062452342\n",
      "Test loss at epoch (552):  0.03718254\n",
      "Train loss at epoch (553):  0.06298793\n",
      "Test loss at epoch (553):  0.03653844\n",
      "Train loss at epoch (554):  0.06319998\n",
      "Test loss at epoch (554):  0.03659659\n",
      "Train loss at epoch (555):  0.06287352\n",
      "Test loss at epoch (555):  0.03671534\n",
      "Train loss at epoch (556):  0.06274461\n",
      "Test loss at epoch (556):  0.036973428\n",
      "Train loss at epoch (557):  0.063038714\n",
      "Test loss at epoch (557):  0.036441233\n",
      "Train loss at epoch (558):  0.06285681\n",
      "Test loss at epoch (558):  0.036708742\n",
      "Train loss at epoch (559):  0.06330118\n",
      "Test loss at epoch (559):  0.03637514\n",
      "Train loss at epoch (560):  0.06313635\n",
      "Test loss at epoch (560):  0.036378004\n",
      "Train loss at epoch (561):  0.062446002\n",
      "Test loss at epoch (561):  0.036566656\n",
      "Train loss at epoch (562):  0.06279393\n",
      "Test loss at epoch (562):  0.036673974\n",
      "Train loss at epoch (563):  0.06289992\n",
      "Test loss at epoch (563):  0.036465295\n",
      "Train loss at epoch (564):  0.06260302\n",
      "Test loss at epoch (564):  0.03635161\n",
      "Train loss at epoch (565):  0.06278869\n",
      "Test loss at epoch (565):  0.036684304\n",
      "Train loss at epoch (566):  0.062657945\n",
      "Test loss at epoch (566):  0.03645233\n",
      "Train loss at epoch (567):  0.062461928\n",
      "Test loss at epoch (567):  0.03636092\n",
      "Train loss at epoch (568):  0.06256058\n",
      "Test loss at epoch (568):  0.03631519\n",
      "Train loss at epoch (569):  0.06261918\n",
      "Test loss at epoch (569):  0.036425266\n",
      "Train loss at epoch (570):  0.062481888\n",
      "Test loss at epoch (570):  0.036286563\n",
      "Train loss at epoch (571):  0.06259656\n",
      "Test loss at epoch (571):  0.036471996\n",
      "Train loss at epoch (572):  0.06247073\n",
      "Test loss at epoch (572):  0.036279682\n",
      "Train loss at epoch (573):  0.061988182\n",
      "Test loss at epoch (573):  0.036492933\n",
      "Train loss at epoch (574):  0.062347163\n",
      "Test loss at epoch (574):  0.03608567\n",
      "Train loss at epoch (575):  0.062428385\n",
      "Test loss at epoch (575):  0.036288872\n",
      "Train loss at epoch (576):  0.062418524\n",
      "Test loss at epoch (576):  0.036021143\n",
      "Train loss at epoch (577):  0.06259396\n",
      "Test loss at epoch (577):  0.03641691\n",
      "Train loss at epoch (578):  0.06237278\n",
      "Test loss at epoch (578):  0.036299076\n",
      "Train loss at epoch (579):  0.06234626\n",
      "Test loss at epoch (579):  0.03624162\n",
      "Train loss at epoch (580):  0.06253557\n",
      "Test loss at epoch (580):  0.03646334\n",
      "Train loss at epoch (581):  0.062119395\n",
      "Test loss at epoch (581):  0.036071017\n",
      "Train loss at epoch (582):  0.062284872\n",
      "Test loss at epoch (582):  0.035997238\n",
      "Train loss at epoch (583):  0.06275055\n",
      "Test loss at epoch (583):  0.03611126\n",
      "Train loss at epoch (584):  0.06230711\n",
      "Test loss at epoch (584):  0.036148477\n",
      "Train loss at epoch (585):  0.062392794\n",
      "Test loss at epoch (585):  0.03611484\n",
      "Train loss at epoch (586):  0.061852075\n",
      "Test loss at epoch (586):  0.03631605\n",
      "Train loss at epoch (587):  0.06219101\n",
      "Test loss at epoch (587):  0.03626608\n",
      "Train loss at epoch (588):  0.062046517\n",
      "Test loss at epoch (588):  0.036212083\n",
      "Train loss at epoch (589):  0.06222798\n",
      "Test loss at epoch (589):  0.035848904\n",
      "Train loss at epoch (590):  0.062317397\n",
      "Test loss at epoch (590):  0.036021776\n",
      "Train loss at epoch (591):  0.061656196\n",
      "Test loss at epoch (591):  0.036092073\n",
      "Train loss at epoch (592):  0.061973196\n",
      "Test loss at epoch (592):  0.036090646\n",
      "Train loss at epoch (593):  0.06184577\n",
      "Test loss at epoch (593):  0.036228806\n",
      "Train loss at epoch (594):  0.062174086\n",
      "Test loss at epoch (594):  0.036023322\n",
      "Train loss at epoch (595):  0.06189146\n",
      "Test loss at epoch (595):  0.03631156\n",
      "Train loss at epoch (596):  0.06167023\n",
      "Test loss at epoch (596):  0.03594831\n",
      "Train loss at epoch (597):  0.061863657\n",
      "Test loss at epoch (597):  0.036115427\n",
      "Train loss at epoch (598):  0.06202264\n",
      "Test loss at epoch (598):  0.036100194\n",
      "Train loss at epoch (599):  0.0618447\n",
      "Test loss at epoch (599):  0.035980195\n",
      "Train loss at epoch (600):  0.06203743\n",
      "Test loss at epoch (600):  0.035941944\n",
      "Train loss at epoch (601):  0.0616042\n",
      "Test loss at epoch (601):  0.03592812\n",
      "Train loss at epoch (602):  0.061463345\n",
      "Test loss at epoch (602):  0.03597453\n",
      "Train loss at epoch (603):  0.06142494\n",
      "Test loss at epoch (603):  0.035876997\n",
      "Train loss at epoch (604):  0.061712246\n",
      "Test loss at epoch (604):  0.03604567\n",
      "Train loss at epoch (605):  0.061269518\n",
      "Test loss at epoch (605):  0.03572741\n",
      "Train loss at epoch (606):  0.06158916\n",
      "Test loss at epoch (606):  0.035987664\n",
      "Train loss at epoch (607):  0.061683167\n",
      "Test loss at epoch (607):  0.03592924\n",
      "Train loss at epoch (608):  0.061740417\n",
      "Test loss at epoch (608):  0.03585381\n",
      "Train loss at epoch (609):  0.06154575\n",
      "Test loss at epoch (609):  0.035604663\n",
      "Train loss at epoch (610):  0.06170922\n",
      "Test loss at epoch (610):  0.035782993\n",
      "Train loss at epoch (611):  0.061607514\n",
      "Test loss at epoch (611):  0.03569832\n",
      "Train loss at epoch (612):  0.06157202\n",
      "Test loss at epoch (612):  0.035850152\n",
      "Train loss at epoch (613):  0.061106607\n",
      "Test loss at epoch (613):  0.03596158\n",
      "Train loss at epoch (614):  0.061621025\n",
      "Test loss at epoch (614):  0.035765044\n",
      "Train loss at epoch (615):  0.06148646\n",
      "Test loss at epoch (615):  0.035779685\n",
      "Train loss at epoch (616):  0.061287474\n",
      "Test loss at epoch (616):  0.035807986\n",
      "Train loss at epoch (617):  0.061279476\n",
      "Test loss at epoch (617):  0.03574703\n",
      "Train loss at epoch (618):  0.06095779\n",
      "Test loss at epoch (618):  0.0356476\n",
      "Train loss at epoch (619):  0.06121996\n",
      "Test loss at epoch (619):  0.035736755\n",
      "Train loss at epoch (620):  0.060960975\n",
      "Test loss at epoch (620):  0.035592865\n",
      "Train loss at epoch (621):  0.06110918\n",
      "Test loss at epoch (621):  0.03565131\n",
      "Train loss at epoch (622):  0.061004423\n",
      "Test loss at epoch (622):  0.035588663\n",
      "Train loss at epoch (623):  0.06152735\n",
      "Test loss at epoch (623):  0.035483252\n",
      "Train loss at epoch (624):  0.06110848\n",
      "Test loss at epoch (624):  0.035487104\n",
      "Train loss at epoch (625):  0.060936026\n",
      "Test loss at epoch (625):  0.035662085\n",
      "Train loss at epoch (626):  0.061169893\n",
      "Test loss at epoch (626):  0.03565935\n",
      "Train loss at epoch (627):  0.060845077\n",
      "Test loss at epoch (627):  0.03570544\n",
      "Train loss at epoch (628):  0.060924433\n",
      "Test loss at epoch (628):  0.035753384\n",
      "Train loss at epoch (629):  0.060831618\n",
      "Test loss at epoch (629):  0.035500813\n",
      "Train loss at epoch (630):  0.061139222\n",
      "Test loss at epoch (630):  0.035588607\n",
      "Train loss at epoch (631):  0.060915146\n",
      "Test loss at epoch (631):  0.0353733\n",
      "Train loss at epoch (632):  0.06088148\n",
      "Test loss at epoch (632):  0.035553418\n",
      "Train loss at epoch (633):  0.06114696\n",
      "Test loss at epoch (633):  0.035555374\n",
      "Train loss at epoch (634):  0.060739987\n",
      "Test loss at epoch (634):  0.035490442\n",
      "Train loss at epoch (635):  0.061000053\n",
      "Test loss at epoch (635):  0.035258498\n",
      "Train loss at epoch (636):  0.061016828\n",
      "Test loss at epoch (636):  0.035503495\n",
      "Train loss at epoch (637):  0.060943477\n",
      "Test loss at epoch (637):  0.03538707\n",
      "Train loss at epoch (638):  0.061053403\n",
      "Test loss at epoch (638):  0.035671733\n",
      "Train loss at epoch (639):  0.060813677\n",
      "Test loss at epoch (639):  0.035309643\n",
      "Train loss at epoch (640):  0.060802426\n",
      "Test loss at epoch (640):  0.03529823\n",
      "Train loss at epoch (641):  0.06044072\n",
      "Test loss at epoch (641):  0.035277124\n",
      "Train loss at epoch (642):  0.060537565\n",
      "Test loss at epoch (642):  0.035384625\n",
      "Train loss at epoch (643):  0.06057248\n",
      "Test loss at epoch (643):  0.03583255\n",
      "Train loss at epoch (644):  0.060523994\n",
      "Test loss at epoch (644):  0.035368532\n",
      "Train loss at epoch (645):  0.06084695\n",
      "Test loss at epoch (645):  0.03505081\n",
      "Train loss at epoch (646):  0.060582936\n",
      "Test loss at epoch (646):  0.035370838\n",
      "Train loss at epoch (647):  0.06059922\n",
      "Test loss at epoch (647):  0.03516413\n",
      "Train loss at epoch (648):  0.06072272\n",
      "Test loss at epoch (648):  0.035132203\n",
      "Train loss at epoch (649):  0.060330104\n",
      "Test loss at epoch (649):  0.035271574\n",
      "Train loss at epoch (650):  0.060337327\n",
      "Test loss at epoch (650):  0.03548907\n",
      "Train loss at epoch (651):  0.060445525\n",
      "Test loss at epoch (651):  0.035155732\n",
      "Train loss at epoch (652):  0.06046018\n",
      "Test loss at epoch (652):  0.035197027\n",
      "Train loss at epoch (653):  0.06044594\n",
      "Test loss at epoch (653):  0.03518446\n",
      "Train loss at epoch (654):  0.060412634\n",
      "Test loss at epoch (654):  0.03522138\n",
      "Train loss at epoch (655):  0.06035703\n",
      "Test loss at epoch (655):  0.035164762\n",
      "Train loss at epoch (656):  0.060614638\n",
      "Test loss at epoch (656):  0.035309106\n",
      "Train loss at epoch (657):  0.060195807\n",
      "Test loss at epoch (657):  0.035019066\n",
      "Train loss at epoch (658):  0.060116302\n",
      "Test loss at epoch (658):  0.035287283\n",
      "Train loss at epoch (659):  0.060129784\n",
      "Test loss at epoch (659):  0.035038125\n",
      "Train loss at epoch (660):  0.060275372\n",
      "Test loss at epoch (660):  0.035124972\n",
      "Train loss at epoch (661):  0.06001951\n",
      "Test loss at epoch (661):  0.035356984\n",
      "Train loss at epoch (662):  0.0605951\n",
      "Test loss at epoch (662):  0.035001036\n",
      "Train loss at epoch (663):  0.060313746\n",
      "Test loss at epoch (663):  0.034926742\n",
      "Train loss at epoch (664):  0.060241096\n",
      "Test loss at epoch (664):  0.03515791\n",
      "Train loss at epoch (665):  0.06008314\n",
      "Test loss at epoch (665):  0.034776326\n",
      "Train loss at epoch (666):  0.060113546\n",
      "Test loss at epoch (666):  0.034884986\n",
      "Train loss at epoch (667):  0.06027353\n",
      "Test loss at epoch (667):  0.03523703\n",
      "Train loss at epoch (668):  0.060114745\n",
      "Test loss at epoch (668):  0.034893125\n",
      "Train loss at epoch (669):  0.060353935\n",
      "Test loss at epoch (669):  0.034890376\n",
      "Train loss at epoch (670):  0.059992757\n",
      "Test loss at epoch (670):  0.034767486\n",
      "Train loss at epoch (671):  0.06019086\n",
      "Test loss at epoch (671):  0.034754835\n",
      "Train loss at epoch (672):  0.059886422\n",
      "Test loss at epoch (672):  0.034852095\n",
      "Train loss at epoch (673):  0.059917737\n",
      "Test loss at epoch (673):  0.03501803\n",
      "Train loss at epoch (674):  0.05972255\n",
      "Test loss at epoch (674):  0.034936875\n",
      "Train loss at epoch (675):  0.059885755\n",
      "Test loss at epoch (675):  0.034766056\n",
      "Train loss at epoch (676):  0.06000918\n",
      "Test loss at epoch (676):  0.03471897\n",
      "Train loss at epoch (677):  0.059894312\n",
      "Test loss at epoch (677):  0.034867335\n",
      "Train loss at epoch (678):  0.059711583\n",
      "Test loss at epoch (678):  0.03469721\n",
      "Train loss at epoch (679):  0.05994796\n",
      "Test loss at epoch (679):  0.034751683\n",
      "Train loss at epoch (680):  0.060008246\n",
      "Test loss at epoch (680):  0.03477156\n",
      "Train loss at epoch (681):  0.05987889\n",
      "Test loss at epoch (681):  0.03464526\n",
      "Train loss at epoch (682):  0.06003259\n",
      "Test loss at epoch (682):  0.03492901\n",
      "Train loss at epoch (683):  0.059788067\n",
      "Test loss at epoch (683):  0.03461764\n",
      "Train loss at epoch (684):  0.059968356\n",
      "Test loss at epoch (684):  0.03484545\n",
      "Train loss at epoch (685):  0.059850287\n",
      "Test loss at epoch (685):  0.034870874\n",
      "Train loss at epoch (686):  0.059573416\n",
      "Test loss at epoch (686):  0.0345529\n",
      "Train loss at epoch (687):  0.059479833\n",
      "Test loss at epoch (687):  0.034715433\n",
      "Train loss at epoch (688):  0.059769187\n",
      "Test loss at epoch (688):  0.034921616\n",
      "Train loss at epoch (689):  0.059735026\n",
      "Test loss at epoch (689):  0.03461722\n",
      "Train loss at epoch (690):  0.0597081\n",
      "Test loss at epoch (690):  0.03477498\n",
      "Train loss at epoch (691):  0.059348315\n",
      "Test loss at epoch (691):  0.034614693\n",
      "Train loss at epoch (692):  0.059730217\n",
      "Test loss at epoch (692):  0.034721863\n",
      "Train loss at epoch (693):  0.059651922\n",
      "Test loss at epoch (693):  0.034781992\n",
      "Train loss at epoch (694):  0.059397094\n",
      "Test loss at epoch (694):  0.034894112\n",
      "Train loss at epoch (695):  0.059471294\n",
      "Test loss at epoch (695):  0.034558725\n",
      "Train loss at epoch (696):  0.05962897\n",
      "Test loss at epoch (696):  0.03474872\n",
      "Train loss at epoch (697):  0.05965243\n",
      "Test loss at epoch (697):  0.0348818\n",
      "Train loss at epoch (698):  0.05961696\n",
      "Test loss at epoch (698):  0.034632068\n",
      "Train loss at epoch (699):  0.0599502\n",
      "Test loss at epoch (699):  0.034388278\n",
      "Train loss at epoch (700):  0.059436835\n",
      "Test loss at epoch (700):  0.034583826\n",
      "Train loss at epoch (701):  0.059380513\n",
      "Test loss at epoch (701):  0.034354802\n",
      "Train loss at epoch (702):  0.059221495\n",
      "Test loss at epoch (702):  0.03450894\n",
      "Train loss at epoch (703):  0.059526443\n",
      "Test loss at epoch (703):  0.034632385\n",
      "Train loss at epoch (704):  0.05968516\n",
      "Test loss at epoch (704):  0.03460893\n",
      "Train loss at epoch (705):  0.059356987\n",
      "Test loss at epoch (705):  0.034699615\n",
      "Train loss at epoch (706):  0.059131533\n",
      "Test loss at epoch (706):  0.034525525\n",
      "Train loss at epoch (707):  0.05905873\n",
      "Test loss at epoch (707):  0.03449569\n",
      "Train loss at epoch (708):  0.05926028\n",
      "Test loss at epoch (708):  0.03472436\n",
      "Train loss at epoch (709):  0.059356004\n",
      "Test loss at epoch (709):  0.034564383\n",
      "Train loss at epoch (710):  0.059469078\n",
      "Test loss at epoch (710):  0.0344345\n",
      "Train loss at epoch (711):  0.05912769\n",
      "Test loss at epoch (711):  0.034388054\n",
      "Train loss at epoch (712):  0.059281293\n",
      "Test loss at epoch (712):  0.03424159\n",
      "Train loss at epoch (713):  0.059467457\n",
      "Test loss at epoch (713):  0.034857474\n",
      "Train loss at epoch (714):  0.059292316\n",
      "Test loss at epoch (714):  0.034368757\n",
      "Train loss at epoch (715):  0.05913001\n",
      "Test loss at epoch (715):  0.034470674\n",
      "Train loss at epoch (716):  0.059110157\n",
      "Test loss at epoch (716):  0.034334213\n",
      "Train loss at epoch (717):  0.058831774\n",
      "Test loss at epoch (717):  0.034238685\n",
      "Train loss at epoch (718):  0.059021663\n",
      "Test loss at epoch (718):  0.034361742\n",
      "Train loss at epoch (719):  0.058849722\n",
      "Test loss at epoch (719):  0.03447213\n",
      "Train loss at epoch (720):  0.058920976\n",
      "Test loss at epoch (720):  0.03427148\n",
      "Train loss at epoch (721):  0.05889693\n",
      "Test loss at epoch (721):  0.03412175\n",
      "Train loss at epoch (722):  0.058857173\n",
      "Test loss at epoch (722):  0.034297213\n",
      "Train loss at epoch (723):  0.05898677\n",
      "Test loss at epoch (723):  0.03445091\n",
      "Train loss at epoch (724):  0.05876374\n",
      "Test loss at epoch (724):  0.03428572\n",
      "Train loss at epoch (725):  0.059005946\n",
      "Test loss at epoch (725):  0.03417683\n",
      "Train loss at epoch (726):  0.059173737\n",
      "Test loss at epoch (726):  0.03413219\n",
      "Train loss at epoch (727):  0.05862181\n",
      "Test loss at epoch (727):  0.03413292\n",
      "Train loss at epoch (728):  0.058979124\n",
      "Test loss at epoch (728):  0.034303624\n",
      "Train loss at epoch (729):  0.05870551\n",
      "Test loss at epoch (729):  0.033921406\n",
      "Train loss at epoch (730):  0.059067935\n",
      "Test loss at epoch (730):  0.034297634\n",
      "Train loss at epoch (731):  0.058700956\n",
      "Test loss at epoch (731):  0.0341885\n",
      "Train loss at epoch (732):  0.058570232\n",
      "Test loss at epoch (732):  0.034287892\n",
      "Train loss at epoch (733):  0.058315117\n",
      "Test loss at epoch (733):  0.034362804\n",
      "Train loss at epoch (734):  0.058793616\n",
      "Test loss at epoch (734):  0.034158554\n",
      "Train loss at epoch (735):  0.05892851\n",
      "Test loss at epoch (735):  0.034415774\n",
      "Train loss at epoch (736):  0.058701\n",
      "Test loss at epoch (736):  0.03403127\n",
      "Train loss at epoch (737):  0.058771484\n",
      "Test loss at epoch (737):  0.034272466\n",
      "Train loss at epoch (738):  0.05844352\n",
      "Test loss at epoch (738):  0.034158286\n",
      "Train loss at epoch (739):  0.05879028\n",
      "Test loss at epoch (739):  0.034044284\n",
      "Train loss at epoch (740):  0.05868583\n",
      "Test loss at epoch (740):  0.034287147\n",
      "Train loss at epoch (741):  0.05853705\n",
      "Test loss at epoch (741):  0.034228593\n",
      "Train loss at epoch (742):  0.058952\n",
      "Test loss at epoch (742):  0.034122497\n",
      "Train loss at epoch (743):  0.05863067\n",
      "Test loss at epoch (743):  0.034004383\n",
      "Train loss at epoch (744):  0.058501426\n",
      "Test loss at epoch (744):  0.034183145\n",
      "Train loss at epoch (745):  0.05864912\n",
      "Test loss at epoch (745):  0.034075264\n",
      "Train loss at epoch (746):  0.058744136\n",
      "Test loss at epoch (746):  0.034020476\n",
      "Train loss at epoch (747):  0.05853966\n",
      "Test loss at epoch (747):  0.034047972\n",
      "Train loss at epoch (748):  0.058216922\n",
      "Test loss at epoch (748):  0.03399353\n",
      "Train loss at epoch (749):  0.058676254\n",
      "Test loss at epoch (749):  0.03399894\n",
      "Train loss at epoch (750):  0.05847193\n",
      "Test loss at epoch (750):  0.03394984\n",
      "Train loss at epoch (751):  0.05841833\n",
      "Test loss at epoch (751):  0.0340934\n",
      "Train loss at epoch (752):  0.058788013\n",
      "Test loss at epoch (752):  0.034164045\n",
      "Train loss at epoch (753):  0.058436465\n",
      "Test loss at epoch (753):  0.034039594\n",
      "Train loss at epoch (754):  0.058643673\n",
      "Test loss at epoch (754):  0.03403682\n",
      "Train loss at epoch (755):  0.058735147\n",
      "Test loss at epoch (755):  0.033905525\n",
      "Train loss at epoch (756):  0.058271743\n",
      "Test loss at epoch (756):  0.03396096\n",
      "Train loss at epoch (757):  0.058559168\n",
      "Test loss at epoch (757):  0.0339773\n",
      "Train loss at epoch (758):  0.058677252\n",
      "Test loss at epoch (758):  0.03384648\n",
      "Train loss at epoch (759):  0.058320623\n",
      "Test loss at epoch (759):  0.03383773\n",
      "Train loss at epoch (760):  0.058188736\n",
      "Test loss at epoch (760):  0.03363001\n",
      "Train loss at epoch (761):  0.058182456\n",
      "Test loss at epoch (761):  0.03371489\n",
      "Train loss at epoch (762):  0.058487047\n",
      "Test loss at epoch (762):  0.03376927\n",
      "Train loss at epoch (763):  0.058485758\n",
      "Test loss at epoch (763):  0.03392593\n",
      "Train loss at epoch (764):  0.058363687\n",
      "Test loss at epoch (764):  0.033740655\n",
      "Train loss at epoch (765):  0.05815288\n",
      "Test loss at epoch (765):  0.033774383\n",
      "Train loss at epoch (766):  0.05844204\n",
      "Test loss at epoch (766):  0.033916295\n",
      "Train loss at epoch (767):  0.058393244\n",
      "Test loss at epoch (767):  0.033687726\n",
      "Train loss at epoch (768):  0.05811803\n",
      "Test loss at epoch (768):  0.03381235\n",
      "Train loss at epoch (769):  0.058308136\n",
      "Test loss at epoch (769):  0.03387683\n",
      "Train loss at epoch (770):  0.05839201\n",
      "Test loss at epoch (770):  0.033814758\n",
      "Train loss at epoch (771):  0.0582959\n",
      "Test loss at epoch (771):  0.03378153\n",
      "Train loss at epoch (772):  0.05796186\n",
      "Test loss at epoch (772):  0.033812642\n",
      "Train loss at epoch (773):  0.058585502\n",
      "Test loss at epoch (773):  0.033898767\n",
      "Train loss at epoch (774):  0.058151945\n",
      "Test loss at epoch (774):  0.033745814\n",
      "Train loss at epoch (775):  0.05818116\n",
      "Test loss at epoch (775):  0.033721637\n",
      "Train loss at epoch (776):  0.057887957\n",
      "Test loss at epoch (776):  0.033780385\n",
      "Train loss at epoch (777):  0.058395352\n",
      "Test loss at epoch (777):  0.03369956\n",
      "Train loss at epoch (778):  0.058084477\n",
      "Test loss at epoch (778):  0.03379557\n",
      "Train loss at epoch (779):  0.05823778\n",
      "Test loss at epoch (779):  0.03378276\n",
      "Train loss at epoch (780):  0.058014635\n",
      "Test loss at epoch (780):  0.033732343\n",
      "Train loss at epoch (781):  0.057808526\n",
      "Test loss at epoch (781):  0.033707134\n",
      "Train loss at epoch (782):  0.05754221\n",
      "Test loss at epoch (782):  0.03400614\n",
      "Train loss at epoch (783):  0.057975456\n",
      "Test loss at epoch (783):  0.03372349\n",
      "Train loss at epoch (784):  0.05785243\n",
      "Test loss at epoch (784):  0.033790518\n",
      "Train loss at epoch (785):  0.05796323\n",
      "Test loss at epoch (785):  0.03371737\n",
      "Train loss at epoch (786):  0.057994004\n",
      "Test loss at epoch (786):  0.033604257\n",
      "Train loss at epoch (787):  0.057661507\n",
      "Test loss at epoch (787):  0.033713087\n",
      "Train loss at epoch (788):  0.057739485\n",
      "Test loss at epoch (788):  0.03376926\n",
      "Train loss at epoch (789):  0.058125854\n",
      "Test loss at epoch (789):  0.033699337\n",
      "Train loss at epoch (790):  0.05798717\n",
      "Test loss at epoch (790):  0.033533756\n",
      "Train loss at epoch (791):  0.057642452\n",
      "Test loss at epoch (791):  0.03349997\n",
      "Train loss at epoch (792):  0.05803621\n",
      "Test loss at epoch (792):  0.033456456\n",
      "Train loss at epoch (793):  0.057980213\n",
      "Test loss at epoch (793):  0.03336558\n",
      "Train loss at epoch (794):  0.057959467\n",
      "Test loss at epoch (794):  0.033595018\n",
      "Train loss at epoch (795):  0.057577495\n",
      "Test loss at epoch (795):  0.033571098\n",
      "Train loss at epoch (796):  0.057642676\n",
      "Test loss at epoch (796):  0.03360924\n",
      "Train loss at epoch (797):  0.057895496\n",
      "Test loss at epoch (797):  0.03362208\n",
      "Train loss at epoch (798):  0.0579301\n",
      "Test loss at epoch (798):  0.033452164\n",
      "Train loss at epoch (799):  0.057473417\n",
      "Test loss at epoch (799):  0.03346861\n",
      "Train loss at epoch (800):  0.057564005\n",
      "Test loss at epoch (800):  0.033518344\n",
      "Train loss at epoch (801):  0.057778522\n",
      "Test loss at epoch (801):  0.033367068\n",
      "Train loss at epoch (802):  0.058137238\n",
      "Test loss at epoch (802):  0.03337307\n",
      "Train loss at epoch (803):  0.05754167\n",
      "Test loss at epoch (803):  0.033419807\n",
      "Train loss at epoch (804):  0.057906665\n",
      "Test loss at epoch (804):  0.033568528\n",
      "Train loss at epoch (805):  0.05762864\n",
      "Test loss at epoch (805):  0.033553574\n",
      "Train loss at epoch (806):  0.05759679\n",
      "Test loss at epoch (806):  0.03386692\n",
      "Train loss at epoch (807):  0.05803433\n",
      "Test loss at epoch (807):  0.033576164\n",
      "Train loss at epoch (808):  0.057655107\n",
      "Test loss at epoch (808):  0.033390936\n",
      "Train loss at epoch (809):  0.057892997\n",
      "Test loss at epoch (809):  0.033470225\n",
      "Train loss at epoch (810):  0.057668846\n",
      "Test loss at epoch (810):  0.03348324\n",
      "Train loss at epoch (811):  0.05761347\n",
      "Test loss at epoch (811):  0.03337708\n",
      "Train loss at epoch (812):  0.057767276\n",
      "Test loss at epoch (812):  0.03346302\n",
      "Train loss at epoch (813):  0.05791673\n",
      "Test loss at epoch (813):  0.033344865\n",
      "Train loss at epoch (814):  0.057212587\n",
      "Test loss at epoch (814):  0.033268478\n",
      "Train loss at epoch (815):  0.057577986\n",
      "Test loss at epoch (815):  0.03336343\n",
      "Train loss at epoch (816):  0.057458796\n",
      "Test loss at epoch (816):  0.03332732\n",
      "Train loss at epoch (817):  0.057511088\n",
      "Test loss at epoch (817):  0.033257972\n",
      "Train loss at epoch (818):  0.057492893\n",
      "Test loss at epoch (818):  0.03313298\n",
      "Train loss at epoch (819):  0.05751496\n",
      "Test loss at epoch (819):  0.033393275\n",
      "Train loss at epoch (820):  0.057818063\n",
      "Test loss at epoch (820):  0.0334932\n",
      "Train loss at epoch (821):  0.057413112\n",
      "Test loss at epoch (821):  0.03331126\n",
      "Train loss at epoch (822):  0.057394296\n",
      "Test loss at epoch (822):  0.033350166\n",
      "Train loss at epoch (823):  0.05776055\n",
      "Test loss at epoch (823):  0.03319851\n",
      "Train loss at epoch (824):  0.057235908\n",
      "Test loss at epoch (824):  0.033490647\n",
      "Train loss at epoch (825):  0.057070006\n",
      "Test loss at epoch (825):  0.033422206\n",
      "Train loss at epoch (826):  0.05777291\n",
      "Test loss at epoch (826):  0.03335291\n",
      "Train loss at epoch (827):  0.057463158\n",
      "Test loss at epoch (827):  0.03345046\n",
      "Train loss at epoch (828):  0.05734223\n",
      "Test loss at epoch (828):  0.033487678\n",
      "Train loss at epoch (829):  0.057539914\n",
      "Test loss at epoch (829):  0.03341522\n",
      "Train loss at epoch (830):  0.05720672\n",
      "Test loss at epoch (830):  0.033632036\n",
      "Train loss at epoch (831):  0.057450153\n",
      "Test loss at epoch (831):  0.033274017\n",
      "Train loss at epoch (832):  0.05730496\n",
      "Test loss at epoch (832):  0.0333968\n",
      "Train loss at epoch (833):  0.057527944\n",
      "Test loss at epoch (833):  0.03335011\n",
      "Train loss at epoch (834):  0.057268925\n",
      "Test loss at epoch (834):  0.03347758\n",
      "Train loss at epoch (835):  0.057507873\n",
      "Test loss at epoch (835):  0.033352382\n",
      "Train loss at epoch (836):  0.057267893\n",
      "Test loss at epoch (836):  0.03308921\n",
      "Train loss at epoch (837):  0.05728556\n",
      "Test loss at epoch (837):  0.033347163\n",
      "Train loss at epoch (838):  0.05707658\n",
      "Test loss at epoch (838):  0.033154085\n",
      "Train loss at epoch (839):  0.056900725\n",
      "Test loss at epoch (839):  0.03317927\n",
      "Train loss at epoch (840):  0.05684726\n",
      "Test loss at epoch (840):  0.033293825\n",
      "Train loss at epoch (841):  0.057172075\n",
      "Test loss at epoch (841):  0.033066902\n",
      "Train loss at epoch (842):  0.05734869\n",
      "Test loss at epoch (842):  0.03324289\n",
      "Train loss at epoch (843):  0.057114564\n",
      "Test loss at epoch (843):  0.033125512\n",
      "Train loss at epoch (844):  0.057298794\n",
      "Test loss at epoch (844):  0.033162404\n",
      "Train loss at epoch (845):  0.056961574\n",
      "Test loss at epoch (845):  0.03303867\n",
      "Train loss at epoch (846):  0.05723176\n",
      "Test loss at epoch (846):  0.03304476\n",
      "Train loss at epoch (847):  0.05691191\n",
      "Test loss at epoch (847):  0.03326459\n",
      "Train loss at epoch (848):  0.057153504\n",
      "Test loss at epoch (848):  0.033139203\n",
      "Train loss at epoch (849):  0.057257544\n",
      "Test loss at epoch (849):  0.0330047\n",
      "Train loss at epoch (850):  0.05708503\n",
      "Test loss at epoch (850):  0.03326148\n",
      "Train loss at epoch (851):  0.056989033\n",
      "Test loss at epoch (851):  0.033059057\n",
      "Train loss at epoch (852):  0.05718484\n",
      "Test loss at epoch (852):  0.0330831\n",
      "Train loss at epoch (853):  0.056777947\n",
      "Test loss at epoch (853):  0.032966547\n",
      "Train loss at epoch (854):  0.05670849\n",
      "Test loss at epoch (854):  0.03312238\n",
      "Train loss at epoch (855):  0.056994647\n",
      "Test loss at epoch (855):  0.033156753\n",
      "Train loss at epoch (856):  0.05692841\n",
      "Test loss at epoch (856):  0.03326761\n",
      "Train loss at epoch (857):  0.057126224\n",
      "Test loss at epoch (857):  0.033016995\n",
      "Train loss at epoch (858):  0.056648877\n",
      "Test loss at epoch (858):  0.032933213\n",
      "Train loss at epoch (859):  0.05673052\n",
      "Test loss at epoch (859):  0.032849904\n",
      "Train loss at epoch (860):  0.056899104\n",
      "Test loss at epoch (860):  0.033060044\n",
      "Train loss at epoch (861):  0.056851305\n",
      "Test loss at epoch (861):  0.03315741\n",
      "Train loss at epoch (862):  0.05707588\n",
      "Test loss at epoch (862):  0.033216167\n",
      "Train loss at epoch (863):  0.05712071\n",
      "Test loss at epoch (863):  0.032908488\n",
      "Train loss at epoch (864):  0.05661133\n",
      "Test loss at epoch (864):  0.03312332\n",
      "Train loss at epoch (865):  0.056982696\n",
      "Test loss at epoch (865):  0.033024676\n",
      "Train loss at epoch (866):  0.05674619\n",
      "Test loss at epoch (866):  0.032923985\n",
      "Train loss at epoch (867):  0.05689899\n",
      "Test loss at epoch (867):  0.0329732\n",
      "Train loss at epoch (868):  0.05722833\n",
      "Test loss at epoch (868):  0.03312364\n",
      "Train loss at epoch (869):  0.056846548\n",
      "Test loss at epoch (869):  0.03314253\n",
      "Train loss at epoch (870):  0.056800816\n",
      "Test loss at epoch (870):  0.033054877\n",
      "Train loss at epoch (871):  0.056893792\n",
      "Test loss at epoch (871):  0.033033706\n",
      "Train loss at epoch (872):  0.05675681\n",
      "Test loss at epoch (872):  0.03304562\n",
      "Train loss at epoch (873):  0.056668643\n",
      "Test loss at epoch (873):  0.0330734\n",
      "Train loss at epoch (874):  0.056740448\n",
      "Test loss at epoch (874):  0.033021662\n",
      "Train loss at epoch (875):  0.0568552\n",
      "Test loss at epoch (875):  0.032905642\n",
      "Train loss at epoch (876):  0.056806456\n",
      "Test loss at epoch (876):  0.033143427\n",
      "Train loss at epoch (877):  0.05660757\n",
      "Test loss at epoch (877):  0.03285484\n",
      "Train loss at epoch (878):  0.056611482\n",
      "Test loss at epoch (878):  0.03288276\n",
      "Train loss at epoch (879):  0.0569103\n",
      "Test loss at epoch (879):  0.032859903\n",
      "Train loss at epoch (880):  0.056720268\n",
      "Test loss at epoch (880):  0.032909475\n",
      "Train loss at epoch (881):  0.05690894\n",
      "Test loss at epoch (881):  0.032910947\n",
      "Train loss at epoch (882):  0.056504257\n",
      "Test loss at epoch (882):  0.032970965\n",
      "Train loss at epoch (883):  0.056754276\n",
      "Test loss at epoch (883):  0.03290515\n",
      "Train loss at epoch (884):  0.056667276\n",
      "Test loss at epoch (884):  0.032779906\n",
      "Train loss at epoch (885):  0.056504715\n",
      "Test loss at epoch (885):  0.03305426\n",
      "Train loss at epoch (886):  0.05677601\n",
      "Test loss at epoch (886):  0.032849267\n",
      "Train loss at epoch (887):  0.05679916\n",
      "Test loss at epoch (887):  0.03289403\n",
      "Train loss at epoch (888):  0.056800403\n",
      "Test loss at epoch (888):  0.032856543\n",
      "Train loss at epoch (889):  0.056607258\n",
      "Test loss at epoch (889):  0.03274591\n",
      "Train loss at epoch (890):  0.056633294\n",
      "Test loss at epoch (890):  0.032930538\n",
      "Train loss at epoch (891):  0.056724325\n",
      "Test loss at epoch (891):  0.032864593\n",
      "Train loss at epoch (892):  0.056431744\n",
      "Test loss at epoch (892):  0.03272792\n",
      "Train loss at epoch (893):  0.056528416\n",
      "Test loss at epoch (893):  0.03278805\n",
      "Train loss at epoch (894):  0.056479637\n",
      "Test loss at epoch (894):  0.032822777\n",
      "Train loss at epoch (895):  0.056631077\n",
      "Test loss at epoch (895):  0.033011902\n",
      "Train loss at epoch (896):  0.056750216\n",
      "Test loss at epoch (896):  0.03277267\n",
      "Train loss at epoch (897):  0.0568161\n",
      "Test loss at epoch (897):  0.032716267\n",
      "Train loss at epoch (898):  0.056480765\n",
      "Test loss at epoch (898):  0.032740816\n",
      "Train loss at epoch (899):  0.056716792\n",
      "Test loss at epoch (899):  0.032732278\n",
      "Train loss at epoch (900):  0.056494478\n",
      "Test loss at epoch (900):  0.032769106\n",
      "Train loss at epoch (901):  0.056559183\n",
      "Test loss at epoch (901):  0.03275824\n",
      "Train loss at epoch (902):  0.056722865\n",
      "Test loss at epoch (902):  0.032688566\n",
      "Train loss at epoch (903):  0.05618599\n",
      "Test loss at epoch (903):  0.032757793\n",
      "Train loss at epoch (904):  0.05617831\n",
      "Test loss at epoch (904):  0.032736093\n",
      "Train loss at epoch (905):  0.056444384\n",
      "Test loss at epoch (905):  0.032718044\n",
      "Train loss at epoch (906):  0.05632379\n",
      "Test loss at epoch (906):  0.03273928\n",
      "Train loss at epoch (907):  0.056521144\n",
      "Test loss at epoch (907):  0.032675873\n",
      "Train loss at epoch (908):  0.056365307\n",
      "Test loss at epoch (908):  0.032665536\n",
      "Train loss at epoch (909):  0.056329563\n",
      "Test loss at epoch (909):  0.03273008\n",
      "Train loss at epoch (910):  0.056475632\n",
      "Test loss at epoch (910):  0.032572273\n",
      "Train loss at epoch (911):  0.056275036\n",
      "Test loss at epoch (911):  0.03278477\n",
      "Train loss at epoch (912):  0.056446563\n",
      "Test loss at epoch (912):  0.032677542\n",
      "Train loss at epoch (913):  0.056583244\n",
      "Test loss at epoch (913):  0.032860488\n",
      "Train loss at epoch (914):  0.05637469\n",
      "Test loss at epoch (914):  0.032645356\n",
      "Train loss at epoch (915):  0.056609333\n",
      "Test loss at epoch (915):  0.03284154\n",
      "Train loss at epoch (916):  0.0562722\n",
      "Test loss at epoch (916):  0.032578595\n",
      "Train loss at epoch (917):  0.056295536\n",
      "Test loss at epoch (917):  0.032778163\n",
      "Train loss at epoch (918):  0.056261096\n",
      "Test loss at epoch (918):  0.032628987\n",
      "Train loss at epoch (919):  0.056459464\n",
      "Test loss at epoch (919):  0.032783438\n",
      "Train loss at epoch (920):  0.056554586\n",
      "Test loss at epoch (920):  0.03268909\n",
      "Train loss at epoch (921):  0.05625588\n",
      "Test loss at epoch (921):  0.032596234\n",
      "Train loss at epoch (922):  0.056200154\n",
      "Test loss at epoch (922):  0.03283184\n",
      "Train loss at epoch (923):  0.056161772\n",
      "Test loss at epoch (923):  0.03269025\n",
      "Train loss at epoch (924):  0.05607809\n",
      "Test loss at epoch (924):  0.032624066\n",
      "Train loss at epoch (925):  0.05619685\n",
      "Test loss at epoch (925):  0.032601405\n",
      "Train loss at epoch (926):  0.056273513\n",
      "Test loss at epoch (926):  0.032596618\n",
      "Train loss at epoch (927):  0.056311805\n",
      "Test loss at epoch (927):  0.03259453\n",
      "Train loss at epoch (928):  0.056487657\n",
      "Test loss at epoch (928):  0.032568567\n",
      "Train loss at epoch (929):  0.056305293\n",
      "Test loss at epoch (929):  0.032585066\n",
      "Train loss at epoch (930):  0.05619559\n",
      "Test loss at epoch (930):  0.03253327\n",
      "Train loss at epoch (931):  0.056054916\n",
      "Test loss at epoch (931):  0.03270117\n",
      "Train loss at epoch (932):  0.05626674\n",
      "Test loss at epoch (932):  0.032830704\n",
      "Train loss at epoch (933):  0.056262285\n",
      "Test loss at epoch (933):  0.0325482\n",
      "Train loss at epoch (934):  0.056023344\n",
      "Test loss at epoch (934):  0.032504324\n",
      "Train loss at epoch (935):  0.05583908\n",
      "Test loss at epoch (935):  0.032585353\n",
      "Train loss at epoch (936):  0.056349635\n",
      "Test loss at epoch (936):  0.032564126\n",
      "Train loss at epoch (937):  0.05618267\n",
      "Test loss at epoch (937):  0.03257385\n",
      "Train loss at epoch (938):  0.05598481\n",
      "Test loss at epoch (938):  0.03269015\n",
      "Train loss at epoch (939):  0.05600619\n",
      "Test loss at epoch (939):  0.032511212\n",
      "Train loss at epoch (940):  0.056041535\n",
      "Test loss at epoch (940):  0.032614052\n",
      "Train loss at epoch (941):  0.056395125\n",
      "Test loss at epoch (941):  0.032412667\n",
      "Train loss at epoch (942):  0.056269925\n",
      "Test loss at epoch (942):  0.032352157\n",
      "Train loss at epoch (943):  0.056435727\n",
      "Test loss at epoch (943):  0.03267194\n",
      "Train loss at epoch (944):  0.056321207\n",
      "Test loss at epoch (944):  0.032645594\n",
      "Train loss at epoch (945):  0.05610665\n",
      "Test loss at epoch (945):  0.032561086\n",
      "Train loss at epoch (946):  0.05613608\n",
      "Test loss at epoch (946):  0.03252113\n",
      "Train loss at epoch (947):  0.05585162\n",
      "Test loss at epoch (947):  0.032551553\n",
      "Train loss at epoch (948):  0.05613088\n",
      "Test loss at epoch (948):  0.03242513\n",
      "Train loss at epoch (949):  0.056155395\n",
      "Test loss at epoch (949):  0.0324158\n",
      "Train loss at epoch (950):  0.05592001\n",
      "Test loss at epoch (950):  0.03257759\n",
      "Train loss at epoch (951):  0.056180872\n",
      "Test loss at epoch (951):  0.03255785\n",
      "Train loss at epoch (952):  0.05615118\n",
      "Test loss at epoch (952):  0.032504354\n",
      "Train loss at epoch (953):  0.056214556\n",
      "Test loss at epoch (953):  0.03249815\n",
      "Train loss at epoch (954):  0.056179695\n",
      "Test loss at epoch (954):  0.032461982\n",
      "Train loss at epoch (955):  0.056140244\n",
      "Test loss at epoch (955):  0.03248645\n",
      "Train loss at epoch (956):  0.055932745\n",
      "Test loss at epoch (956):  0.03235607\n",
      "Train loss at epoch (957):  0.055936437\n",
      "Test loss at epoch (957):  0.032432117\n",
      "Train loss at epoch (958):  0.055649992\n",
      "Test loss at epoch (958):  0.03248052\n",
      "Train loss at epoch (959):  0.05603012\n",
      "Test loss at epoch (959):  0.03250181\n",
      "Train loss at epoch (960):  0.056056976\n",
      "Test loss at epoch (960):  0.032421235\n",
      "Train loss at epoch (961):  0.055929605\n",
      "Test loss at epoch (961):  0.03240617\n",
      "Train loss at epoch (962):  0.05586185\n",
      "Test loss at epoch (962):  0.03238788\n",
      "Train loss at epoch (963):  0.055845782\n",
      "Test loss at epoch (963):  0.032500807\n",
      "Train loss at epoch (964):  0.055735976\n",
      "Test loss at epoch (964):  0.032416172\n",
      "Train loss at epoch (965):  0.055616386\n",
      "Test loss at epoch (965):  0.032359827\n",
      "Train loss at epoch (966):  0.05608781\n",
      "Test loss at epoch (966):  0.032378327\n",
      "Train loss at epoch (967):  0.056315716\n",
      "Test loss at epoch (967):  0.032357268\n",
      "Train loss at epoch (968):  0.055771448\n",
      "Test loss at epoch (968):  0.03253957\n",
      "Train loss at epoch (969):  0.055704664\n",
      "Test loss at epoch (969):  0.03245275\n",
      "Train loss at epoch (970):  0.055896167\n",
      "Test loss at epoch (970):  0.032446723\n",
      "Train loss at epoch (971):  0.05599476\n",
      "Test loss at epoch (971):  0.032367773\n",
      "Train loss at epoch (972):  0.055977065\n",
      "Test loss at epoch (972):  0.032437675\n",
      "Train loss at epoch (973):  0.055897776\n",
      "Test loss at epoch (973):  0.032412916\n",
      "Train loss at epoch (974):  0.05577678\n",
      "Test loss at epoch (974):  0.03225836\n",
      "Train loss at epoch (975):  0.055524934\n",
      "Test loss at epoch (975):  0.032184873\n",
      "Train loss at epoch (976):  0.05589632\n",
      "Test loss at epoch (976):  0.03236436\n",
      "Train loss at epoch (977):  0.055795986\n",
      "Test loss at epoch (977):  0.03238714\n",
      "Train loss at epoch (978):  0.055827256\n",
      "Test loss at epoch (978):  0.03224936\n",
      "Train loss at epoch (979):  0.055939935\n",
      "Test loss at epoch (979):  0.032335877\n",
      "Train loss at epoch (980):  0.05576401\n",
      "Test loss at epoch (980):  0.032383543\n",
      "Train loss at epoch (981):  0.056101087\n",
      "Test loss at epoch (981):  0.032260746\n",
      "Train loss at epoch (982):  0.05564554\n",
      "Test loss at epoch (982):  0.032257486\n",
      "Train loss at epoch (983):  0.055870373\n",
      "Test loss at epoch (983):  0.0324837\n",
      "Train loss at epoch (984):  0.055675432\n",
      "Test loss at epoch (984):  0.03236257\n",
      "Train loss at epoch (985):  0.055828024\n",
      "Test loss at epoch (985):  0.03230554\n",
      "Train loss at epoch (986):  0.056102347\n",
      "Test loss at epoch (986):  0.032232612\n",
      "Train loss at epoch (987):  0.05611711\n",
      "Test loss at epoch (987):  0.032435097\n",
      "Train loss at epoch (988):  0.05608815\n",
      "Test loss at epoch (988):  0.0323552\n",
      "Train loss at epoch (989):  0.05553061\n",
      "Test loss at epoch (989):  0.032257564\n",
      "Train loss at epoch (990):  0.055630278\n",
      "Test loss at epoch (990):  0.032397866\n",
      "Train loss at epoch (991):  0.055997632\n",
      "Test loss at epoch (991):  0.03236454\n",
      "Train loss at epoch (992):  0.05574662\n",
      "Test loss at epoch (992):  0.03234308\n",
      "Train loss at epoch (993):  0.055512376\n",
      "Test loss at epoch (993):  0.032203455\n",
      "Train loss at epoch (994):  0.05586467\n",
      "Test loss at epoch (994):  0.032236114\n",
      "Train loss at epoch (995):  0.05540253\n",
      "Test loss at epoch (995):  0.032314774\n",
      "Train loss at epoch (996):  0.055720355\n",
      "Test loss at epoch (996):  0.03235065\n",
      "Train loss at epoch (997):  0.05554594\n",
      "Test loss at epoch (997):  0.032267343\n",
      "Train loss at epoch (998):  0.055636425\n",
      "Test loss at epoch (998):  0.032301594\n",
      "Train loss at epoch (999):  0.05597289\n",
      "Test loss at epoch (999):  0.032185134\n",
      "Train loss at epoch (1000):  0.05549493\n",
      "Test loss at epoch (1000):  0.032293342\n",
      "Train loss at epoch (1001):  0.05602007\n",
      "Test loss at epoch (1001):  0.03247954\n",
      "Train loss at epoch (1002):  0.055491522\n",
      "Test loss at epoch (1002):  0.032184456\n",
      "Train loss at epoch (1003):  0.05580741\n",
      "Test loss at epoch (1003):  0.032215483\n",
      "Train loss at epoch (1004):  0.056028772\n",
      "Test loss at epoch (1004):  0.03225408\n",
      "Train loss at epoch (1005):  0.055563807\n",
      "Test loss at epoch (1005):  0.032234393\n",
      "Train loss at epoch (1006):  0.055753466\n",
      "Test loss at epoch (1006):  0.03217145\n",
      "Train loss at epoch (1007):  0.05544865\n",
      "Test loss at epoch (1007):  0.03218044\n",
      "Train loss at epoch (1008):  0.05579989\n",
      "Test loss at epoch (1008):  0.03223768\n",
      "Train loss at epoch (1009):  0.055533092\n",
      "Test loss at epoch (1009):  0.032248802\n",
      "Train loss at epoch (1010):  0.055464085\n",
      "Test loss at epoch (1010):  0.032240544\n",
      "Train loss at epoch (1011):  0.055832006\n",
      "Test loss at epoch (1011):  0.032269627\n",
      "Train loss at epoch (1012):  0.055204436\n",
      "Test loss at epoch (1012):  0.032163173\n",
      "Train loss at epoch (1013):  0.055717945\n",
      "Test loss at epoch (1013):  0.03229186\n",
      "Train loss at epoch (1014):  0.05530983\n",
      "Test loss at epoch (1014):  0.0321977\n",
      "Train loss at epoch (1015):  0.055596244\n",
      "Test loss at epoch (1015):  0.032314464\n",
      "Train loss at epoch (1016):  0.055700418\n",
      "Test loss at epoch (1016):  0.03216073\n",
      "Train loss at epoch (1017):  0.0556483\n",
      "Test loss at epoch (1017):  0.032097965\n",
      "Train loss at epoch (1018):  0.055487867\n",
      "Test loss at epoch (1018):  0.032304317\n",
      "Train loss at epoch (1019):  0.055333298\n",
      "Test loss at epoch (1019):  0.032215185\n",
      "Train loss at epoch (1020):  0.055757772\n",
      "Test loss at epoch (1020):  0.03207675\n",
      "Train loss at epoch (1021):  0.055669434\n",
      "Test loss at epoch (1021):  0.032063145\n",
      "Train loss at epoch (1022):  0.055768814\n",
      "Test loss at epoch (1022):  0.032210194\n",
      "Train loss at epoch (1023):  0.055111345\n",
      "Test loss at epoch (1023):  0.032174293\n",
      "Train loss at epoch (1024):  0.05541588\n",
      "Test loss at epoch (1024):  0.032161664\n",
      "Train loss at epoch (1025):  0.05554469\n",
      "Test loss at epoch (1025):  0.032131013\n",
      "Train loss at epoch (1026):  0.055410583\n",
      "Test loss at epoch (1026):  0.032145843\n",
      "Train loss at epoch (1027):  0.055694498\n",
      "Test loss at epoch (1027):  0.032216337\n",
      "Train loss at epoch (1028):  0.055616073\n",
      "Test loss at epoch (1028):  0.032059755\n",
      "Train loss at epoch (1029):  0.055560317\n",
      "Test loss at epoch (1029):  0.032132808\n",
      "Train loss at epoch (1030):  0.055439007\n",
      "Test loss at epoch (1030):  0.0321481\n",
      "Train loss at epoch (1031):  0.055752244\n",
      "Test loss at epoch (1031):  0.032153152\n",
      "Train loss at epoch (1032):  0.055141665\n",
      "Test loss at epoch (1032):  0.032111857\n",
      "Train loss at epoch (1033):  0.0555027\n",
      "Test loss at epoch (1033):  0.03214768\n",
      "Train loss at epoch (1034):  0.05528118\n",
      "Test loss at epoch (1034):  0.0320794\n",
      "Train loss at epoch (1035):  0.055459887\n",
      "Test loss at epoch (1035):  0.0321648\n",
      "Train loss at epoch (1036):  0.055532575\n",
      "Test loss at epoch (1036):  0.032015763\n",
      "Train loss at epoch (1037):  0.055199567\n",
      "Test loss at epoch (1037):  0.032021306\n",
      "Train loss at epoch (1038):  0.055360273\n",
      "Test loss at epoch (1038):  0.032072335\n",
      "Train loss at epoch (1039):  0.055349465\n",
      "Test loss at epoch (1039):  0.032198403\n",
      "Train loss at epoch (1040):  0.055677433\n",
      "Test loss at epoch (1040):  0.032164507\n",
      "Train loss at epoch (1041):  0.05547618\n",
      "Test loss at epoch (1041):  0.03208695\n",
      "Train loss at epoch (1042):  0.055418547\n",
      "Test loss at epoch (1042):  0.03212584\n",
      "Train loss at epoch (1043):  0.055506777\n",
      "Test loss at epoch (1043):  0.031931132\n",
      "Train loss at epoch (1044):  0.055478033\n",
      "Test loss at epoch (1044):  0.032045826\n",
      "Train loss at epoch (1045):  0.05534937\n",
      "Test loss at epoch (1045):  0.03206888\n",
      "Train loss at epoch (1046):  0.055531655\n",
      "Test loss at epoch (1046):  0.031963248\n",
      "Train loss at epoch (1047):  0.055204786\n",
      "Test loss at epoch (1047):  0.03205105\n",
      "Train loss at epoch (1048):  0.05512851\n",
      "Test loss at epoch (1048):  0.032068904\n",
      "Train loss at epoch (1049):  0.055264466\n",
      "Test loss at epoch (1049):  0.032110486\n",
      "Train loss at epoch (1050):  0.055492986\n",
      "Test loss at epoch (1050):  0.032027747\n",
      "Train loss at epoch (1051):  0.055228934\n",
      "Test loss at epoch (1051):  0.032080006\n",
      "Train loss at epoch (1052):  0.054999948\n",
      "Test loss at epoch (1052):  0.032091\n",
      "Train loss at epoch (1053):  0.05546352\n",
      "Test loss at epoch (1053):  0.032172624\n",
      "Train loss at epoch (1054):  0.05567476\n",
      "Test loss at epoch (1054):  0.032008786\n",
      "Train loss at epoch (1055):  0.055477906\n",
      "Test loss at epoch (1055):  0.032064926\n",
      "Train loss at epoch (1056):  0.05517794\n",
      "Test loss at epoch (1056):  0.03192679\n",
      "Train loss at epoch (1057):  0.05563925\n",
      "Test loss at epoch (1057):  0.032078058\n",
      "Train loss at epoch (1058):  0.05581245\n",
      "Test loss at epoch (1058):  0.03203955\n",
      "Train loss at epoch (1059):  0.055392247\n",
      "Test loss at epoch (1059):  0.032008085\n",
      "Train loss at epoch (1060):  0.05541636\n",
      "Test loss at epoch (1060):  0.031980045\n",
      "Train loss at epoch (1061):  0.055419248\n",
      "Test loss at epoch (1061):  0.03191326\n",
      "Train loss at epoch (1062):  0.05521886\n",
      "Test loss at epoch (1062):  0.032025605\n",
      "Train loss at epoch (1063):  0.055263508\n",
      "Test loss at epoch (1063):  0.031906534\n",
      "Train loss at epoch (1064):  0.05515524\n",
      "Test loss at epoch (1064):  0.03195718\n",
      "Train loss at epoch (1065):  0.0554604\n",
      "Test loss at epoch (1065):  0.032071367\n",
      "Train loss at epoch (1066):  0.055246595\n",
      "Test loss at epoch (1066):  0.03201766\n",
      "Train loss at epoch (1067):  0.055287983\n",
      "Test loss at epoch (1067):  0.03199624\n",
      "Train loss at epoch (1068):  0.055374596\n",
      "Test loss at epoch (1068):  0.03203045\n",
      "Train loss at epoch (1069):  0.055359613\n",
      "Test loss at epoch (1069):  0.031985667\n",
      "Train loss at epoch (1070):  0.05518108\n",
      "Test loss at epoch (1070):  0.031938124\n",
      "Train loss at epoch (1071):  0.055322412\n",
      "Test loss at epoch (1071):  0.031953663\n",
      "Train loss at epoch (1072):  0.05512221\n",
      "Test loss at epoch (1072):  0.032012437\n",
      "Train loss at epoch (1073):  0.055322576\n",
      "Test loss at epoch (1073):  0.031864826\n",
      "Train loss at epoch (1074):  0.055350944\n",
      "Test loss at epoch (1074):  0.032048058\n",
      "Train loss at epoch (1075):  0.055130716\n",
      "Test loss at epoch (1075):  0.03191094\n",
      "Train loss at epoch (1076):  0.05541017\n",
      "Test loss at epoch (1076):  0.031964283\n",
      "Train loss at epoch (1077):  0.05518186\n",
      "Test loss at epoch (1077):  0.03188452\n",
      "Train loss at epoch (1078):  0.055160057\n",
      "Test loss at epoch (1078):  0.031882312\n",
      "Train loss at epoch (1079):  0.055461597\n",
      "Test loss at epoch (1079):  0.03188675\n",
      "Train loss at epoch (1080):  0.05512286\n",
      "Test loss at epoch (1080):  0.03183933\n",
      "Train loss at epoch (1081):  0.055411134\n",
      "Test loss at epoch (1081):  0.03184178\n",
      "Train loss at epoch (1082):  0.05523608\n",
      "Test loss at epoch (1082):  0.0318157\n",
      "Train loss at epoch (1083):  0.05496509\n",
      "Test loss at epoch (1083):  0.031980205\n",
      "Train loss at epoch (1084):  0.055171005\n",
      "Test loss at epoch (1084):  0.031964418\n",
      "Train loss at epoch (1085):  0.054888997\n",
      "Test loss at epoch (1085):  0.03198016\n",
      "Train loss at epoch (1086):  0.055022463\n",
      "Test loss at epoch (1086):  0.03186358\n",
      "Train loss at epoch (1087):  0.05505256\n",
      "Test loss at epoch (1087):  0.031950783\n",
      "Train loss at epoch (1088):  0.05502069\n",
      "Test loss at epoch (1088):  0.031928215\n",
      "Train loss at epoch (1089):  0.055092074\n",
      "Test loss at epoch (1089):  0.0318759\n",
      "Train loss at epoch (1090):  0.05515119\n",
      "Test loss at epoch (1090):  0.03185813\n",
      "Train loss at epoch (1091):  0.055237815\n",
      "Test loss at epoch (1091):  0.031886924\n",
      "Train loss at epoch (1092):  0.055375718\n",
      "Test loss at epoch (1092):  0.031902507\n",
      "Train loss at epoch (1093):  0.055205707\n",
      "Test loss at epoch (1093):  0.031878762\n",
      "Train loss at epoch (1094):  0.055009536\n",
      "Test loss at epoch (1094):  0.031956464\n",
      "Train loss at epoch (1095):  0.054939263\n",
      "Test loss at epoch (1095):  0.031823\n",
      "Train loss at epoch (1096):  0.055174395\n",
      "Test loss at epoch (1096):  0.03197103\n",
      "Train loss at epoch (1097):  0.054822885\n",
      "Test loss at epoch (1097):  0.03183384\n",
      "Train loss at epoch (1098):  0.055128682\n",
      "Test loss at epoch (1098):  0.03190828\n",
      "Train loss at epoch (1099):  0.055195224\n",
      "Test loss at epoch (1099):  0.031880543\n",
      "Train loss at epoch (1100):  0.055155754\n",
      "Test loss at epoch (1100):  0.031800497\n",
      "Train loss at epoch (1101):  0.05508711\n",
      "Test loss at epoch (1101):  0.03187858\n",
      "Train loss at epoch (1102):  0.055361737\n",
      "Test loss at epoch (1102):  0.031719808\n",
      "Train loss at epoch (1103):  0.054919515\n",
      "Test loss at epoch (1103):  0.03192162\n",
      "Train loss at epoch (1104):  0.055190723\n",
      "Test loss at epoch (1104):  0.031891827\n",
      "Train loss at epoch (1105):  0.054618098\n",
      "Test loss at epoch (1105):  0.031788044\n",
      "Train loss at epoch (1106):  0.05516702\n",
      "Test loss at epoch (1106):  0.031935323\n",
      "Train loss at epoch (1107):  0.05505667\n",
      "Test loss at epoch (1107):  0.03176026\n",
      "Train loss at epoch (1108):  0.054905966\n",
      "Test loss at epoch (1108):  0.031774983\n",
      "Train loss at epoch (1109):  0.05521741\n",
      "Test loss at epoch (1109):  0.031862956\n",
      "Train loss at epoch (1110):  0.055230815\n",
      "Test loss at epoch (1110):  0.03179881\n",
      "Train loss at epoch (1111):  0.055166773\n",
      "Test loss at epoch (1111):  0.031705238\n",
      "Train loss at epoch (1112):  0.055135887\n",
      "Test loss at epoch (1112):  0.03182503\n",
      "Train loss at epoch (1113):  0.054940708\n",
      "Test loss at epoch (1113):  0.031776235\n",
      "Train loss at epoch (1114):  0.05517929\n",
      "Test loss at epoch (1114):  0.031718828\n",
      "Train loss at epoch (1115):  0.054994628\n",
      "Test loss at epoch (1115):  0.031708945\n",
      "Train loss at epoch (1116):  0.05458993\n",
      "Test loss at epoch (1116):  0.0317329\n",
      "Train loss at epoch (1117):  0.055312816\n",
      "Test loss at epoch (1117):  0.031744074\n",
      "Train loss at epoch (1118):  0.055248145\n",
      "Test loss at epoch (1118):  0.031820185\n",
      "Train loss at epoch (1119):  0.05519212\n",
      "Test loss at epoch (1119):  0.031709403\n",
      "Train loss at epoch (1120):  0.05502547\n",
      "Test loss at epoch (1120):  0.031714726\n",
      "Train loss at epoch (1121):  0.054794166\n",
      "Test loss at epoch (1121):  0.03183789\n",
      "Train loss at epoch (1122):  0.054884315\n",
      "Test loss at epoch (1122):  0.031857353\n",
      "Train loss at epoch (1123):  0.05508746\n",
      "Test loss at epoch (1123):  0.031763744\n",
      "Train loss at epoch (1124):  0.054872762\n",
      "Test loss at epoch (1124):  0.031801995\n",
      "Train loss at epoch (1125):  0.055524144\n",
      "Test loss at epoch (1125):  0.031727325\n",
      "Train loss at epoch (1126):  0.055140413\n",
      "Test loss at epoch (1126):  0.031757165\n",
      "Train loss at epoch (1127):  0.05510744\n",
      "Test loss at epoch (1127):  0.031725973\n",
      "Train loss at epoch (1128):  0.054741956\n",
      "Test loss at epoch (1128):  0.031659734\n",
      "Train loss at epoch (1129):  0.055298302\n",
      "Test loss at epoch (1129):  0.031777177\n",
      "Train loss at epoch (1130):  0.054957982\n",
      "Test loss at epoch (1130):  0.031802416\n",
      "Train loss at epoch (1131):  0.055040874\n",
      "Test loss at epoch (1131):  0.03178804\n",
      "Train loss at epoch (1132):  0.055245534\n",
      "Test loss at epoch (1132):  0.03179829\n",
      "Train loss at epoch (1133):  0.05535745\n",
      "Test loss at epoch (1133):  0.03176778\n",
      "Train loss at epoch (1134):  0.055129357\n",
      "Test loss at epoch (1134):  0.031814743\n",
      "Train loss at epoch (1135):  0.055228416\n",
      "Test loss at epoch (1135):  0.031773973\n",
      "Train loss at epoch (1136):  0.05496771\n",
      "Test loss at epoch (1136):  0.031740792\n",
      "Train loss at epoch (1137):  0.055175554\n",
      "Test loss at epoch (1137):  0.03176257\n",
      "Train loss at epoch (1138):  0.055084635\n",
      "Test loss at epoch (1138):  0.031774364\n",
      "Train loss at epoch (1139):  0.05490881\n",
      "Test loss at epoch (1139):  0.031817928\n",
      "Train loss at epoch (1140):  0.054530513\n",
      "Test loss at epoch (1140):  0.031719305\n",
      "Train loss at epoch (1141):  0.054806303\n",
      "Test loss at epoch (1141):  0.03174625\n",
      "Train loss at epoch (1142):  0.054956596\n",
      "Test loss at epoch (1142):  0.031743158\n",
      "Train loss at epoch (1143):  0.054668047\n",
      "Test loss at epoch (1143):  0.03170057\n",
      "Train loss at epoch (1144):  0.055141035\n",
      "Test loss at epoch (1144):  0.031740535\n",
      "Train loss at epoch (1145):  0.05477407\n",
      "Test loss at epoch (1145):  0.031663146\n",
      "Train loss at epoch (1146):  0.055005055\n",
      "Test loss at epoch (1146):  0.031797566\n",
      "Train loss at epoch (1147):  0.054647304\n",
      "Test loss at epoch (1147):  0.031721268\n",
      "Train loss at epoch (1148):  0.055135652\n",
      "Test loss at epoch (1148):  0.031703763\n",
      "Train loss at epoch (1149):  0.05484993\n",
      "Test loss at epoch (1149):  0.031672332\n",
      "Train loss at epoch (1150):  0.055242226\n",
      "Test loss at epoch (1150):  0.03168772\n",
      "Train loss at epoch (1151):  0.054807752\n",
      "Test loss at epoch (1151):  0.031775724\n",
      "Train loss at epoch (1152):  0.05495541\n",
      "Test loss at epoch (1152):  0.03175487\n",
      "Train loss at epoch (1153):  0.05517456\n",
      "Test loss at epoch (1153):  0.031728167\n",
      "Train loss at epoch (1154):  0.05482905\n",
      "Test loss at epoch (1154):  0.031733803\n",
      "Train loss at epoch (1155):  0.05513717\n",
      "Test loss at epoch (1155):  0.031744167\n",
      "Train loss at epoch (1156):  0.05465487\n",
      "Test loss at epoch (1156):  0.031670827\n",
      "Train loss at epoch (1157):  0.05476678\n",
      "Test loss at epoch (1157):  0.03162376\n",
      "Train loss at epoch (1158):  0.05514449\n",
      "Test loss at epoch (1158):  0.03171046\n",
      "Train loss at epoch (1159):  0.05493969\n",
      "Test loss at epoch (1159):  0.031701654\n",
      "Train loss at epoch (1160):  0.05456875\n",
      "Test loss at epoch (1160):  0.031737994\n",
      "Train loss at epoch (1161):  0.05483921\n",
      "Test loss at epoch (1161):  0.031806003\n",
      "Train loss at epoch (1162):  0.05496086\n",
      "Test loss at epoch (1162):  0.031766832\n",
      "Train loss at epoch (1163):  0.054724272\n",
      "Test loss at epoch (1163):  0.03169012\n",
      "Train loss at epoch (1164):  0.055065814\n",
      "Test loss at epoch (1164):  0.03182355\n",
      "Train loss at epoch (1165):  0.054791227\n",
      "Test loss at epoch (1165):  0.03164394\n",
      "Train loss at epoch (1166):  0.055016942\n",
      "Test loss at epoch (1166):  0.031697698\n",
      "Train loss at epoch (1167):  0.055092912\n",
      "Test loss at epoch (1167):  0.03167692\n",
      "Train loss at epoch (1168):  0.054861024\n",
      "Test loss at epoch (1168):  0.031627707\n",
      "Train loss at epoch (1169):  0.0547973\n",
      "Test loss at epoch (1169):  0.031699654\n",
      "Train loss at epoch (1170):  0.054702967\n",
      "Test loss at epoch (1170):  0.03165958\n",
      "Train loss at epoch (1171):  0.054746717\n",
      "Test loss at epoch (1171):  0.031713787\n",
      "Train loss at epoch (1172):  0.05515948\n",
      "Test loss at epoch (1172):  0.031715084\n",
      "Train loss at epoch (1173):  0.054663625\n",
      "Test loss at epoch (1173):  0.03175055\n",
      "Train loss at epoch (1174):  0.054830488\n",
      "Test loss at epoch (1174):  0.03169935\n",
      "Train loss at epoch (1175):  0.055009294\n",
      "Test loss at epoch (1175):  0.03165954\n",
      "Train loss at epoch (1176):  0.054931793\n",
      "Test loss at epoch (1176):  0.031664267\n",
      "Train loss at epoch (1177):  0.05486449\n",
      "Test loss at epoch (1177):  0.0316584\n",
      "Train loss at epoch (1178):  0.054906074\n",
      "Test loss at epoch (1178):  0.03161354\n",
      "Train loss at epoch (1179):  0.055078927\n",
      "Test loss at epoch (1179):  0.03169692\n",
      "Train loss at epoch (1180):  0.054789867\n",
      "Test loss at epoch (1180):  0.03167297\n",
      "Train loss at epoch (1181):  0.054925576\n",
      "Test loss at epoch (1181):  0.031585656\n",
      "Train loss at epoch (1182):  0.05493317\n",
      "Test loss at epoch (1182):  0.031665724\n",
      "Train loss at epoch (1183):  0.055041797\n",
      "Test loss at epoch (1183):  0.03167831\n",
      "Train loss at epoch (1184):  0.054672763\n",
      "Test loss at epoch (1184):  0.031714883\n",
      "Train loss at epoch (1185):  0.054763414\n",
      "Test loss at epoch (1185):  0.031667106\n",
      "Train loss at epoch (1186):  0.054955147\n",
      "Test loss at epoch (1186):  0.031661753\n",
      "Train loss at epoch (1187):  0.054634705\n",
      "Test loss at epoch (1187):  0.031671535\n",
      "Train loss at epoch (1188):  0.054730397\n",
      "Test loss at epoch (1188):  0.03161298\n",
      "Train loss at epoch (1189):  0.054626446\n",
      "Test loss at epoch (1189):  0.03171171\n",
      "Train loss at epoch (1190):  0.05475889\n",
      "Test loss at epoch (1190):  0.031656276\n",
      "Train loss at epoch (1191):  0.05493508\n",
      "Test loss at epoch (1191):  0.031625044\n",
      "Train loss at epoch (1192):  0.05477255\n",
      "Test loss at epoch (1192):  0.031613708\n",
      "Train loss at epoch (1193):  0.05482481\n",
      "Test loss at epoch (1193):  0.03157627\n",
      "Train loss at epoch (1194):  0.054728515\n",
      "Test loss at epoch (1194):  0.03171344\n",
      "Train loss at epoch (1195):  0.054771055\n",
      "Test loss at epoch (1195):  0.031640675\n",
      "Train loss at epoch (1196):  0.054592393\n",
      "Test loss at epoch (1196):  0.031686988\n",
      "Train loss at epoch (1197):  0.054825973\n",
      "Test loss at epoch (1197):  0.031645894\n",
      "Train loss at epoch (1198):  0.054528076\n",
      "Test loss at epoch (1198):  0.031620108\n",
      "Train loss at epoch (1199):  0.054744948\n",
      "Test loss at epoch (1199):  0.031585574\n",
      "Train loss at epoch (1200):  0.054646123\n",
      "Test loss at epoch (1200):  0.03154541\n",
      "Train loss at epoch (1201):  0.054999407\n",
      "Test loss at epoch (1201):  0.03163386\n",
      "Train loss at epoch (1202):  0.054850522\n",
      "Test loss at epoch (1202):  0.031682506\n",
      "Train loss at epoch (1203):  0.054681562\n",
      "Test loss at epoch (1203):  0.031647235\n",
      "Train loss at epoch (1204):  0.05474465\n",
      "Test loss at epoch (1204):  0.031629056\n",
      "Train loss at epoch (1205):  0.05461522\n",
      "Test loss at epoch (1205):  0.03160619\n",
      "Train loss at epoch (1206):  0.054768726\n",
      "Test loss at epoch (1206):  0.031663682\n",
      "Train loss at epoch (1207):  0.054730773\n",
      "Test loss at epoch (1207):  0.03166476\n",
      "Train loss at epoch (1208):  0.05480395\n",
      "Test loss at epoch (1208):  0.031617038\n",
      "Train loss at epoch (1209):  0.05464051\n",
      "Test loss at epoch (1209):  0.031616163\n",
      "Train loss at epoch (1210):  0.054819163\n",
      "Test loss at epoch (1210):  0.031640783\n",
      "Train loss at epoch (1211):  0.0544289\n",
      "Test loss at epoch (1211):  0.031674854\n",
      "Train loss at epoch (1212):  0.05483017\n",
      "Test loss at epoch (1212):  0.031662118\n",
      "Train loss at epoch (1213):  0.05486949\n",
      "Test loss at epoch (1213):  0.031641595\n",
      "Train loss at epoch (1214):  0.054920476\n",
      "Test loss at epoch (1214):  0.031716496\n",
      "Train loss at epoch (1215):  0.05500274\n",
      "Test loss at epoch (1215):  0.03165767\n",
      "Train loss at epoch (1216):  0.054556362\n",
      "Test loss at epoch (1216):  0.031588882\n",
      "Train loss at epoch (1217):  0.054858997\n",
      "Test loss at epoch (1217):  0.031595826\n",
      "Train loss at epoch (1218):  0.05490844\n",
      "Test loss at epoch (1218):  0.031575974\n",
      "Train loss at epoch (1219):  0.054464627\n",
      "Test loss at epoch (1219):  0.031580467\n",
      "Train loss at epoch (1220):  0.054295413\n",
      "Test loss at epoch (1220):  0.031605054\n",
      "Train loss at epoch (1221):  0.0547666\n",
      "Test loss at epoch (1221):  0.031577908\n",
      "Train loss at epoch (1222):  0.054912783\n",
      "Test loss at epoch (1222):  0.031639203\n",
      "Train loss at epoch (1223):  0.054892506\n",
      "Test loss at epoch (1223):  0.031576302\n",
      "Train loss at epoch (1224):  0.054630477\n",
      "Test loss at epoch (1224):  0.03156102\n",
      "Train loss at epoch (1225):  0.05468921\n",
      "Test loss at epoch (1225):  0.031604648\n",
      "Train loss at epoch (1226):  0.054698486\n",
      "Test loss at epoch (1226):  0.031576343\n",
      "Train loss at epoch (1227):  0.054631233\n",
      "Test loss at epoch (1227):  0.031559575\n",
      "Train loss at epoch (1228):  0.05457742\n",
      "Test loss at epoch (1228):  0.03156395\n",
      "Train loss at epoch (1229):  0.054985084\n",
      "Test loss at epoch (1229):  0.031604957\n",
      "Train loss at epoch (1230):  0.054607987\n",
      "Test loss at epoch (1230):  0.0316248\n",
      "Train loss at epoch (1231):  0.054712087\n",
      "Test loss at epoch (1231):  0.03156345\n",
      "Train loss at epoch (1232):  0.054892614\n",
      "Test loss at epoch (1232):  0.03157968\n",
      "Train loss at epoch (1233):  0.05454045\n",
      "Test loss at epoch (1233):  0.0315389\n",
      "Train loss at epoch (1234):  0.054799188\n",
      "Test loss at epoch (1234):  0.03162474\n",
      "Train loss at epoch (1235):  0.054788966\n",
      "Test loss at epoch (1235):  0.031592544\n",
      "Train loss at epoch (1236):  0.05482767\n",
      "Test loss at epoch (1236):  0.031586736\n",
      "Train loss at epoch (1237):  0.05475493\n",
      "Test loss at epoch (1237):  0.03154952\n",
      "Train loss at epoch (1238):  0.05481092\n",
      "Test loss at epoch (1238):  0.031574346\n",
      "Train loss at epoch (1239):  0.05469118\n",
      "Test loss at epoch (1239):  0.03158633\n",
      "Train loss at epoch (1240):  0.054607004\n",
      "Test loss at epoch (1240):  0.031609368\n",
      "Train loss at epoch (1241):  0.05466484\n",
      "Test loss at epoch (1241):  0.031596042\n",
      "Train loss at epoch (1242):  0.054829948\n",
      "Test loss at epoch (1242):  0.03156457\n",
      "Train loss at epoch (1243):  0.054574877\n",
      "Test loss at epoch (1243):  0.03157889\n",
      "Train loss at epoch (1244):  0.054887816\n",
      "Test loss at epoch (1244):  0.031643182\n",
      "Train loss at epoch (1245):  0.05471324\n",
      "Test loss at epoch (1245):  0.03166015\n",
      "Train loss at epoch (1246):  0.0546234\n",
      "Test loss at epoch (1246):  0.031582545\n",
      "Train loss at epoch (1247):  0.054597434\n",
      "Test loss at epoch (1247):  0.031541936\n",
      "Train loss at epoch (1248):  0.054533392\n",
      "Test loss at epoch (1248):  0.03153472\n",
      "Train loss at epoch (1249):  0.054562643\n",
      "Test loss at epoch (1249):  0.031515278\n",
      "Train loss at epoch (1250):  0.054604974\n",
      "Test loss at epoch (1250):  0.0315322\n",
      "Train loss at epoch (1251):  0.05453151\n",
      "Test loss at epoch (1251):  0.031512354\n",
      "Train loss at epoch (1252):  0.054687526\n",
      "Test loss at epoch (1252):  0.031594012\n",
      "Train loss at epoch (1253):  0.05447198\n",
      "Test loss at epoch (1253):  0.031585667\n",
      "Train loss at epoch (1254):  0.05455719\n",
      "Test loss at epoch (1254):  0.031595565\n",
      "Train loss at epoch (1255):  0.054598458\n",
      "Test loss at epoch (1255):  0.031572614\n",
      "Train loss at epoch (1256):  0.054553173\n",
      "Test loss at epoch (1256):  0.031622037\n",
      "Train loss at epoch (1257):  0.05468586\n",
      "Test loss at epoch (1257):  0.031526178\n",
      "Train loss at epoch (1258):  0.05471467\n",
      "Test loss at epoch (1258):  0.031547178\n",
      "Train loss at epoch (1259):  0.054653816\n",
      "Test loss at epoch (1259):  0.03157483\n",
      "Train loss at epoch (1260):  0.054620743\n",
      "Test loss at epoch (1260):  0.03152971\n",
      "Train loss at epoch (1261):  0.054632224\n",
      "Test loss at epoch (1261):  0.03154662\n",
      "Train loss at epoch (1262):  0.054879315\n",
      "Test loss at epoch (1262):  0.031522464\n",
      "Train loss at epoch (1263):  0.054559436\n",
      "Test loss at epoch (1263):  0.031567466\n",
      "Train loss at epoch (1264):  0.054554496\n",
      "Test loss at epoch (1264):  0.031506654\n",
      "Train loss at epoch (1265):  0.054713257\n",
      "Test loss at epoch (1265):  0.031567518\n",
      "Train loss at epoch (1266):  0.054648843\n",
      "Test loss at epoch (1266):  0.031584732\n",
      "Train loss at epoch (1267):  0.054630242\n",
      "Test loss at epoch (1267):  0.03161335\n",
      "Train loss at epoch (1268):  0.05488376\n",
      "Test loss at epoch (1268):  0.031597342\n",
      "Train loss at epoch (1269):  0.05450982\n",
      "Test loss at epoch (1269):  0.03156682\n",
      "Train loss at epoch (1270):  0.054966666\n",
      "Test loss at epoch (1270):  0.031581227\n",
      "Train loss at epoch (1271):  0.054741625\n",
      "Test loss at epoch (1271):  0.03157081\n",
      "Train loss at epoch (1272):  0.054719873\n",
      "Test loss at epoch (1272):  0.031560194\n",
      "Train loss at epoch (1273):  0.054580223\n",
      "Test loss at epoch (1273):  0.031523403\n",
      "Train loss at epoch (1274):  0.05454398\n",
      "Test loss at epoch (1274):  0.03158281\n",
      "Train loss at epoch (1275):  0.054766465\n",
      "Test loss at epoch (1275):  0.031619977\n",
      "Train loss at epoch (1276):  0.054410808\n",
      "Test loss at epoch (1276):  0.031612776\n",
      "Train loss at epoch (1277):  0.05449281\n",
      "Test loss at epoch (1277):  0.031572066\n",
      "Train loss at epoch (1278):  0.055010103\n",
      "Test loss at epoch (1278):  0.031550325\n",
      "Train loss at epoch (1279):  0.054398097\n",
      "Test loss at epoch (1279):  0.03155465\n",
      "Train loss at epoch (1280):  0.054813422\n",
      "Test loss at epoch (1280):  0.031599723\n",
      "Train loss at epoch (1281):  0.05436248\n",
      "Test loss at epoch (1281):  0.0315721\n",
      "Train loss at epoch (1282):  0.054678973\n",
      "Test loss at epoch (1282):  0.031516016\n",
      "Train loss at epoch (1283):  0.05445796\n",
      "Test loss at epoch (1283):  0.03155077\n",
      "Train loss at epoch (1284):  0.05470667\n",
      "Test loss at epoch (1284):  0.03154223\n",
      "Train loss at epoch (1285):  0.05464821\n",
      "Test loss at epoch (1285):  0.031559806\n",
      "Train loss at epoch (1286):  0.054424077\n",
      "Test loss at epoch (1286):  0.03155541\n",
      "Train loss at epoch (1287):  0.054550182\n",
      "Test loss at epoch (1287):  0.031562436\n",
      "Train loss at epoch (1288):  0.054851055\n",
      "Test loss at epoch (1288):  0.031584606\n",
      "Train loss at epoch (1289):  0.054514706\n",
      "Test loss at epoch (1289):  0.031537186\n",
      "Train loss at epoch (1290):  0.05465682\n",
      "Test loss at epoch (1290):  0.03153694\n",
      "Train loss at epoch (1291):  0.054641075\n",
      "Test loss at epoch (1291):  0.031547215\n",
      "Train loss at epoch (1292):  0.054393984\n",
      "Test loss at epoch (1292):  0.031539354\n",
      "Train loss at epoch (1293):  0.05458022\n",
      "Test loss at epoch (1293):  0.031530436\n",
      "Train loss at epoch (1294):  0.054639008\n",
      "Test loss at epoch (1294):  0.03156603\n",
      "Train loss at epoch (1295):  0.054476965\n",
      "Test loss at epoch (1295):  0.031575028\n",
      "Train loss at epoch (1296):  0.054709382\n",
      "Test loss at epoch (1296):  0.03152205\n",
      "Train loss at epoch (1297):  0.054666158\n",
      "Test loss at epoch (1297):  0.03153346\n",
      "Train loss at epoch (1298):  0.054656316\n",
      "Test loss at epoch (1298):  0.031574775\n",
      "Train loss at epoch (1299):  0.054609712\n",
      "Test loss at epoch (1299):  0.031550776\n",
      "Train loss at epoch (1300):  0.05474894\n",
      "Test loss at epoch (1300):  0.031545267\n",
      "Train loss at epoch (1301):  0.054997884\n",
      "Test loss at epoch (1301):  0.03150999\n",
      "Train loss at epoch (1302):  0.054416314\n",
      "Test loss at epoch (1302):  0.031522304\n",
      "Train loss at epoch (1303):  0.054642677\n",
      "Test loss at epoch (1303):  0.031537365\n",
      "Train loss at epoch (1304):  0.05447752\n",
      "Test loss at epoch (1304):  0.031559195\n",
      "Train loss at epoch (1305):  0.054269172\n",
      "Test loss at epoch (1305):  0.031531494\n",
      "Train loss at epoch (1306):  0.054708805\n",
      "Test loss at epoch (1306):  0.03154907\n",
      "Train loss at epoch (1307):  0.05447731\n",
      "Test loss at epoch (1307):  0.03153144\n",
      "Train loss at epoch (1308):  0.054555595\n",
      "Test loss at epoch (1308):  0.031515528\n",
      "Train loss at epoch (1309):  0.054494318\n",
      "Test loss at epoch (1309):  0.031514518\n",
      "Train loss at epoch (1310):  0.05456419\n",
      "Test loss at epoch (1310):  0.031499524\n",
      "Train loss at epoch (1311):  0.054581057\n",
      "Test loss at epoch (1311):  0.0315065\n",
      "Train loss at epoch (1312):  0.05478752\n",
      "Test loss at epoch (1312):  0.031491708\n",
      "Train loss at epoch (1313):  0.054791406\n",
      "Test loss at epoch (1313):  0.03152867\n",
      "Train loss at epoch (1314):  0.054817796\n",
      "Test loss at epoch (1314):  0.03156747\n",
      "Train loss at epoch (1315):  0.054478265\n",
      "Test loss at epoch (1315):  0.03156486\n",
      "Train loss at epoch (1316):  0.054486632\n",
      "Test loss at epoch (1316):  0.03152848\n",
      "Train loss at epoch (1317):  0.05470335\n",
      "Test loss at epoch (1317):  0.03152502\n",
      "Train loss at epoch (1318):  0.054432645\n",
      "Test loss at epoch (1318):  0.03152148\n",
      "Train loss at epoch (1319):  0.054624062\n",
      "Test loss at epoch (1319):  0.031513657\n",
      "Train loss at epoch (1320):  0.054692548\n",
      "Test loss at epoch (1320):  0.03151955\n",
      "Train loss at epoch (1321):  0.054600015\n",
      "Test loss at epoch (1321):  0.031557363\n",
      "Train loss at epoch (1322):  0.05436983\n",
      "Test loss at epoch (1322):  0.03150941\n",
      "Train loss at epoch (1323):  0.054494083\n",
      "Test loss at epoch (1323):  0.03149574\n",
      "Train loss at epoch (1324):  0.05443732\n",
      "Test loss at epoch (1324):  0.031518333\n",
      "Train loss at epoch (1325):  0.05441204\n",
      "Test loss at epoch (1325):  0.03148201\n",
      "Train loss at epoch (1326):  0.054787654\n",
      "Test loss at epoch (1326):  0.031459253\n",
      "Train loss at epoch (1327):  0.054461192\n",
      "Test loss at epoch (1327):  0.031469442\n",
      "Train loss at epoch (1328):  0.054280587\n",
      "Test loss at epoch (1328):  0.03149327\n",
      "Train loss at epoch (1329):  0.05436685\n",
      "Test loss at epoch (1329):  0.031489998\n",
      "Train loss at epoch (1330):  0.05472634\n",
      "Test loss at epoch (1330):  0.031469706\n",
      "Train loss at epoch (1331):  0.054717485\n",
      "Test loss at epoch (1331):  0.031479668\n",
      "Train loss at epoch (1332):  0.054109693\n",
      "Test loss at epoch (1332):  0.031523984\n",
      "Train loss at epoch (1333):  0.054533996\n",
      "Test loss at epoch (1333):  0.031507112\n",
      "Train loss at epoch (1334):  0.05452704\n",
      "Test loss at epoch (1334):  0.03152813\n",
      "Train loss at epoch (1335):  0.054386515\n",
      "Test loss at epoch (1335):  0.03153756\n",
      "Train loss at epoch (1336):  0.05445549\n",
      "Test loss at epoch (1336):  0.031533394\n",
      "Train loss at epoch (1337):  0.05464519\n",
      "Test loss at epoch (1337):  0.03153655\n",
      "Train loss at epoch (1338):  0.054586075\n",
      "Test loss at epoch (1338):  0.031520393\n",
      "Train loss at epoch (1339):  0.054777026\n",
      "Test loss at epoch (1339):  0.031493317\n",
      "Train loss at epoch (1340):  0.054494508\n",
      "Test loss at epoch (1340):  0.031500325\n",
      "Train loss at epoch (1341):  0.054633394\n",
      "Test loss at epoch (1341):  0.031491693\n",
      "Train loss at epoch (1342):  0.05463477\n",
      "Test loss at epoch (1342):  0.03149533\n",
      "Train loss at epoch (1343):  0.05457093\n",
      "Test loss at epoch (1343):  0.03151931\n",
      "Train loss at epoch (1344):  0.05461844\n",
      "Test loss at epoch (1344):  0.031478345\n",
      "Train loss at epoch (1345):  0.054868273\n",
      "Test loss at epoch (1345):  0.031502716\n",
      "Train loss at epoch (1346):  0.054755975\n",
      "Test loss at epoch (1346):  0.031507503\n",
      "Train loss at epoch (1347):  0.05458484\n",
      "Test loss at epoch (1347):  0.03151842\n",
      "Train loss at epoch (1348):  0.054792766\n",
      "Test loss at epoch (1348):  0.031482104\n",
      "Train loss at epoch (1349):  0.0544579\n",
      "Test loss at epoch (1349):  0.03148521\n",
      "Train loss at epoch (1350):  0.05448775\n",
      "Test loss at epoch (1350):  0.031494066\n",
      "Train loss at epoch (1351):  0.054550007\n",
      "Test loss at epoch (1351):  0.03150394\n",
      "Train loss at epoch (1352):  0.054250844\n",
      "Test loss at epoch (1352):  0.031525914\n",
      "Train loss at epoch (1353):  0.054412894\n",
      "Test loss at epoch (1353):  0.031510927\n",
      "Train loss at epoch (1354):  0.05446471\n",
      "Test loss at epoch (1354):  0.031487316\n",
      "Train loss at epoch (1355):  0.054302942\n",
      "Test loss at epoch (1355):  0.031490423\n",
      "Train loss at epoch (1356):  0.054740727\n",
      "Test loss at epoch (1356):  0.03146042\n",
      "Train loss at epoch (1357):  0.054725\n",
      "Test loss at epoch (1357):  0.03146946\n",
      "Train loss at epoch (1358):  0.05454092\n",
      "Test loss at epoch (1358):  0.031474683\n",
      "Train loss at epoch (1359):  0.054587103\n",
      "Test loss at epoch (1359):  0.03145756\n",
      "Train loss at epoch (1360):  0.054585163\n",
      "Test loss at epoch (1360):  0.031473447\n",
      "Train loss at epoch (1361):  0.05456972\n",
      "Test loss at epoch (1361):  0.03148076\n",
      "Train loss at epoch (1362):  0.05462336\n",
      "Test loss at epoch (1362):  0.03147043\n",
      "Train loss at epoch (1363):  0.054560084\n",
      "Test loss at epoch (1363):  0.031508647\n",
      "Train loss at epoch (1364):  0.054459322\n",
      "Test loss at epoch (1364):  0.03149029\n",
      "Train loss at epoch (1365):  0.054801617\n",
      "Test loss at epoch (1365):  0.031496298\n",
      "Train loss at epoch (1366):  0.0547571\n",
      "Test loss at epoch (1366):  0.031494975\n",
      "Train loss at epoch (1367):  0.054779954\n",
      "Test loss at epoch (1367):  0.03147599\n",
      "Train loss at epoch (1368):  0.054800022\n",
      "Test loss at epoch (1368):  0.031507146\n",
      "Train loss at epoch (1369):  0.054594804\n",
      "Test loss at epoch (1369):  0.031494234\n",
      "Train loss at epoch (1370):  0.054765645\n",
      "Test loss at epoch (1370):  0.03149361\n",
      "Train loss at epoch (1371):  0.05451598\n",
      "Test loss at epoch (1371):  0.03149549\n",
      "Train loss at epoch (1372):  0.054545645\n",
      "Test loss at epoch (1372):  0.031493768\n",
      "Train loss at epoch (1373):  0.054784548\n",
      "Test loss at epoch (1373):  0.03150902\n",
      "Train loss at epoch (1374):  0.054667447\n",
      "Test loss at epoch (1374):  0.03149736\n",
      "Train loss at epoch (1375):  0.054665294\n",
      "Test loss at epoch (1375):  0.031501837\n",
      "Train loss at epoch (1376):  0.05422324\n",
      "Test loss at epoch (1376):  0.03149101\n",
      "Train loss at epoch (1377):  0.054800097\n",
      "Test loss at epoch (1377):  0.031502362\n",
      "Train loss at epoch (1378):  0.054658294\n",
      "Test loss at epoch (1378):  0.03150836\n",
      "Train loss at epoch (1379):  0.054803714\n",
      "Test loss at epoch (1379):  0.03149468\n",
      "Train loss at epoch (1380):  0.054503106\n",
      "Test loss at epoch (1380):  0.03147584\n",
      "Train loss at epoch (1381):  0.054529622\n",
      "Test loss at epoch (1381):  0.031465758\n",
      "Train loss at epoch (1382):  0.054368738\n",
      "Test loss at epoch (1382):  0.031503785\n",
      "Train loss at epoch (1383):  0.05465995\n",
      "Test loss at epoch (1383):  0.03150478\n",
      "Train loss at epoch (1384):  0.05452084\n",
      "Test loss at epoch (1384):  0.031499404\n",
      "Train loss at epoch (1385):  0.054709237\n",
      "Test loss at epoch (1385):  0.031507857\n",
      "Train loss at epoch (1386):  0.054709345\n",
      "Test loss at epoch (1386):  0.031509288\n",
      "Train loss at epoch (1387):  0.054294575\n",
      "Test loss at epoch (1387):  0.03148337\n",
      "Train loss at epoch (1388):  0.054706287\n",
      "Test loss at epoch (1388):  0.0314835\n",
      "Train loss at epoch (1389):  0.05454962\n",
      "Test loss at epoch (1389):  0.031493906\n",
      "Train loss at epoch (1390):  0.054498617\n",
      "Test loss at epoch (1390):  0.03147739\n",
      "Train loss at epoch (1391):  0.054908957\n",
      "Test loss at epoch (1391):  0.03147523\n",
      "Train loss at epoch (1392):  0.054647356\n",
      "Test loss at epoch (1392):  0.03150026\n",
      "Train loss at epoch (1393):  0.054497384\n",
      "Test loss at epoch (1393):  0.031493075\n",
      "Train loss at epoch (1394):  0.054737568\n",
      "Test loss at epoch (1394):  0.031484064\n",
      "Train loss at epoch (1395):  0.05471093\n",
      "Test loss at epoch (1395):  0.031486224\n",
      "Train loss at epoch (1396):  0.054446626\n",
      "Test loss at epoch (1396):  0.031499\n",
      "Train loss at epoch (1397):  0.05480921\n",
      "Test loss at epoch (1397):  0.031483978\n",
      "Train loss at epoch (1398):  0.0543666\n",
      "Test loss at epoch (1398):  0.031467\n",
      "Train loss at epoch (1399):  0.054652285\n",
      "Test loss at epoch (1399):  0.0314767\n",
      "Train loss at epoch (1400):  0.054288432\n",
      "Test loss at epoch (1400):  0.031496342\n",
      "Train loss at epoch (1401):  0.05462445\n",
      "Test loss at epoch (1401):  0.031478744\n",
      "Train loss at epoch (1402):  0.054900475\n",
      "Test loss at epoch (1402):  0.031491112\n",
      "Train loss at epoch (1403):  0.05428181\n",
      "Test loss at epoch (1403):  0.031488977\n",
      "Train loss at epoch (1404):  0.05451197\n",
      "Test loss at epoch (1404):  0.03147254\n",
      "Train loss at epoch (1405):  0.05444556\n",
      "Test loss at epoch (1405):  0.03147669\n",
      "Train loss at epoch (1406):  0.05446552\n",
      "Test loss at epoch (1406):  0.03145654\n",
      "Train loss at epoch (1407):  0.054421045\n",
      "Test loss at epoch (1407):  0.031467855\n",
      "Train loss at epoch (1408):  0.054324985\n",
      "Test loss at epoch (1408):  0.03144874\n",
      "Train loss at epoch (1409):  0.05454121\n",
      "Test loss at epoch (1409):  0.03145738\n",
      "Train loss at epoch (1410):  0.0543072\n",
      "Test loss at epoch (1410):  0.031458102\n",
      "Train loss at epoch (1411):  0.054698963\n",
      "Test loss at epoch (1411):  0.031467047\n",
      "Train loss at epoch (1412):  0.054443404\n",
      "Test loss at epoch (1412):  0.03146526\n",
      "Train loss at epoch (1413):  0.054623242\n",
      "Test loss at epoch (1413):  0.031461447\n",
      "Train loss at epoch (1414):  0.054583937\n",
      "Test loss at epoch (1414):  0.031469367\n",
      "Train loss at epoch (1415):  0.054876257\n",
      "Test loss at epoch (1415):  0.031476665\n",
      "Train loss at epoch (1416):  0.054698955\n",
      "Test loss at epoch (1416):  0.031465303\n",
      "Train loss at epoch (1417):  0.054259498\n",
      "Test loss at epoch (1417):  0.031463392\n",
      "Train loss at epoch (1418):  0.054532304\n",
      "Test loss at epoch (1418):  0.031472772\n",
      "Train loss at epoch (1419):  0.05493202\n",
      "Test loss at epoch (1419):  0.031487253\n",
      "Train loss at epoch (1420):  0.054342784\n",
      "Test loss at epoch (1420):  0.03147903\n",
      "Train loss at epoch (1421):  0.05453165\n",
      "Test loss at epoch (1421):  0.031484276\n",
      "Train loss at epoch (1422):  0.05446343\n",
      "Test loss at epoch (1422):  0.031475045\n",
      "Train loss at epoch (1423):  0.05441803\n",
      "Test loss at epoch (1423):  0.031462774\n",
      "Train loss at epoch (1424):  0.054391544\n",
      "Test loss at epoch (1424):  0.03148815\n",
      "Train loss at epoch (1425):  0.054530703\n",
      "Test loss at epoch (1425):  0.031478237\n",
      "Train loss at epoch (1426):  0.05481281\n",
      "Test loss at epoch (1426):  0.03148899\n",
      "Train loss at epoch (1427):  0.05441485\n",
      "Test loss at epoch (1427):  0.031489562\n",
      "Train loss at epoch (1428):  0.054400697\n",
      "Test loss at epoch (1428):  0.03148063\n",
      "Train loss at epoch (1429):  0.05469172\n",
      "Test loss at epoch (1429):  0.03148646\n",
      "Train loss at epoch (1430):  0.054679617\n",
      "Test loss at epoch (1430):  0.031487525\n",
      "Train loss at epoch (1431):  0.054549668\n",
      "Test loss at epoch (1431):  0.031486735\n",
      "Train loss at epoch (1432):  0.05463898\n",
      "Test loss at epoch (1432):  0.031481337\n",
      "Train loss at epoch (1433):  0.054692727\n",
      "Test loss at epoch (1433):  0.031470507\n",
      "Train loss at epoch (1434):  0.054794166\n",
      "Test loss at epoch (1434):  0.031475835\n",
      "Train loss at epoch (1435):  0.054734502\n",
      "Test loss at epoch (1435):  0.031479258\n",
      "Train loss at epoch (1436):  0.054641094\n",
      "Test loss at epoch (1436):  0.03147439\n",
      "Train loss at epoch (1437):  0.05462694\n",
      "Test loss at epoch (1437):  0.031467542\n",
      "Train loss at epoch (1438):  0.054809887\n",
      "Test loss at epoch (1438):  0.031474154\n",
      "Train loss at epoch (1439):  0.05450711\n",
      "Test loss at epoch (1439):  0.03148086\n",
      "Train loss at epoch (1440):  0.054389052\n",
      "Test loss at epoch (1440):  0.031476468\n",
      "Train loss at epoch (1441):  0.054556333\n",
      "Test loss at epoch (1441):  0.031493075\n",
      "Train loss at epoch (1442):  0.05467179\n",
      "Test loss at epoch (1442):  0.03148396\n",
      "Train loss at epoch (1443):  0.054392554\n",
      "Test loss at epoch (1443):  0.031482507\n",
      "Train loss at epoch (1444):  0.05456641\n",
      "Test loss at epoch (1444):  0.031486873\n",
      "Train loss at epoch (1445):  0.05472508\n",
      "Test loss at epoch (1445):  0.031480864\n",
      "Train loss at epoch (1446):  0.05471405\n",
      "Test loss at epoch (1446):  0.031473957\n",
      "Train loss at epoch (1447):  0.054321583\n",
      "Test loss at epoch (1447):  0.031476043\n",
      "Train loss at epoch (1448):  0.054704614\n",
      "Test loss at epoch (1448):  0.031469997\n",
      "Train loss at epoch (1449):  0.054492943\n",
      "Test loss at epoch (1449):  0.031480424\n",
      "Train loss at epoch (1450):  0.05466336\n",
      "Test loss at epoch (1450):  0.03148266\n",
      "Train loss at epoch (1451):  0.054440938\n",
      "Test loss at epoch (1451):  0.03147646\n",
      "Train loss at epoch (1452):  0.055090938\n",
      "Test loss at epoch (1452):  0.031468563\n",
      "Train loss at epoch (1453):  0.054521885\n",
      "Test loss at epoch (1453):  0.031482924\n",
      "Train loss at epoch (1454):  0.054398995\n",
      "Test loss at epoch (1454):  0.03147089\n",
      "Train loss at epoch (1455):  0.05462785\n",
      "Test loss at epoch (1455):  0.031474285\n",
      "Train loss at epoch (1456):  0.054562688\n",
      "Test loss at epoch (1456):  0.031480107\n",
      "Train loss at epoch (1457):  0.05463892\n",
      "Test loss at epoch (1457):  0.0314667\n",
      "Train loss at epoch (1458):  0.054483756\n",
      "Test loss at epoch (1458):  0.031465244\n",
      "Train loss at epoch (1459):  0.054641284\n",
      "Test loss at epoch (1459):  0.03146516\n",
      "Train loss at epoch (1460):  0.054741975\n",
      "Test loss at epoch (1460):  0.031470824\n",
      "Train loss at epoch (1461):  0.054492034\n",
      "Test loss at epoch (1461):  0.031472016\n",
      "Train loss at epoch (1462):  0.054660294\n",
      "Test loss at epoch (1462):  0.031460285\n",
      "Train loss at epoch (1463):  0.054629903\n",
      "Test loss at epoch (1463):  0.03147558\n",
      "Train loss at epoch (1464):  0.054574825\n",
      "Test loss at epoch (1464):  0.031468663\n",
      "Train loss at epoch (1465):  0.05469809\n",
      "Test loss at epoch (1465):  0.03146892\n",
      "Train loss at epoch (1466):  0.054652017\n",
      "Test loss at epoch (1466):  0.031473022\n",
      "Train loss at epoch (1467):  0.054793324\n",
      "Test loss at epoch (1467):  0.03147267\n",
      "Train loss at epoch (1468):  0.05443715\n",
      "Test loss at epoch (1468):  0.031469792\n",
      "Train loss at epoch (1469):  0.054551635\n",
      "Test loss at epoch (1469):  0.031475954\n",
      "Train loss at epoch (1470):  0.054509386\n",
      "Test loss at epoch (1470):  0.03148048\n",
      "Train loss at epoch (1471):  0.05444226\n",
      "Test loss at epoch (1471):  0.031481408\n",
      "Train loss at epoch (1472):  0.05469089\n",
      "Test loss at epoch (1472):  0.031483714\n",
      "Train loss at epoch (1473):  0.054568436\n",
      "Test loss at epoch (1473):  0.03148076\n",
      "Train loss at epoch (1474):  0.05464741\n",
      "Test loss at epoch (1474):  0.03147501\n",
      "Train loss at epoch (1475):  0.054625932\n",
      "Test loss at epoch (1475):  0.031477425\n",
      "Train loss at epoch (1476):  0.054128043\n",
      "Test loss at epoch (1476):  0.031473506\n",
      "Train loss at epoch (1477):  0.054429907\n",
      "Test loss at epoch (1477):  0.03147266\n",
      "Train loss at epoch (1478):  0.05490458\n",
      "Test loss at epoch (1478):  0.03147094\n",
      "Train loss at epoch (1479):  0.054421913\n",
      "Test loss at epoch (1479):  0.031472534\n",
      "Train loss at epoch (1480):  0.054445133\n",
      "Test loss at epoch (1480):  0.031468604\n",
      "Train loss at epoch (1481):  0.0544288\n",
      "Test loss at epoch (1481):  0.03147907\n",
      "Train loss at epoch (1482):  0.05449375\n",
      "Test loss at epoch (1482):  0.031478167\n",
      "Train loss at epoch (1483):  0.054506835\n",
      "Test loss at epoch (1483):  0.03147633\n",
      "Train loss at epoch (1484):  0.05446739\n",
      "Test loss at epoch (1484):  0.031481773\n",
      "Train loss at epoch (1485):  0.05454417\n",
      "Test loss at epoch (1485):  0.031470552\n",
      "Train loss at epoch (1486):  0.05441868\n",
      "Test loss at epoch (1486):  0.031487707\n",
      "Train loss at epoch (1487):  0.05437761\n",
      "Test loss at epoch (1487):  0.031472553\n",
      "Train loss at epoch (1488):  0.054579787\n",
      "Test loss at epoch (1488):  0.03146441\n",
      "Train loss at epoch (1489):  0.05464194\n",
      "Test loss at epoch (1489):  0.03148229\n",
      "Train loss at epoch (1490):  0.05449387\n",
      "Test loss at epoch (1490):  0.031477507\n",
      "Train loss at epoch (1491):  0.054317392\n",
      "Test loss at epoch (1491):  0.031465124\n",
      "Train loss at epoch (1492):  0.054607365\n",
      "Test loss at epoch (1492):  0.031479698\n",
      "Train loss at epoch (1493):  0.054773457\n",
      "Test loss at epoch (1493):  0.03147703\n",
      "Train loss at epoch (1494):  0.054456763\n",
      "Test loss at epoch (1494):  0.031480487\n",
      "Train loss at epoch (1495):  0.05415257\n",
      "Test loss at epoch (1495):  0.03147623\n",
      "Train loss at epoch (1496):  0.054875184\n",
      "Test loss at epoch (1496):  0.03146605\n",
      "Train loss at epoch (1497):  0.05429156\n",
      "Test loss at epoch (1497):  0.031467136\n",
      "Train loss at epoch (1498):  0.05439979\n",
      "Test loss at epoch (1498):  0.031470228\n",
      "Train loss at epoch (1499):  0.05453612\n",
      "Test loss at epoch (1499):  0.03147262\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "EPOCHS = 1500\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=16, shuffle=True)\n",
    "decoder = TransformerDecoder(cfg)\n",
    "optimizer = SGD(decoder.parameters(), lr=1e-4, momentum=0.9)\n",
    "lr_scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "trainer = Trainer(\n",
    "    train_data_loader=train_data_loader,\n",
    "    test_data_loader=test_data_loader,\n",
    "    # optimizer=AdamW(decoder.parameters(), lr=1e-5),\n",
    "    optimizer=optimizer,\n",
    "    model=decoder,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    epochs=EPOCHS\n",
    ")\n",
    "\n",
    "trainer.train(loss_fn=nn.L1Loss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_sample, y_sample = test_dataset[np.random.randint(0, TEST_SIZE)]\n",
    "predictions = decoder.predict(x_sample.unsqueeze(0)[:, :SOURCE_SEQ_LEN, :], TARGET_SEQ_LEN)\n",
    "labels = torch.cat((x_sample, y_sample[-1:]))\n",
    "\n",
    "plot_circle(\n",
    "    input=labels.detach().numpy()[0:],\n",
    "    prediction=torch.cat((labels[0:SOURCE_SEQ_LEN, :], predictions[0])).detach().numpy()[0:],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
