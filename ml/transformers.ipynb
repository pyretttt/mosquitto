{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW, Optimizer, SGD\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from scratchers.vanilla_transformer.attn import Attention, MultiheadAttention\n",
    "from scratchers.vanilla_transformer.transformer import TransformerBlock, TransformerDecoder\n",
    "from scratchers.transformer_config import TransformerConfig\n",
    "from scratchers.transformer.attn import Attention as CachedAttention\n",
    "from scratchers.transformer.transformer import TransformerDecoder as CachedTransformerDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'scratchers' (namespace) from ['/Users/s-a-bakulin/mosquitto/ml/scratchers']>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scratchers\n",
    "importlib.reload(scratchers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_SEQ_LEN = 12\n",
    "TARGET_SEQ_LEN = 12\n",
    "\n",
    "DATA_SIZE = 1500\n",
    "TRAIN_SIZE = int(DATA_SIZE * 0.8)\n",
    "TEST_SIZE = DATA_SIZE - TRAIN_SIZE\n",
    "\n",
    "# radii = np.random.ranf((DATA_SIZE)) # * 9 + 1\n",
    "radii = np.ones((DATA_SIZE))\n",
    "starting_radian = np.random.ranf((DATA_SIZE)) * 2 * np.pi\n",
    "directions = np.random.randint(2, size=DATA_SIZE) * 2 - 1\n",
    "\n",
    "def to_cartesian(\n",
    "    radius: float,\n",
    "    start_radian: float, \n",
    "    direction: int\n",
    "):\n",
    "    delta = 2 * np.pi / (SOURCE_SEQ_LEN + TARGET_SEQ_LEN)\n",
    "    seq = np.array([\n",
    "        np.array([\n",
    "            radius * np.cos(start_radian + (i * direction * delta)),\n",
    "            radius * np.sin(start_radian + (i * direction * delta))\n",
    "        ])\n",
    "        for i in range(SOURCE_SEQ_LEN + TARGET_SEQ_LEN)\n",
    "    ])\n",
    "    source_seq = seq[:-1]\n",
    "    target_seq = seq[1:]\n",
    "    return source_seq, target_seq\n",
    "\n",
    "def make_circles_data():\n",
    "    X = np.empty((DATA_SIZE, (SOURCE_SEQ_LEN + TARGET_SEQ_LEN) - 1, 2))\n",
    "    Y = np.empty((DATA_SIZE, (SOURCE_SEQ_LEN + TARGET_SEQ_LEN) - 1, 2))\n",
    "    for idx, (radius, start_radian, direction) in enumerate(zip(radii, starting_radian, directions)):\n",
    "        x, y = to_cartesian(radius, start_radian, direction)\n",
    "        X[idx, :, :] = x\n",
    "        Y[idx, :, :] = y\n",
    "\n",
    "    return (\n",
    "        torch.from_numpy(X[:TRAIN_SIZE]).float(), \n",
    "        torch.from_numpy(Y[:TRAIN_SIZE]).float(),\n",
    "        torch.from_numpy(X[TRAIN_SIZE:]).float(), \n",
    "        torch.from_numpy(Y[TRAIN_SIZE:]).float()\n",
    "    )\n",
    "\n",
    "def make_squares_data():\n",
    "    X = np.empty((DATA_SIZE, (2 + 2) - 1, 2))\n",
    "    Y = np.empty((DATA_SIZE, (2 + 2) - 1, 2))\n",
    "\n",
    "    def map(elements):\n",
    "        res = []\n",
    "        for element in elements:\n",
    "            if element == 0:\n",
    "                res.append(np.array([-1, -1]))\n",
    "            elif element == 1:\n",
    "                res.append(np.array([1, -1]))\n",
    "            elif element == 2:\n",
    "                res.append(np.array([1, 1]))\n",
    "            elif element == 3:\n",
    "                res.append(np.array([-1, 1]))\n",
    "\n",
    "        return np.array(res)\n",
    "\n",
    "    first = np.random.randint(0, 4, size=(DATA_SIZE))\n",
    "    second = (first + 1) % 4\n",
    "    third = (second + 1) % 4\n",
    "    fourth = (third + 1) % 4\n",
    "    first = map(first)\n",
    "    second = map(second)\n",
    "    third = map(third)\n",
    "    fourth = map(fourth)\n",
    "\n",
    "    X[:, 0, :] = first\n",
    "    X[:, 1, :] = second\n",
    "    X[:, 2, :] = third\n",
    "    Y[:, 0, :] = second\n",
    "    Y[:, 1, :] = third\n",
    "    Y[:, 2, :] = fourth\n",
    "\n",
    "    return (\n",
    "        torch.from_numpy(X[:TRAIN_SIZE]).float(), \n",
    "        torch.from_numpy(Y[:TRAIN_SIZE]).float(),\n",
    "        torch.from_numpy(X[TRAIN_SIZE:]).float(), \n",
    "        torch.from_numpy(Y[TRAIN_SIZE:]).float()\n",
    "    )\n",
    "\n",
    "\n",
    "X_train, y_train, X_test, y_test = make_circles_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_circle(input, prediction, figsize=(6, 6)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(input)))\n",
    "    plt.scatter(\n",
    "        input[:, 0], input[:, 1], label=\"input\", marker=\"*\", s=250, alpha=0.5, color=colors\n",
    "    )\n",
    "    plt.scatter(prediction[:, 0], prediction[:, 1], label=\"prediction\", color=colors)\n",
    "    plt.legend()\n",
    "\n",
    "plot_circle(X_train[4], y_train[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = TransformerConfig(\n",
    "    input_size=2,\n",
    "    attn_d_k=32,\n",
    "    transformer_proj_dim=64,\n",
    "    dropout=0.2,\n",
    "    nlayers=2,\n",
    "    is_self_attn=False,\n",
    "    max_seq_len=TARGET_SEQ_LEN + SOURCE_SEQ_LEN,\n",
    "    nheads=2,\n",
    "    pre_layer_norm=True,\n",
    "    use_cache=True\n",
    ")\n",
    "\n",
    "def attn_factory(config: TransformerConfig):\n",
    "    return Attention(\n",
    "        d_k=config.attn_d_k,\n",
    "        # nheads=config.nheads,\n",
    "        is_self_attn=config.is_self_attn,\n",
    "        dropout=config.dropout\n",
    "    )\n",
    "\n",
    "def caching_attn_factory(config: TransformerConfig):\n",
    "    return CachedAttention(\n",
    "        d_k=config.attn_d_k,\n",
    "        dropout=config.dropout\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_data_loader: DataLoader,\n",
    "        test_data_loader: DataLoader,\n",
    "        optimizer: Optimizer,\n",
    "        model: nn.Module,\n",
    "        lr_scheduler = None,\n",
    "        epochs: int = 10,\n",
    "    ):\n",
    "        self.train_data_loader = train_data_loader\n",
    "        self.test_data_loader = test_data_loader\n",
    "        self.optimizer = optimizer\n",
    "        self.model = model\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def train(self, loss_fn: callable):\n",
    "        for epoch in range(self.epochs):\n",
    "            losses = []\n",
    "            self.model.train()\n",
    "            for x_batch, y_batch in self.train_data_loader:\n",
    "                out = self.model(x_batch)\n",
    "                loss = loss_fn(out, y_batch)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                losses.append(loss.detach().cpu().numpy())\n",
    "\n",
    "            if self.lr_scheduler is not None:\n",
    "                self.lr_scheduler.step()\n",
    "\n",
    "            print(f\"Train loss at epoch ({epoch}): \", np.array(losses).mean())\n",
    "\n",
    "            with torch.no_grad():\n",
    "                self.model.eval()\n",
    "                test_losses = []\n",
    "                for x_batch, y_batch in self.test_data_loader:\n",
    "                    out = self.model(x_batch)\n",
    "                    loss = loss_fn(out, y_batch)\n",
    "                    test_losses.append(loss.detach().cpu().numpy())\n",
    "\n",
    "                print(f\"Test loss at epoch ({epoch}): \", np.array(test_losses).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "EPOCHS = 1500\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=16, shuffle=True)\n",
    "decoder = TransformerDecoder(cfg, attn_factory)\n",
    "optimizer = SGD(decoder.parameters(), lr=1e-4, momentum=0.9)\n",
    "lr_scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "trainer = Trainer(\n",
    "    train_data_loader=train_data_loader,\n",
    "    test_data_loader=test_data_loader,\n",
    "    # optimizer=AdamW(decoder.parameters(), lr=1e-5),\n",
    "    optimizer=optimizer,\n",
    "    model=decoder,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    epochs=EPOCHS\n",
    ")\n",
    "\n",
    "# trainer.train(loss_fn=nn.L1Loss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at epoch (0):  0.72251946\n",
      "Test loss at epoch (0):  0.61641324\n",
      "Train loss at epoch (1):  0.5616314\n",
      "Test loss at epoch (1):  0.48370397\n",
      "Train loss at epoch (2):  0.451972\n",
      "Test loss at epoch (2):  0.38260365\n",
      "Train loss at epoch (3):  0.37542135\n",
      "Test loss at epoch (3):  0.31361064\n",
      "Train loss at epoch (4):  0.32571858\n",
      "Test loss at epoch (4):  0.27149117\n",
      "Train loss at epoch (5):  0.29638687\n",
      "Test loss at epoch (5):  0.24568234\n",
      "Train loss at epoch (6):  0.2776189\n",
      "Test loss at epoch (6):  0.22882755\n",
      "Train loss at epoch (7):  0.26447824\n",
      "Test loss at epoch (7):  0.21642952\n",
      "Train loss at epoch (8):  0.2542866\n",
      "Test loss at epoch (8):  0.20664339\n",
      "Train loss at epoch (9):  0.24454743\n",
      "Test loss at epoch (9):  0.19823301\n",
      "Train loss at epoch (10):  0.23535153\n",
      "Test loss at epoch (10):  0.19106942\n",
      "Train loss at epoch (11):  0.22842552\n",
      "Test loss at epoch (11):  0.18448481\n",
      "Train loss at epoch (12):  0.22228202\n",
      "Test loss at epoch (12):  0.17865519\n",
      "Train loss at epoch (13):  0.21649452\n",
      "Test loss at epoch (13):  0.17377357\n",
      "Train loss at epoch (14):  0.21023366\n",
      "Test loss at epoch (14):  0.16915974\n",
      "Train loss at epoch (15):  0.20488763\n",
      "Test loss at epoch (15):  0.16521287\n",
      "Train loss at epoch (16):  0.20067333\n",
      "Test loss at epoch (16):  0.16169634\n",
      "Train loss at epoch (17):  0.19719936\n",
      "Test loss at epoch (17):  0.15854657\n",
      "Train loss at epoch (18):  0.19322306\n",
      "Test loss at epoch (18):  0.15570898\n",
      "Train loss at epoch (19):  0.18967815\n",
      "Test loss at epoch (19):  0.1529795\n",
      "Train loss at epoch (20):  0.18768555\n",
      "Test loss at epoch (20):  0.15058242\n",
      "Train loss at epoch (21):  0.18532108\n",
      "Test loss at epoch (21):  0.14860648\n",
      "Train loss at epoch (22):  0.18157561\n",
      "Test loss at epoch (22):  0.14685021\n",
      "Train loss at epoch (23):  0.17905104\n",
      "Test loss at epoch (23):  0.14504658\n",
      "Train loss at epoch (24):  0.17668562\n",
      "Test loss at epoch (24):  0.14332657\n",
      "Train loss at epoch (25):  0.1750816\n",
      "Test loss at epoch (25):  0.14186758\n",
      "Train loss at epoch (26):  0.17306757\n",
      "Test loss at epoch (26):  0.140411\n",
      "Train loss at epoch (27):  0.17129989\n",
      "Test loss at epoch (27):  0.13913293\n",
      "Train loss at epoch (28):  0.17047565\n",
      "Test loss at epoch (28):  0.13805358\n",
      "Train loss at epoch (29):  0.16877413\n",
      "Test loss at epoch (29):  0.13689756\n",
      "Train loss at epoch (30):  0.16624048\n",
      "Test loss at epoch (30):  0.13598591\n",
      "Train loss at epoch (31):  0.16542026\n",
      "Test loss at epoch (31):  0.13517253\n",
      "Train loss at epoch (32):  0.16446361\n",
      "Test loss at epoch (32):  0.13414747\n",
      "Train loss at epoch (33):  0.16318789\n",
      "Test loss at epoch (33):  0.13325788\n",
      "Train loss at epoch (34):  0.16174957\n",
      "Test loss at epoch (34):  0.13255472\n",
      "Train loss at epoch (35):  0.16160613\n",
      "Test loss at epoch (35):  0.13172255\n",
      "Train loss at epoch (36):  0.15879458\n",
      "Test loss at epoch (36):  0.13086385\n",
      "Train loss at epoch (37):  0.15845989\n",
      "Test loss at epoch (37):  0.13024843\n",
      "Train loss at epoch (38):  0.1576427\n",
      "Test loss at epoch (38):  0.12937824\n",
      "Train loss at epoch (39):  0.15700339\n",
      "Test loss at epoch (39):  0.12896673\n",
      "Train loss at epoch (40):  0.15554032\n",
      "Test loss at epoch (40):  0.12829368\n",
      "Train loss at epoch (41):  0.15437719\n",
      "Test loss at epoch (41):  0.12747079\n",
      "Train loss at epoch (42):  0.1536733\n",
      "Test loss at epoch (42):  0.12702645\n",
      "Train loss at epoch (43):  0.15310222\n",
      "Test loss at epoch (43):  0.12620072\n",
      "Train loss at epoch (44):  0.1519005\n",
      "Test loss at epoch (44):  0.12567095\n",
      "Train loss at epoch (45):  0.15110108\n",
      "Test loss at epoch (45):  0.12508914\n",
      "Train loss at epoch (46):  0.1503424\n",
      "Test loss at epoch (46):  0.12458277\n",
      "Train loss at epoch (47):  0.14940222\n",
      "Test loss at epoch (47):  0.12388376\n",
      "Train loss at epoch (48):  0.14919242\n",
      "Test loss at epoch (48):  0.12325472\n",
      "Train loss at epoch (49):  0.1476959\n",
      "Test loss at epoch (49):  0.122744925\n",
      "Train loss at epoch (50):  0.14677508\n",
      "Test loss at epoch (50):  0.122380316\n",
      "Train loss at epoch (51):  0.14672846\n",
      "Test loss at epoch (51):  0.12178391\n",
      "Train loss at epoch (52):  0.14667454\n",
      "Test loss at epoch (52):  0.12138767\n",
      "Train loss at epoch (53):  0.14469966\n",
      "Test loss at epoch (53):  0.12074792\n",
      "Train loss at epoch (54):  0.14396234\n",
      "Test loss at epoch (54):  0.1201594\n",
      "Train loss at epoch (55):  0.14353947\n",
      "Test loss at epoch (55):  0.11953911\n",
      "Train loss at epoch (56):  0.14337766\n",
      "Test loss at epoch (56):  0.11894466\n",
      "Train loss at epoch (57):  0.1420436\n",
      "Test loss at epoch (57):  0.11861323\n",
      "Train loss at epoch (58):  0.14166047\n",
      "Test loss at epoch (58):  0.11785597\n",
      "Train loss at epoch (59):  0.14166223\n",
      "Test loss at epoch (59):  0.11725978\n",
      "Train loss at epoch (60):  0.1400486\n",
      "Test loss at epoch (60):  0.116996504\n",
      "Train loss at epoch (61):  0.13959259\n",
      "Test loss at epoch (61):  0.11640491\n",
      "Train loss at epoch (62):  0.13975476\n",
      "Test loss at epoch (62):  0.11614926\n",
      "Train loss at epoch (63):  0.13966215\n",
      "Test loss at epoch (63):  0.115565866\n",
      "Train loss at epoch (64):  0.13886435\n",
      "Test loss at epoch (64):  0.1151502\n",
      "Train loss at epoch (65):  0.13741386\n",
      "Test loss at epoch (65):  0.114379644\n",
      "Train loss at epoch (66):  0.1369503\n",
      "Test loss at epoch (66):  0.114141226\n",
      "Train loss at epoch (67):  0.13675925\n",
      "Test loss at epoch (67):  0.113593794\n",
      "Train loss at epoch (68):  0.13555567\n",
      "Test loss at epoch (68):  0.11311406\n",
      "Train loss at epoch (69):  0.1353517\n",
      "Test loss at epoch (69):  0.11258918\n",
      "Train loss at epoch (70):  0.13496612\n",
      "Test loss at epoch (70):  0.11211381\n",
      "Train loss at epoch (71):  0.13454764\n",
      "Test loss at epoch (71):  0.11166673\n",
      "Train loss at epoch (72):  0.13393027\n",
      "Test loss at epoch (72):  0.11124814\n",
      "Train loss at epoch (73):  0.13388807\n",
      "Test loss at epoch (73):  0.11074002\n",
      "Train loss at epoch (74):  0.1324057\n",
      "Test loss at epoch (74):  0.11025667\n",
      "Train loss at epoch (75):  0.1319908\n",
      "Test loss at epoch (75):  0.10979524\n",
      "Train loss at epoch (76):  0.13215633\n",
      "Test loss at epoch (76):  0.109259225\n",
      "Train loss at epoch (77):  0.13089612\n",
      "Test loss at epoch (77):  0.10893402\n",
      "Train loss at epoch (78):  0.13058531\n",
      "Test loss at epoch (78):  0.1085117\n",
      "Train loss at epoch (79):  0.129903\n",
      "Test loss at epoch (79):  0.108004235\n",
      "Train loss at epoch (80):  0.13093306\n",
      "Test loss at epoch (80):  0.107661836\n",
      "Train loss at epoch (81):  0.12931265\n",
      "Test loss at epoch (81):  0.10715167\n",
      "Train loss at epoch (82):  0.12846561\n",
      "Test loss at epoch (82):  0.1066789\n",
      "Train loss at epoch (83):  0.12839809\n",
      "Test loss at epoch (83):  0.10605713\n",
      "Train loss at epoch (84):  0.12811376\n",
      "Test loss at epoch (84):  0.105712436\n",
      "Train loss at epoch (85):  0.12794666\n",
      "Test loss at epoch (85):  0.10532806\n",
      "Train loss at epoch (86):  0.12766398\n",
      "Test loss at epoch (86):  0.10481096\n",
      "Train loss at epoch (87):  0.12618344\n",
      "Test loss at epoch (87):  0.1043183\n",
      "Train loss at epoch (88):  0.12658967\n",
      "Test loss at epoch (88):  0.103803225\n",
      "Train loss at epoch (89):  0.12565756\n",
      "Test loss at epoch (89):  0.10344226\n",
      "Train loss at epoch (90):  0.12513895\n",
      "Test loss at epoch (90):  0.102906846\n",
      "Train loss at epoch (91):  0.12503481\n",
      "Test loss at epoch (91):  0.10258268\n",
      "Train loss at epoch (92):  0.124691986\n",
      "Test loss at epoch (92):  0.10221573\n",
      "Train loss at epoch (93):  0.12372951\n",
      "Test loss at epoch (93):  0.10178153\n",
      "Train loss at epoch (94):  0.12383199\n",
      "Test loss at epoch (94):  0.101301454\n",
      "Train loss at epoch (95):  0.12306645\n",
      "Test loss at epoch (95):  0.100907676\n",
      "Train loss at epoch (96):  0.12365443\n",
      "Test loss at epoch (96):  0.100513704\n",
      "Train loss at epoch (97):  0.12305262\n",
      "Test loss at epoch (97):  0.100072004\n",
      "Train loss at epoch (98):  0.12205011\n",
      "Test loss at epoch (98):  0.09967337\n",
      "Train loss at epoch (99):  0.12137923\n",
      "Test loss at epoch (99):  0.099239886\n",
      "Train loss at epoch (100):  0.121092886\n",
      "Test loss at epoch (100):  0.09877184\n",
      "Train loss at epoch (101):  0.12084806\n",
      "Test loss at epoch (101):  0.09842044\n",
      "Train loss at epoch (102):  0.1201232\n",
      "Test loss at epoch (102):  0.098140724\n",
      "Train loss at epoch (103):  0.11987064\n",
      "Test loss at epoch (103):  0.0977806\n",
      "Train loss at epoch (104):  0.11957552\n",
      "Test loss at epoch (104):  0.097282745\n",
      "Train loss at epoch (105):  0.120060116\n",
      "Test loss at epoch (105):  0.096731864\n",
      "Train loss at epoch (106):  0.11896383\n",
      "Test loss at epoch (106):  0.09628448\n",
      "Train loss at epoch (107):  0.11880218\n",
      "Test loss at epoch (107):  0.0959363\n",
      "Train loss at epoch (108):  0.118213706\n",
      "Test loss at epoch (108):  0.09553863\n",
      "Train loss at epoch (109):  0.11787877\n",
      "Test loss at epoch (109):  0.0950215\n",
      "Train loss at epoch (110):  0.11765315\n",
      "Test loss at epoch (110):  0.09472238\n",
      "Train loss at epoch (111):  0.11795775\n",
      "Test loss at epoch (111):  0.09422417\n",
      "Train loss at epoch (112):  0.11666374\n",
      "Test loss at epoch (112):  0.09384491\n",
      "Train loss at epoch (113):  0.11690493\n",
      "Test loss at epoch (113):  0.09359213\n",
      "Train loss at epoch (114):  0.11599917\n",
      "Test loss at epoch (114):  0.09300414\n",
      "Train loss at epoch (115):  0.115496635\n",
      "Test loss at epoch (115):  0.09251192\n",
      "Train loss at epoch (116):  0.115811065\n",
      "Test loss at epoch (116):  0.09222984\n",
      "Train loss at epoch (117):  0.11558169\n",
      "Test loss at epoch (117):  0.09189004\n",
      "Train loss at epoch (118):  0.114995815\n",
      "Test loss at epoch (118):  0.091560826\n",
      "Train loss at epoch (119):  0.11423199\n",
      "Test loss at epoch (119):  0.09121074\n",
      "Train loss at epoch (120):  0.11474516\n",
      "Test loss at epoch (120):  0.09074321\n",
      "Train loss at epoch (121):  0.11403966\n",
      "Test loss at epoch (121):  0.090417966\n",
      "Train loss at epoch (122):  0.11331357\n",
      "Test loss at epoch (122):  0.08988939\n",
      "Train loss at epoch (123):  0.11321343\n",
      "Test loss at epoch (123):  0.089614026\n",
      "Train loss at epoch (124):  0.11333088\n",
      "Test loss at epoch (124):  0.089346744\n",
      "Train loss at epoch (125):  0.11269924\n",
      "Test loss at epoch (125):  0.08881155\n",
      "Train loss at epoch (126):  0.11210326\n",
      "Test loss at epoch (126):  0.088377185\n",
      "Train loss at epoch (127):  0.11167558\n",
      "Test loss at epoch (127):  0.088073485\n",
      "Train loss at epoch (128):  0.11149306\n",
      "Test loss at epoch (128):  0.087607704\n",
      "Train loss at epoch (129):  0.11103128\n",
      "Test loss at epoch (129):  0.08736151\n",
      "Train loss at epoch (130):  0.11138484\n",
      "Test loss at epoch (130):  0.08713507\n",
      "Train loss at epoch (131):  0.11081631\n",
      "Test loss at epoch (131):  0.08672589\n",
      "Train loss at epoch (132):  0.11076449\n",
      "Test loss at epoch (132):  0.0863567\n",
      "Train loss at epoch (133):  0.11029537\n",
      "Test loss at epoch (133):  0.086122\n",
      "Train loss at epoch (134):  0.11031601\n",
      "Test loss at epoch (134):  0.085752554\n",
      "Train loss at epoch (135):  0.10952301\n",
      "Test loss at epoch (135):  0.085220195\n",
      "Train loss at epoch (136):  0.10956631\n",
      "Test loss at epoch (136):  0.08498327\n",
      "Train loss at epoch (137):  0.10879443\n",
      "Test loss at epoch (137):  0.08454624\n",
      "Train loss at epoch (138):  0.10874991\n",
      "Test loss at epoch (138):  0.084273264\n",
      "Train loss at epoch (139):  0.10783043\n",
      "Test loss at epoch (139):  0.083837606\n",
      "Train loss at epoch (140):  0.10796275\n",
      "Test loss at epoch (140):  0.0835318\n",
      "Train loss at epoch (141):  0.10782152\n",
      "Test loss at epoch (141):  0.083206005\n",
      "Train loss at epoch (142):  0.10790605\n",
      "Test loss at epoch (142):  0.0829579\n",
      "Train loss at epoch (143):  0.10753248\n",
      "Test loss at epoch (143):  0.08242168\n",
      "Train loss at epoch (144):  0.107221514\n",
      "Test loss at epoch (144):  0.082145385\n",
      "Train loss at epoch (145):  0.10677652\n",
      "Test loss at epoch (145):  0.081811056\n",
      "Train loss at epoch (146):  0.10631247\n",
      "Test loss at epoch (146):  0.081729196\n",
      "Train loss at epoch (147):  0.10651256\n",
      "Test loss at epoch (147):  0.08108374\n",
      "Train loss at epoch (148):  0.106130324\n",
      "Test loss at epoch (148):  0.08070328\n",
      "Train loss at epoch (149):  0.10591725\n",
      "Test loss at epoch (149):  0.08067572\n",
      "Train loss at epoch (150):  0.10551913\n",
      "Test loss at epoch (150):  0.08008874\n",
      "Train loss at epoch (151):  0.105224304\n",
      "Test loss at epoch (151):  0.07973309\n",
      "Train loss at epoch (152):  0.10518847\n",
      "Test loss at epoch (152):  0.07934978\n",
      "Train loss at epoch (153):  0.10463745\n",
      "Test loss at epoch (153):  0.07915532\n",
      "Train loss at epoch (154):  0.10472563\n",
      "Test loss at epoch (154):  0.078841455\n",
      "Train loss at epoch (155):  0.10442658\n",
      "Test loss at epoch (155):  0.07847147\n",
      "Train loss at epoch (156):  0.104282714\n",
      "Test loss at epoch (156):  0.07823009\n",
      "Train loss at epoch (157):  0.1038222\n",
      "Test loss at epoch (157):  0.0780291\n",
      "Train loss at epoch (158):  0.10327825\n",
      "Test loss at epoch (158):  0.077564046\n",
      "Train loss at epoch (159):  0.10349857\n",
      "Test loss at epoch (159):  0.07725481\n",
      "Train loss at epoch (160):  0.10294533\n",
      "Test loss at epoch (160):  0.07710503\n",
      "Train loss at epoch (161):  0.10312766\n",
      "Test loss at epoch (161):  0.07656805\n",
      "Train loss at epoch (162):  0.10280524\n",
      "Test loss at epoch (162):  0.076337956\n",
      "Train loss at epoch (163):  0.10237115\n",
      "Test loss at epoch (163):  0.075945996\n",
      "Train loss at epoch (164):  0.10200832\n",
      "Test loss at epoch (164):  0.075819805\n",
      "Train loss at epoch (165):  0.10171572\n",
      "Test loss at epoch (165):  0.07537749\n",
      "Train loss at epoch (166):  0.101916805\n",
      "Test loss at epoch (166):  0.075119294\n",
      "Train loss at epoch (167):  0.10190362\n",
      "Test loss at epoch (167):  0.07487055\n",
      "Train loss at epoch (168):  0.10168319\n",
      "Test loss at epoch (168):  0.07450105\n",
      "Train loss at epoch (169):  0.10115225\n",
      "Test loss at epoch (169):  0.07434485\n",
      "Train loss at epoch (170):  0.101123616\n",
      "Test loss at epoch (170):  0.07397912\n",
      "Train loss at epoch (171):  0.10006876\n",
      "Test loss at epoch (171):  0.07388638\n",
      "Train loss at epoch (172):  0.10014842\n",
      "Test loss at epoch (172):  0.073514946\n",
      "Train loss at epoch (173):  0.10055862\n",
      "Test loss at epoch (173):  0.073374785\n",
      "Train loss at epoch (174):  0.099927634\n",
      "Test loss at epoch (174):  0.072984286\n",
      "Train loss at epoch (175):  0.09986616\n",
      "Test loss at epoch (175):  0.072771885\n",
      "Train loss at epoch (176):  0.09984724\n",
      "Test loss at epoch (176):  0.072446704\n",
      "Train loss at epoch (177):  0.09938059\n",
      "Test loss at epoch (177):  0.07210678\n",
      "Train loss at epoch (178):  0.098959945\n",
      "Test loss at epoch (178):  0.07182783\n",
      "Train loss at epoch (179):  0.09903794\n",
      "Test loss at epoch (179):  0.07155149\n",
      "Train loss at epoch (180):  0.09895625\n",
      "Test loss at epoch (180):  0.07133039\n",
      "Train loss at epoch (181):  0.09862954\n",
      "Test loss at epoch (181):  0.0709349\n",
      "Train loss at epoch (182):  0.09863369\n",
      "Test loss at epoch (182):  0.07096687\n",
      "Train loss at epoch (183):  0.098038785\n",
      "Test loss at epoch (183):  0.07078112\n",
      "Train loss at epoch (184):  0.09803773\n",
      "Test loss at epoch (184):  0.07043472\n",
      "Train loss at epoch (185):  0.098162636\n",
      "Test loss at epoch (185):  0.07014552\n",
      "Train loss at epoch (186):  0.09816103\n",
      "Test loss at epoch (186):  0.06992382\n",
      "Train loss at epoch (187):  0.09768565\n",
      "Test loss at epoch (187):  0.069710575\n",
      "Train loss at epoch (188):  0.097156666\n",
      "Test loss at epoch (188):  0.069653384\n",
      "Train loss at epoch (189):  0.09783258\n",
      "Test loss at epoch (189):  0.06935138\n",
      "Train loss at epoch (190):  0.09728068\n",
      "Test loss at epoch (190):  0.06895809\n",
      "Train loss at epoch (191):  0.09719032\n",
      "Test loss at epoch (191):  0.06872979\n",
      "Train loss at epoch (192):  0.09672644\n",
      "Test loss at epoch (192):  0.06858864\n",
      "Train loss at epoch (193):  0.09640363\n",
      "Test loss at epoch (193):  0.068301216\n",
      "Train loss at epoch (194):  0.0964332\n",
      "Test loss at epoch (194):  0.067988336\n",
      "Train loss at epoch (195):  0.09619498\n",
      "Test loss at epoch (195):  0.067893416\n",
      "Train loss at epoch (196):  0.096256666\n",
      "Test loss at epoch (196):  0.06766921\n",
      "Train loss at epoch (197):  0.09608061\n",
      "Test loss at epoch (197):  0.06748247\n",
      "Train loss at epoch (198):  0.09514629\n",
      "Test loss at epoch (198):  0.06726748\n",
      "Train loss at epoch (199):  0.09561271\n",
      "Test loss at epoch (199):  0.06704821\n",
      "Train loss at epoch (200):  0.095207416\n",
      "Test loss at epoch (200):  0.06681505\n",
      "Train loss at epoch (201):  0.09536205\n",
      "Test loss at epoch (201):  0.066503815\n",
      "Train loss at epoch (202):  0.09459335\n",
      "Test loss at epoch (202):  0.066452615\n",
      "Train loss at epoch (203):  0.09424068\n",
      "Test loss at epoch (203):  0.06607868\n",
      "Train loss at epoch (204):  0.09455314\n",
      "Test loss at epoch (204):  0.06582812\n",
      "Train loss at epoch (205):  0.094997734\n",
      "Test loss at epoch (205):  0.06567267\n",
      "Train loss at epoch (206):  0.094575174\n",
      "Test loss at epoch (206):  0.06554408\n",
      "Train loss at epoch (207):  0.09466557\n",
      "Test loss at epoch (207):  0.06528963\n",
      "Train loss at epoch (208):  0.0936376\n",
      "Test loss at epoch (208):  0.06526283\n",
      "Train loss at epoch (209):  0.094017565\n",
      "Test loss at epoch (209):  0.06486217\n",
      "Train loss at epoch (210):  0.093704864\n",
      "Test loss at epoch (210):  0.064700544\n",
      "Train loss at epoch (211):  0.09340367\n",
      "Test loss at epoch (211):  0.06443246\n",
      "Train loss at epoch (212):  0.09309457\n",
      "Test loss at epoch (212):  0.06441251\n",
      "Train loss at epoch (213):  0.09296813\n",
      "Test loss at epoch (213):  0.06429048\n",
      "Train loss at epoch (214):  0.09315974\n",
      "Test loss at epoch (214):  0.06410974\n",
      "Train loss at epoch (215):  0.09320399\n",
      "Test loss at epoch (215):  0.06384441\n",
      "Train loss at epoch (216):  0.093277\n",
      "Test loss at epoch (216):  0.06375771\n",
      "Train loss at epoch (217):  0.09318393\n",
      "Test loss at epoch (217):  0.06367302\n",
      "Train loss at epoch (218):  0.09216215\n",
      "Test loss at epoch (218):  0.06335702\n",
      "Train loss at epoch (219):  0.09273653\n",
      "Test loss at epoch (219):  0.06320375\n",
      "Train loss at epoch (220):  0.09314326\n",
      "Test loss at epoch (220):  0.06300816\n",
      "Train loss at epoch (221):  0.092106834\n",
      "Test loss at epoch (221):  0.06273717\n",
      "Train loss at epoch (222):  0.091978535\n",
      "Test loss at epoch (222):  0.062440395\n",
      "Train loss at epoch (223):  0.09182032\n",
      "Test loss at epoch (223):  0.062299024\n",
      "Train loss at epoch (224):  0.09163802\n",
      "Test loss at epoch (224):  0.062223133\n",
      "Train loss at epoch (225):  0.0916245\n",
      "Test loss at epoch (225):  0.0620883\n",
      "Train loss at epoch (226):  0.09156158\n",
      "Test loss at epoch (226):  0.061951153\n",
      "Train loss at epoch (227):  0.09152205\n",
      "Test loss at epoch (227):  0.06177044\n",
      "Train loss at epoch (228):  0.09071639\n",
      "Test loss at epoch (228):  0.061544444\n",
      "Train loss at epoch (229):  0.09104416\n",
      "Test loss at epoch (229):  0.061344236\n",
      "Train loss at epoch (230):  0.09112721\n",
      "Test loss at epoch (230):  0.06126645\n",
      "Train loss at epoch (231):  0.09073773\n",
      "Test loss at epoch (231):  0.061195586\n",
      "Train loss at epoch (232):  0.09077531\n",
      "Test loss at epoch (232):  0.060957123\n",
      "Train loss at epoch (233):  0.089980714\n",
      "Test loss at epoch (233):  0.060754105\n",
      "Train loss at epoch (234):  0.090121076\n",
      "Test loss at epoch (234):  0.060707983\n",
      "Train loss at epoch (235):  0.09019559\n",
      "Test loss at epoch (235):  0.060637325\n",
      "Train loss at epoch (236):  0.09010644\n",
      "Test loss at epoch (236):  0.060446482\n",
      "Train loss at epoch (237):  0.09016915\n",
      "Test loss at epoch (237):  0.06017495\n",
      "Train loss at epoch (238):  0.08972206\n",
      "Test loss at epoch (238):  0.060316235\n",
      "Train loss at epoch (239):  0.09024374\n",
      "Test loss at epoch (239):  0.059960175\n",
      "Train loss at epoch (240):  0.08955706\n",
      "Test loss at epoch (240):  0.06006451\n",
      "Train loss at epoch (241):  0.089751296\n",
      "Test loss at epoch (241):  0.059683003\n",
      "Train loss at epoch (242):  0.08904585\n",
      "Test loss at epoch (242):  0.05962929\n",
      "Train loss at epoch (243):  0.08954781\n",
      "Test loss at epoch (243):  0.05924607\n",
      "Train loss at epoch (244):  0.089130506\n",
      "Test loss at epoch (244):  0.059282273\n",
      "Train loss at epoch (245):  0.089145295\n",
      "Test loss at epoch (245):  0.059139717\n",
      "Train loss at epoch (246):  0.089232266\n",
      "Test loss at epoch (246):  0.05903859\n",
      "Train loss at epoch (247):  0.08883144\n",
      "Test loss at epoch (247):  0.058888122\n",
      "Train loss at epoch (248):  0.088805325\n",
      "Test loss at epoch (248):  0.058803532\n",
      "Train loss at epoch (249):  0.08892582\n",
      "Test loss at epoch (249):  0.05866621\n",
      "Train loss at epoch (250):  0.08839689\n",
      "Test loss at epoch (250):  0.0584902\n",
      "Train loss at epoch (251):  0.08862226\n",
      "Test loss at epoch (251):  0.058382027\n",
      "Train loss at epoch (252):  0.08845341\n",
      "Test loss at epoch (252):  0.058438133\n",
      "Train loss at epoch (253):  0.0882028\n",
      "Test loss at epoch (253):  0.05792265\n",
      "Train loss at epoch (254):  0.08826362\n",
      "Test loss at epoch (254):  0.057981335\n",
      "Train loss at epoch (255):  0.088455915\n",
      "Test loss at epoch (255):  0.057981383\n",
      "Train loss at epoch (256):  0.08824682\n",
      "Test loss at epoch (256):  0.057787683\n",
      "Train loss at epoch (257):  0.087843545\n",
      "Test loss at epoch (257):  0.05771403\n",
      "Train loss at epoch (258):  0.08765903\n",
      "Test loss at epoch (258):  0.057341926\n",
      "Train loss at epoch (259):  0.08781824\n",
      "Test loss at epoch (259):  0.05729009\n",
      "Train loss at epoch (260):  0.08756859\n",
      "Test loss at epoch (260):  0.057173636\n",
      "Train loss at epoch (261):  0.08755305\n",
      "Test loss at epoch (261):  0.05706986\n",
      "Train loss at epoch (262):  0.08724797\n",
      "Test loss at epoch (262):  0.056914035\n",
      "Train loss at epoch (263):  0.08730929\n",
      "Test loss at epoch (263):  0.05686021\n",
      "Train loss at epoch (264):  0.08711021\n",
      "Test loss at epoch (264):  0.05681388\n",
      "Train loss at epoch (265):  0.086373344\n",
      "Test loss at epoch (265):  0.056748454\n",
      "Train loss at epoch (266):  0.087065816\n",
      "Test loss at epoch (266):  0.05666035\n",
      "Train loss at epoch (267):  0.08698229\n",
      "Test loss at epoch (267):  0.056658387\n",
      "Train loss at epoch (268):  0.08654675\n",
      "Test loss at epoch (268):  0.05640636\n",
      "Train loss at epoch (269):  0.08660972\n",
      "Test loss at epoch (269):  0.056258887\n",
      "Train loss at epoch (270):  0.086549096\n",
      "Test loss at epoch (270):  0.055972245\n",
      "Train loss at epoch (271):  0.086401485\n",
      "Test loss at epoch (271):  0.055876963\n",
      "Train loss at epoch (272):  0.086271524\n",
      "Test loss at epoch (272):  0.055899784\n",
      "Train loss at epoch (273):  0.085792564\n",
      "Test loss at epoch (273):  0.055680707\n",
      "Train loss at epoch (274):  0.08605399\n",
      "Test loss at epoch (274):  0.055577785\n",
      "Train loss at epoch (275):  0.086175084\n",
      "Test loss at epoch (275):  0.055473674\n",
      "Train loss at epoch (276):  0.08551346\n",
      "Test loss at epoch (276):  0.0554366\n",
      "Train loss at epoch (277):  0.0857806\n",
      "Test loss at epoch (277):  0.055355676\n",
      "Train loss at epoch (278):  0.08546907\n",
      "Test loss at epoch (278):  0.055191737\n",
      "Train loss at epoch (279):  0.08571977\n",
      "Test loss at epoch (279):  0.055125266\n",
      "Train loss at epoch (280):  0.08541408\n",
      "Test loss at epoch (280):  0.055009354\n",
      "Train loss at epoch (281):  0.08542727\n",
      "Test loss at epoch (281):  0.05486524\n",
      "Train loss at epoch (282):  0.08529344\n",
      "Test loss at epoch (282):  0.054861564\n",
      "Train loss at epoch (283):  0.085310146\n",
      "Test loss at epoch (283):  0.05471896\n",
      "Train loss at epoch (284):  0.08542995\n",
      "Test loss at epoch (284):  0.054539412\n",
      "Train loss at epoch (285):  0.08495042\n",
      "Test loss at epoch (285):  0.054491784\n",
      "Train loss at epoch (286):  0.08509263\n",
      "Test loss at epoch (286):  0.054484468\n",
      "Train loss at epoch (287):  0.08518863\n",
      "Test loss at epoch (287):  0.054330852\n",
      "Train loss at epoch (288):  0.084851556\n",
      "Test loss at epoch (288):  0.05434638\n",
      "Train loss at epoch (289):  0.0843792\n",
      "Test loss at epoch (289):  0.053953096\n",
      "Train loss at epoch (290):  0.08453476\n",
      "Test loss at epoch (290):  0.054025248\n",
      "Train loss at epoch (291):  0.08425346\n",
      "Test loss at epoch (291):  0.0538778\n",
      "Train loss at epoch (292):  0.08438117\n",
      "Test loss at epoch (292):  0.053842325\n",
      "Train loss at epoch (293):  0.08404634\n",
      "Test loss at epoch (293):  0.053653736\n",
      "Train loss at epoch (294):  0.08442612\n",
      "Test loss at epoch (294):  0.053578466\n",
      "Train loss at epoch (295):  0.08372864\n",
      "Test loss at epoch (295):  0.053642932\n",
      "Train loss at epoch (296):  0.08403789\n",
      "Test loss at epoch (296):  0.05345453\n",
      "Train loss at epoch (297):  0.08369691\n",
      "Test loss at epoch (297):  0.053429633\n",
      "Train loss at epoch (298):  0.08348756\n",
      "Test loss at epoch (298):  0.05334271\n",
      "Train loss at epoch (299):  0.083821885\n",
      "Test loss at epoch (299):  0.05315534\n",
      "Train loss at epoch (300):  0.08386774\n",
      "Test loss at epoch (300):  0.05326061\n",
      "Train loss at epoch (301):  0.08351764\n",
      "Test loss at epoch (301):  0.053124428\n",
      "Train loss at epoch (302):  0.08349787\n",
      "Test loss at epoch (302):  0.05303976\n",
      "Train loss at epoch (303):  0.083541855\n",
      "Test loss at epoch (303):  0.052935116\n",
      "Train loss at epoch (304):  0.08375193\n",
      "Test loss at epoch (304):  0.052941706\n",
      "Train loss at epoch (305):  0.08389956\n",
      "Test loss at epoch (305):  0.052630823\n",
      "Train loss at epoch (306):  0.083576225\n",
      "Test loss at epoch (306):  0.052546665\n",
      "Train loss at epoch (307):  0.082987666\n",
      "Test loss at epoch (307):  0.052620813\n",
      "Train loss at epoch (308):  0.08332435\n",
      "Test loss at epoch (308):  0.052558213\n",
      "Train loss at epoch (309):  0.08339158\n",
      "Test loss at epoch (309):  0.052565537\n",
      "Train loss at epoch (310):  0.082469285\n",
      "Test loss at epoch (310):  0.052298605\n",
      "Train loss at epoch (311):  0.082992144\n",
      "Test loss at epoch (311):  0.052314464\n",
      "Train loss at epoch (312):  0.0829352\n",
      "Test loss at epoch (312):  0.052191768\n",
      "Train loss at epoch (313):  0.08268229\n",
      "Test loss at epoch (313):  0.05203975\n",
      "Train loss at epoch (314):  0.08297481\n",
      "Test loss at epoch (314):  0.051971294\n",
      "Train loss at epoch (315):  0.08250121\n",
      "Test loss at epoch (315):  0.05182028\n",
      "Train loss at epoch (316):  0.08275932\n",
      "Test loss at epoch (316):  0.051866103\n",
      "Train loss at epoch (317):  0.08252629\n",
      "Test loss at epoch (317):  0.051797323\n",
      "Train loss at epoch (318):  0.082099736\n",
      "Test loss at epoch (318):  0.051800847\n",
      "Train loss at epoch (319):  0.082197726\n",
      "Test loss at epoch (319):  0.051754955\n",
      "Train loss at epoch (320):  0.082520306\n",
      "Test loss at epoch (320):  0.0515995\n",
      "Train loss at epoch (321):  0.08207312\n",
      "Test loss at epoch (321):  0.051636163\n",
      "Train loss at epoch (322):  0.08204146\n",
      "Test loss at epoch (322):  0.05148306\n",
      "Train loss at epoch (323):  0.08205534\n",
      "Test loss at epoch (323):  0.051294297\n",
      "Train loss at epoch (324):  0.08188602\n",
      "Test loss at epoch (324):  0.05128947\n",
      "Train loss at epoch (325):  0.08193611\n",
      "Test loss at epoch (325):  0.05118676\n",
      "Train loss at epoch (326):  0.08196515\n",
      "Test loss at epoch (326):  0.051179662\n",
      "Train loss at epoch (327):  0.081486195\n",
      "Test loss at epoch (327):  0.051086575\n",
      "Train loss at epoch (328):  0.081349246\n",
      "Test loss at epoch (328):  0.051099587\n",
      "Train loss at epoch (329):  0.081011884\n",
      "Test loss at epoch (329):  0.05085095\n",
      "Train loss at epoch (330):  0.08157324\n",
      "Test loss at epoch (330):  0.050820578\n",
      "Train loss at epoch (331):  0.08165623\n",
      "Test loss at epoch (331):  0.050806977\n",
      "Train loss at epoch (332):  0.08192225\n",
      "Test loss at epoch (332):  0.050792888\n",
      "Train loss at epoch (333):  0.081299804\n",
      "Test loss at epoch (333):  0.050512232\n",
      "Train loss at epoch (334):  0.08150565\n",
      "Test loss at epoch (334):  0.050591175\n",
      "Train loss at epoch (335):  0.08125138\n",
      "Test loss at epoch (335):  0.0505237\n",
      "Train loss at epoch (336):  0.080670886\n",
      "Test loss at epoch (336):  0.050437234\n",
      "Train loss at epoch (337):  0.08080658\n",
      "Test loss at epoch (337):  0.050553758\n",
      "Train loss at epoch (338):  0.08087466\n",
      "Test loss at epoch (338):  0.050235458\n",
      "Train loss at epoch (339):  0.08079472\n",
      "Test loss at epoch (339):  0.05022005\n",
      "Train loss at epoch (340):  0.08068708\n",
      "Test loss at epoch (340):  0.050192326\n",
      "Train loss at epoch (341):  0.08097665\n",
      "Test loss at epoch (341):  0.050088614\n",
      "Train loss at epoch (342):  0.08069451\n",
      "Test loss at epoch (342):  0.049966644\n",
      "Train loss at epoch (343):  0.08070137\n",
      "Test loss at epoch (343):  0.049961913\n",
      "Train loss at epoch (344):  0.08007011\n",
      "Test loss at epoch (344):  0.049944147\n",
      "Train loss at epoch (345):  0.08050084\n",
      "Test loss at epoch (345):  0.04993236\n",
      "Train loss at epoch (346):  0.08008585\n",
      "Test loss at epoch (346):  0.04967238\n",
      "Train loss at epoch (347):  0.08037855\n",
      "Test loss at epoch (347):  0.049550187\n",
      "Train loss at epoch (348):  0.080149636\n",
      "Test loss at epoch (348):  0.049680386\n",
      "Train loss at epoch (349):  0.079965025\n",
      "Test loss at epoch (349):  0.049569476\n",
      "Train loss at epoch (350):  0.08029878\n",
      "Test loss at epoch (350):  0.049450163\n",
      "Train loss at epoch (351):  0.079718426\n",
      "Test loss at epoch (351):  0.049465504\n",
      "Train loss at epoch (352):  0.080079794\n",
      "Test loss at epoch (352):  0.04925418\n",
      "Train loss at epoch (353):  0.08002214\n",
      "Test loss at epoch (353):  0.04906125\n",
      "Train loss at epoch (354):  0.0799354\n",
      "Test loss at epoch (354):  0.04920384\n",
      "Train loss at epoch (355):  0.07979277\n",
      "Test loss at epoch (355):  0.049059927\n",
      "Train loss at epoch (356):  0.079718225\n",
      "Test loss at epoch (356):  0.049098894\n",
      "Train loss at epoch (357):  0.07963843\n",
      "Test loss at epoch (357):  0.04940186\n",
      "Train loss at epoch (358):  0.07947243\n",
      "Test loss at epoch (358):  0.048993897\n",
      "Train loss at epoch (359):  0.079812504\n",
      "Test loss at epoch (359):  0.04887206\n",
      "Train loss at epoch (360):  0.07939458\n",
      "Test loss at epoch (360):  0.048916284\n",
      "Train loss at epoch (361):  0.07961169\n",
      "Test loss at epoch (361):  0.048847508\n",
      "Train loss at epoch (362):  0.079328865\n",
      "Test loss at epoch (362):  0.04864867\n",
      "Train loss at epoch (363):  0.07938932\n",
      "Test loss at epoch (363):  0.048596628\n",
      "Train loss at epoch (364):  0.07913782\n",
      "Test loss at epoch (364):  0.048551567\n",
      "Train loss at epoch (365):  0.07960474\n",
      "Test loss at epoch (365):  0.048563965\n",
      "Train loss at epoch (366):  0.079280384\n",
      "Test loss at epoch (366):  0.048539724\n",
      "Train loss at epoch (367):  0.07880887\n",
      "Test loss at epoch (367):  0.048588146\n",
      "Train loss at epoch (368):  0.07890579\n",
      "Test loss at epoch (368):  0.048448626\n",
      "Train loss at epoch (369):  0.07895238\n",
      "Test loss at epoch (369):  0.048320085\n",
      "Train loss at epoch (370):  0.078656346\n",
      "Test loss at epoch (370):  0.048312206\n",
      "Train loss at epoch (371):  0.07922508\n",
      "Test loss at epoch (371):  0.048283875\n",
      "Train loss at epoch (372):  0.07896449\n",
      "Test loss at epoch (372):  0.048188135\n",
      "Train loss at epoch (373):  0.07866939\n",
      "Test loss at epoch (373):  0.048257984\n",
      "Train loss at epoch (374):  0.07889768\n",
      "Test loss at epoch (374):  0.048081152\n",
      "Train loss at epoch (375):  0.07826282\n",
      "Test loss at epoch (375):  0.047974218\n",
      "Train loss at epoch (376):  0.07872275\n",
      "Test loss at epoch (376):  0.047999825\n",
      "Train loss at epoch (377):  0.07811781\n",
      "Test loss at epoch (377):  0.047865346\n",
      "Train loss at epoch (378):  0.0782836\n",
      "Test loss at epoch (378):  0.047760412\n",
      "Train loss at epoch (379):  0.07827042\n",
      "Test loss at epoch (379):  0.0478519\n",
      "Train loss at epoch (380):  0.078478046\n",
      "Test loss at epoch (380):  0.047655992\n",
      "Train loss at epoch (381):  0.078464925\n",
      "Test loss at epoch (381):  0.04775916\n",
      "Train loss at epoch (382):  0.078741334\n",
      "Test loss at epoch (382):  0.047687244\n",
      "Train loss at epoch (383):  0.07827155\n",
      "Test loss at epoch (383):  0.047795437\n",
      "Train loss at epoch (384):  0.07822559\n",
      "Test loss at epoch (384):  0.047638446\n",
      "Train loss at epoch (385):  0.07790801\n",
      "Test loss at epoch (385):  0.04748205\n",
      "Train loss at epoch (386):  0.07774621\n",
      "Test loss at epoch (386):  0.047394034\n",
      "Train loss at epoch (387):  0.0779451\n",
      "Test loss at epoch (387):  0.0473337\n",
      "Train loss at epoch (388):  0.07817212\n",
      "Test loss at epoch (388):  0.047451995\n",
      "Train loss at epoch (389):  0.077810265\n",
      "Test loss at epoch (389):  0.047323767\n",
      "Train loss at epoch (390):  0.0774269\n",
      "Test loss at epoch (390):  0.047208246\n",
      "Train loss at epoch (391):  0.07765004\n",
      "Test loss at epoch (391):  0.047081538\n",
      "Train loss at epoch (392):  0.07764454\n",
      "Test loss at epoch (392):  0.04707027\n",
      "Train loss at epoch (393):  0.07730785\n",
      "Test loss at epoch (393):  0.046899788\n",
      "Train loss at epoch (394):  0.07760873\n",
      "Test loss at epoch (394):  0.046911847\n",
      "Train loss at epoch (395):  0.07742819\n",
      "Test loss at epoch (395):  0.04690968\n",
      "Train loss at epoch (396):  0.076818965\n",
      "Test loss at epoch (396):  0.046821956\n",
      "Train loss at epoch (397):  0.07746449\n",
      "Test loss at epoch (397):  0.04698665\n",
      "Train loss at epoch (398):  0.07706093\n",
      "Test loss at epoch (398):  0.046768915\n",
      "Train loss at epoch (399):  0.07734721\n",
      "Test loss at epoch (399):  0.046728782\n",
      "Train loss at epoch (400):  0.077148676\n",
      "Test loss at epoch (400):  0.046744768\n",
      "Train loss at epoch (401):  0.07715009\n",
      "Test loss at epoch (401):  0.0466779\n",
      "Train loss at epoch (402):  0.07731245\n",
      "Test loss at epoch (402):  0.04654305\n",
      "Train loss at epoch (403):  0.077269085\n",
      "Test loss at epoch (403):  0.04664266\n",
      "Train loss at epoch (404):  0.0771593\n",
      "Test loss at epoch (404):  0.04661573\n",
      "Train loss at epoch (405):  0.077151544\n",
      "Test loss at epoch (405):  0.04640554\n",
      "Train loss at epoch (406):  0.0764368\n",
      "Test loss at epoch (406):  0.046376187\n",
      "Train loss at epoch (407):  0.0768025\n",
      "Test loss at epoch (407):  0.046362754\n",
      "Train loss at epoch (408):  0.0770244\n",
      "Test loss at epoch (408):  0.046312574\n",
      "Train loss at epoch (409):  0.07675189\n",
      "Test loss at epoch (409):  0.04636889\n",
      "Train loss at epoch (410):  0.076663494\n",
      "Test loss at epoch (410):  0.046361864\n",
      "Train loss at epoch (411):  0.076542445\n",
      "Test loss at epoch (411):  0.04608946\n",
      "Train loss at epoch (412):  0.076666564\n",
      "Test loss at epoch (412):  0.046026725\n",
      "Train loss at epoch (413):  0.076531254\n",
      "Test loss at epoch (413):  0.046156853\n",
      "Train loss at epoch (414):  0.07680795\n",
      "Test loss at epoch (414):  0.046052836\n",
      "Train loss at epoch (415):  0.07682211\n",
      "Test loss at epoch (415):  0.046035994\n",
      "Train loss at epoch (416):  0.076337256\n",
      "Test loss at epoch (416):  0.046139102\n",
      "Train loss at epoch (417):  0.07669848\n",
      "Test loss at epoch (417):  0.04597048\n",
      "Train loss at epoch (418):  0.07634921\n",
      "Test loss at epoch (418):  0.046062853\n",
      "Train loss at epoch (419):  0.07633802\n",
      "Test loss at epoch (419):  0.046155576\n",
      "Train loss at epoch (420):  0.07631219\n",
      "Test loss at epoch (420):  0.045881495\n",
      "Train loss at epoch (421):  0.076190285\n",
      "Test loss at epoch (421):  0.045782294\n",
      "Train loss at epoch (422):  0.076419726\n",
      "Test loss at epoch (422):  0.04587487\n",
      "Train loss at epoch (423):  0.07642128\n",
      "Test loss at epoch (423):  0.04577417\n",
      "Train loss at epoch (424):  0.07651977\n",
      "Test loss at epoch (424):  0.045577385\n",
      "Train loss at epoch (425):  0.07659506\n",
      "Test loss at epoch (425):  0.045579087\n",
      "Train loss at epoch (426):  0.075789355\n",
      "Test loss at epoch (426):  0.045584425\n",
      "Train loss at epoch (427):  0.07583213\n",
      "Test loss at epoch (427):  0.045671526\n",
      "Train loss at epoch (428):  0.075628586\n",
      "Test loss at epoch (428):  0.045481343\n",
      "Train loss at epoch (429):  0.07566688\n",
      "Test loss at epoch (429):  0.045411643\n",
      "Train loss at epoch (430):  0.07636591\n",
      "Test loss at epoch (430):  0.04545444\n",
      "Train loss at epoch (431):  0.0758341\n",
      "Test loss at epoch (431):  0.045357443\n",
      "Train loss at epoch (432):  0.07569852\n",
      "Test loss at epoch (432):  0.045202743\n",
      "Train loss at epoch (433):  0.07552622\n",
      "Test loss at epoch (433):  0.04510377\n",
      "Train loss at epoch (434):  0.07606392\n",
      "Test loss at epoch (434):  0.045122717\n",
      "Train loss at epoch (435):  0.075727515\n",
      "Test loss at epoch (435):  0.04515514\n",
      "Train loss at epoch (436):  0.07565883\n",
      "Test loss at epoch (436):  0.045207668\n",
      "Train loss at epoch (437):  0.075846046\n",
      "Test loss at epoch (437):  0.045245707\n",
      "Train loss at epoch (438):  0.07556298\n",
      "Test loss at epoch (438):  0.04504068\n",
      "Train loss at epoch (439):  0.07563875\n",
      "Test loss at epoch (439):  0.045303605\n",
      "Train loss at epoch (440):  0.07597619\n",
      "Test loss at epoch (440):  0.045044288\n",
      "Train loss at epoch (441):  0.07534716\n",
      "Test loss at epoch (441):  0.044989083\n",
      "Train loss at epoch (442):  0.075219534\n",
      "Test loss at epoch (442):  0.044908237\n",
      "Train loss at epoch (443):  0.075421244\n",
      "Test loss at epoch (443):  0.044878434\n",
      "Train loss at epoch (444):  0.07524757\n",
      "Test loss at epoch (444):  0.044924114\n",
      "Train loss at epoch (445):  0.075209886\n",
      "Test loss at epoch (445):  0.044816643\n",
      "Train loss at epoch (446):  0.07533909\n",
      "Test loss at epoch (446):  0.04474867\n",
      "Train loss at epoch (447):  0.075120084\n",
      "Test loss at epoch (447):  0.044665236\n",
      "Train loss at epoch (448):  0.07459595\n",
      "Test loss at epoch (448):  0.044655047\n",
      "Train loss at epoch (449):  0.0748619\n",
      "Test loss at epoch (449):  0.044695262\n",
      "Train loss at epoch (450):  0.07516567\n",
      "Test loss at epoch (450):  0.04465121\n",
      "Train loss at epoch (451):  0.07456254\n",
      "Test loss at epoch (451):  0.044656564\n",
      "Train loss at epoch (452):  0.0747002\n",
      "Test loss at epoch (452):  0.044576064\n",
      "Train loss at epoch (453):  0.07484997\n",
      "Test loss at epoch (453):  0.04447521\n",
      "Train loss at epoch (454):  0.07474284\n",
      "Test loss at epoch (454):  0.044447552\n",
      "Train loss at epoch (455):  0.07454574\n",
      "Test loss at epoch (455):  0.04438327\n",
      "Train loss at epoch (456):  0.07433665\n",
      "Test loss at epoch (456):  0.0443467\n",
      "Train loss at epoch (457):  0.074525945\n",
      "Test loss at epoch (457):  0.044511188\n",
      "Train loss at epoch (458):  0.0749118\n",
      "Test loss at epoch (458):  0.0443294\n",
      "Train loss at epoch (459):  0.07479777\n",
      "Test loss at epoch (459):  0.04439496\n",
      "Train loss at epoch (460):  0.07481232\n",
      "Test loss at epoch (460):  0.044219643\n",
      "Train loss at epoch (461):  0.07437827\n",
      "Test loss at epoch (461):  0.044207852\n",
      "Train loss at epoch (462):  0.07465391\n",
      "Test loss at epoch (462):  0.044125486\n",
      "Train loss at epoch (463):  0.07432663\n",
      "Test loss at epoch (463):  0.044268884\n",
      "Train loss at epoch (464):  0.07441868\n",
      "Test loss at epoch (464):  0.04410379\n",
      "Train loss at epoch (465):  0.07409938\n",
      "Test loss at epoch (465):  0.044053916\n",
      "Train loss at epoch (466):  0.07407713\n",
      "Test loss at epoch (466):  0.04420863\n",
      "Train loss at epoch (467):  0.074407056\n",
      "Test loss at epoch (467):  0.044113874\n",
      "Train loss at epoch (468):  0.07402891\n",
      "Test loss at epoch (468):  0.044074584\n",
      "Train loss at epoch (469):  0.074298315\n",
      "Test loss at epoch (469):  0.04391026\n",
      "Train loss at epoch (470):  0.073874325\n",
      "Test loss at epoch (470):  0.043935332\n",
      "Train loss at epoch (471):  0.07411072\n",
      "Test loss at epoch (471):  0.0438671\n",
      "Train loss at epoch (472):  0.07381034\n",
      "Test loss at epoch (472):  0.043856274\n",
      "Train loss at epoch (473):  0.07365375\n",
      "Test loss at epoch (473):  0.04377024\n",
      "Train loss at epoch (474):  0.07471478\n",
      "Test loss at epoch (474):  0.043826073\n",
      "Train loss at epoch (475):  0.07368675\n",
      "Test loss at epoch (475):  0.043629263\n",
      "Train loss at epoch (476):  0.073741734\n",
      "Test loss at epoch (476):  0.043752436\n",
      "Train loss at epoch (477):  0.07406983\n",
      "Test loss at epoch (477):  0.043617565\n",
      "Train loss at epoch (478):  0.07340025\n",
      "Test loss at epoch (478):  0.043560777\n",
      "Train loss at epoch (479):  0.07373766\n",
      "Test loss at epoch (479):  0.043505866\n",
      "Train loss at epoch (480):  0.07362857\n",
      "Test loss at epoch (480):  0.0435813\n",
      "Train loss at epoch (481):  0.073971495\n",
      "Test loss at epoch (481):  0.04354904\n",
      "Train loss at epoch (482):  0.073574804\n",
      "Test loss at epoch (482):  0.043537296\n",
      "Train loss at epoch (483):  0.073237106\n",
      "Test loss at epoch (483):  0.043478504\n",
      "Train loss at epoch (484):  0.07387737\n",
      "Test loss at epoch (484):  0.043459326\n",
      "Train loss at epoch (485):  0.07354677\n",
      "Test loss at epoch (485):  0.043472733\n",
      "Train loss at epoch (486):  0.073246546\n",
      "Test loss at epoch (486):  0.04345974\n",
      "Train loss at epoch (487):  0.073698595\n",
      "Test loss at epoch (487):  0.04331381\n",
      "Train loss at epoch (488):  0.07370502\n",
      "Test loss at epoch (488):  0.0433088\n",
      "Train loss at epoch (489):  0.07352176\n",
      "Test loss at epoch (489):  0.0433128\n",
      "Train loss at epoch (490):  0.073696814\n",
      "Test loss at epoch (490):  0.043313976\n",
      "Train loss at epoch (491):  0.07338336\n",
      "Test loss at epoch (491):  0.043270614\n",
      "Train loss at epoch (492):  0.073470525\n",
      "Test loss at epoch (492):  0.043226745\n",
      "Train loss at epoch (493):  0.073731184\n",
      "Test loss at epoch (493):  0.043112475\n",
      "Train loss at epoch (494):  0.073140286\n",
      "Test loss at epoch (494):  0.04309967\n",
      "Train loss at epoch (495):  0.07320342\n",
      "Test loss at epoch (495):  0.043113124\n",
      "Train loss at epoch (496):  0.07299483\n",
      "Test loss at epoch (496):  0.043053653\n",
      "Train loss at epoch (497):  0.07302552\n",
      "Test loss at epoch (497):  0.04302948\n",
      "Train loss at epoch (498):  0.07300341\n",
      "Test loss at epoch (498):  0.042891618\n",
      "Train loss at epoch (499):  0.07347677\n",
      "Test loss at epoch (499):  0.0429915\n",
      "Train loss at epoch (500):  0.07277842\n",
      "Test loss at epoch (500):  0.043045275\n",
      "Train loss at epoch (501):  0.0728363\n",
      "Test loss at epoch (501):  0.042981323\n",
      "Train loss at epoch (502):  0.07336441\n",
      "Test loss at epoch (502):  0.042897172\n",
      "Train loss at epoch (503):  0.07297695\n",
      "Test loss at epoch (503):  0.04293939\n",
      "Train loss at epoch (504):  0.072948754\n",
      "Test loss at epoch (504):  0.042927295\n",
      "Train loss at epoch (505):  0.0732299\n",
      "Test loss at epoch (505):  0.04295327\n",
      "Train loss at epoch (506):  0.07287958\n",
      "Test loss at epoch (506):  0.04282069\n",
      "Train loss at epoch (507):  0.072639905\n",
      "Test loss at epoch (507):  0.04270824\n",
      "Train loss at epoch (508):  0.0727626\n",
      "Test loss at epoch (508):  0.042621586\n",
      "Train loss at epoch (509):  0.07288783\n",
      "Test loss at epoch (509):  0.042615402\n",
      "Train loss at epoch (510):  0.072798274\n",
      "Test loss at epoch (510):  0.042674895\n",
      "Train loss at epoch (511):  0.07239416\n",
      "Test loss at epoch (511):  0.042492017\n",
      "Train loss at epoch (512):  0.07272837\n",
      "Test loss at epoch (512):  0.042591523\n",
      "Train loss at epoch (513):  0.07279077\n",
      "Test loss at epoch (513):  0.04259184\n",
      "Train loss at epoch (514):  0.072964\n",
      "Test loss at epoch (514):  0.042649724\n",
      "Train loss at epoch (515):  0.072429776\n",
      "Test loss at epoch (515):  0.04257498\n",
      "Train loss at epoch (516):  0.072293386\n",
      "Test loss at epoch (516):  0.04256825\n",
      "Train loss at epoch (517):  0.07237141\n",
      "Test loss at epoch (517):  0.04247695\n",
      "Train loss at epoch (518):  0.07253689\n",
      "Test loss at epoch (518):  0.04242299\n",
      "Train loss at epoch (519):  0.072096325\n",
      "Test loss at epoch (519):  0.042405132\n",
      "Train loss at epoch (520):  0.0721124\n",
      "Test loss at epoch (520):  0.04234867\n",
      "Train loss at epoch (521):  0.072679915\n",
      "Test loss at epoch (521):  0.042396676\n",
      "Train loss at epoch (522):  0.07249213\n",
      "Test loss at epoch (522):  0.04228486\n",
      "Train loss at epoch (523):  0.07222028\n",
      "Test loss at epoch (523):  0.04225838\n",
      "Train loss at epoch (524):  0.072119996\n",
      "Test loss at epoch (524):  0.04228347\n",
      "Train loss at epoch (525):  0.07193968\n",
      "Test loss at epoch (525):  0.04236989\n",
      "Train loss at epoch (526):  0.0724429\n",
      "Test loss at epoch (526):  0.042199656\n",
      "Train loss at epoch (527):  0.071751595\n",
      "Test loss at epoch (527):  0.0421768\n",
      "Train loss at epoch (528):  0.072369024\n",
      "Test loss at epoch (528):  0.042130947\n",
      "Train loss at epoch (529):  0.07219818\n",
      "Test loss at epoch (529):  0.042133603\n",
      "Train loss at epoch (530):  0.071973346\n",
      "Test loss at epoch (530):  0.042200215\n",
      "Train loss at epoch (531):  0.07239111\n",
      "Test loss at epoch (531):  0.042159803\n",
      "Train loss at epoch (532):  0.07195864\n",
      "Test loss at epoch (532):  0.042095073\n",
      "Train loss at epoch (533):  0.07215559\n",
      "Test loss at epoch (533):  0.042091765\n",
      "Train loss at epoch (534):  0.07225383\n",
      "Test loss at epoch (534):  0.04199326\n",
      "Train loss at epoch (535):  0.07213284\n",
      "Test loss at epoch (535):  0.04207187\n",
      "Train loss at epoch (536):  0.07228459\n",
      "Test loss at epoch (536):  0.0420351\n",
      "Train loss at epoch (537):  0.071902305\n",
      "Test loss at epoch (537):  0.041920904\n",
      "Train loss at epoch (538):  0.07185582\n",
      "Test loss at epoch (538):  0.041849792\n",
      "Train loss at epoch (539):  0.071777865\n",
      "Test loss at epoch (539):  0.041870173\n",
      "Train loss at epoch (540):  0.07166692\n",
      "Test loss at epoch (540):  0.041875374\n",
      "Train loss at epoch (541):  0.071631975\n",
      "Test loss at epoch (541):  0.041889936\n",
      "Train loss at epoch (542):  0.07184886\n",
      "Test loss at epoch (542):  0.041814525\n",
      "Train loss at epoch (543):  0.07186241\n",
      "Test loss at epoch (543):  0.041822363\n",
      "Train loss at epoch (544):  0.071623795\n",
      "Test loss at epoch (544):  0.041769613\n",
      "Train loss at epoch (545):  0.07159584\n",
      "Test loss at epoch (545):  0.04181993\n",
      "Train loss at epoch (546):  0.071568444\n",
      "Test loss at epoch (546):  0.041779827\n",
      "Train loss at epoch (547):  0.07145795\n",
      "Test loss at epoch (547):  0.041772094\n",
      "Train loss at epoch (548):  0.07147312\n",
      "Test loss at epoch (548):  0.041665874\n",
      "Train loss at epoch (549):  0.07124602\n",
      "Test loss at epoch (549):  0.041657735\n",
      "Train loss at epoch (550):  0.07134803\n",
      "Test loss at epoch (550):  0.041613925\n",
      "Train loss at epoch (551):  0.07153725\n",
      "Test loss at epoch (551):  0.04161241\n",
      "Train loss at epoch (552):  0.07140983\n",
      "Test loss at epoch (552):  0.041587863\n",
      "Train loss at epoch (553):  0.07109382\n",
      "Test loss at epoch (553):  0.04160737\n",
      "Train loss at epoch (554):  0.07156231\n",
      "Test loss at epoch (554):  0.041584063\n",
      "Train loss at epoch (555):  0.071607895\n",
      "Test loss at epoch (555):  0.04144714\n",
      "Train loss at epoch (556):  0.07154312\n",
      "Test loss at epoch (556):  0.04148035\n",
      "Train loss at epoch (557):  0.071235485\n",
      "Test loss at epoch (557):  0.041514333\n",
      "Train loss at epoch (558):  0.07107102\n",
      "Test loss at epoch (558):  0.041472066\n",
      "Train loss at epoch (559):  0.07113521\n",
      "Test loss at epoch (559):  0.041529007\n",
      "Train loss at epoch (560):  0.07119075\n",
      "Test loss at epoch (560):  0.041466277\n",
      "Train loss at epoch (561):  0.071235165\n",
      "Test loss at epoch (561):  0.04153535\n",
      "Train loss at epoch (562):  0.070912115\n",
      "Test loss at epoch (562):  0.041451495\n",
      "Train loss at epoch (563):  0.07097625\n",
      "Test loss at epoch (563):  0.041475978\n",
      "Train loss at epoch (564):  0.071457244\n",
      "Test loss at epoch (564):  0.041394178\n",
      "Train loss at epoch (565):  0.070996195\n",
      "Test loss at epoch (565):  0.041322757\n",
      "Train loss at epoch (566):  0.07098551\n",
      "Test loss at epoch (566):  0.04128392\n",
      "Train loss at epoch (567):  0.07089639\n",
      "Test loss at epoch (567):  0.04129301\n",
      "Train loss at epoch (568):  0.071026616\n",
      "Test loss at epoch (568):  0.04123421\n",
      "Train loss at epoch (569):  0.07129701\n",
      "Test loss at epoch (569):  0.04116323\n",
      "Train loss at epoch (570):  0.07097855\n",
      "Test loss at epoch (570):  0.041219287\n",
      "Train loss at epoch (571):  0.070911914\n",
      "Test loss at epoch (571):  0.04120743\n",
      "Train loss at epoch (572):  0.07068909\n",
      "Test loss at epoch (572):  0.041097473\n",
      "Train loss at epoch (573):  0.07062756\n",
      "Test loss at epoch (573):  0.04115788\n",
      "Train loss at epoch (574):  0.07125975\n",
      "Test loss at epoch (574):  0.0411229\n",
      "Train loss at epoch (575):  0.07053546\n",
      "Test loss at epoch (575):  0.04104166\n",
      "Train loss at epoch (576):  0.07111331\n",
      "Test loss at epoch (576):  0.041040644\n",
      "Train loss at epoch (577):  0.07046761\n",
      "Test loss at epoch (577):  0.040996958\n",
      "Train loss at epoch (578):  0.07090799\n",
      "Test loss at epoch (578):  0.041083764\n",
      "Train loss at epoch (579):  0.070701554\n",
      "Test loss at epoch (579):  0.040958196\n",
      "Train loss at epoch (580):  0.07001029\n",
      "Test loss at epoch (580):  0.041035432\n",
      "Train loss at epoch (581):  0.07057795\n",
      "Test loss at epoch (581):  0.041067015\n",
      "Train loss at epoch (582):  0.07064631\n",
      "Test loss at epoch (582):  0.040878844\n",
      "Train loss at epoch (583):  0.070610404\n",
      "Test loss at epoch (583):  0.040922184\n",
      "Train loss at epoch (584):  0.07050124\n",
      "Test loss at epoch (584):  0.04093213\n",
      "Train loss at epoch (585):  0.07040479\n",
      "Test loss at epoch (585):  0.040848825\n",
      "Train loss at epoch (586):  0.07051533\n",
      "Test loss at epoch (586):  0.040828887\n",
      "Train loss at epoch (587):  0.07039428\n",
      "Test loss at epoch (587):  0.040875867\n",
      "Train loss at epoch (588):  0.07045313\n",
      "Test loss at epoch (588):  0.040867776\n",
      "Train loss at epoch (589):  0.07039102\n",
      "Test loss at epoch (589):  0.04066928\n",
      "Train loss at epoch (590):  0.0702778\n",
      "Test loss at epoch (590):  0.04069327\n",
      "Train loss at epoch (591):  0.07023224\n",
      "Test loss at epoch (591):  0.040787414\n",
      "Train loss at epoch (592):  0.070585616\n",
      "Test loss at epoch (592):  0.0406688\n",
      "Train loss at epoch (593):  0.06983014\n",
      "Test loss at epoch (593):  0.040581208\n",
      "Train loss at epoch (594):  0.0700432\n",
      "Test loss at epoch (594):  0.040490497\n",
      "Train loss at epoch (595):  0.07031812\n",
      "Test loss at epoch (595):  0.04057943\n",
      "Train loss at epoch (596):  0.07030623\n",
      "Test loss at epoch (596):  0.040564507\n",
      "Train loss at epoch (597):  0.070197426\n",
      "Test loss at epoch (597):  0.040581573\n",
      "Train loss at epoch (598):  0.0704132\n",
      "Test loss at epoch (598):  0.04049195\n",
      "Train loss at epoch (599):  0.07032427\n",
      "Test loss at epoch (599):  0.04055061\n",
      "Train loss at epoch (600):  0.0701231\n",
      "Test loss at epoch (600):  0.040484637\n",
      "Train loss at epoch (601):  0.07002574\n",
      "Test loss at epoch (601):  0.040421277\n",
      "Train loss at epoch (602):  0.07015671\n",
      "Test loss at epoch (602):  0.04038386\n",
      "Train loss at epoch (603):  0.070138246\n",
      "Test loss at epoch (603):  0.04044357\n",
      "Train loss at epoch (604):  0.07002178\n",
      "Test loss at epoch (604):  0.040367927\n",
      "Train loss at epoch (605):  0.06986647\n",
      "Test loss at epoch (605):  0.040430106\n",
      "Train loss at epoch (606):  0.06994094\n",
      "Test loss at epoch (606):  0.04032102\n",
      "Train loss at epoch (607):  0.069719836\n",
      "Test loss at epoch (607):  0.04036956\n",
      "Train loss at epoch (608):  0.07000714\n",
      "Test loss at epoch (608):  0.040260695\n",
      "Train loss at epoch (609):  0.0701648\n",
      "Test loss at epoch (609):  0.04047993\n",
      "Train loss at epoch (610):  0.06964446\n",
      "Test loss at epoch (610):  0.04039141\n",
      "Train loss at epoch (611):  0.06961213\n",
      "Test loss at epoch (611):  0.04032054\n",
      "Train loss at epoch (612):  0.07000362\n",
      "Test loss at epoch (612):  0.040368747\n",
      "Train loss at epoch (613):  0.069648765\n",
      "Test loss at epoch (613):  0.040367913\n",
      "Train loss at epoch (614):  0.069691464\n",
      "Test loss at epoch (614):  0.040266324\n",
      "Train loss at epoch (615):  0.06998227\n",
      "Test loss at epoch (615):  0.040296264\n",
      "Train loss at epoch (616):  0.069785446\n",
      "Test loss at epoch (616):  0.04026061\n",
      "Train loss at epoch (617):  0.06974479\n",
      "Test loss at epoch (617):  0.04033228\n",
      "Train loss at epoch (618):  0.06980537\n",
      "Test loss at epoch (618):  0.040238235\n",
      "Train loss at epoch (619):  0.069926396\n",
      "Test loss at epoch (619):  0.040301926\n",
      "Train loss at epoch (620):  0.06947342\n",
      "Test loss at epoch (620):  0.040342778\n",
      "Train loss at epoch (621):  0.06983181\n",
      "Test loss at epoch (621):  0.040268995\n",
      "Train loss at epoch (622):  0.069961436\n",
      "Test loss at epoch (622):  0.040205874\n",
      "Train loss at epoch (623):  0.06969357\n",
      "Test loss at epoch (623):  0.040245518\n",
      "Train loss at epoch (624):  0.06975341\n",
      "Test loss at epoch (624):  0.040117484\n",
      "Train loss at epoch (625):  0.06944219\n",
      "Test loss at epoch (625):  0.04017016\n",
      "Train loss at epoch (626):  0.06941606\n",
      "Test loss at epoch (626):  0.040049933\n",
      "Train loss at epoch (627):  0.06942953\n",
      "Test loss at epoch (627):  0.04003191\n",
      "Train loss at epoch (628):  0.06994073\n",
      "Test loss at epoch (628):  0.040160667\n",
      "Train loss at epoch (629):  0.06942896\n",
      "Test loss at epoch (629):  0.04012742\n",
      "Train loss at epoch (630):  0.06943536\n",
      "Test loss at epoch (630):  0.04008125\n",
      "Train loss at epoch (631):  0.06903904\n",
      "Test loss at epoch (631):  0.040081423\n",
      "Train loss at epoch (632):  0.06928845\n",
      "Test loss at epoch (632):  0.039921056\n",
      "Train loss at epoch (633):  0.06966842\n",
      "Test loss at epoch (633):  0.040006623\n",
      "Train loss at epoch (634):  0.06956049\n",
      "Test loss at epoch (634):  0.039996568\n",
      "Train loss at epoch (635):  0.06898354\n",
      "Test loss at epoch (635):  0.039891943\n",
      "Train loss at epoch (636):  0.069379725\n",
      "Test loss at epoch (636):  0.039915074\n",
      "Train loss at epoch (637):  0.069564275\n",
      "Test loss at epoch (637):  0.03997724\n",
      "Train loss at epoch (638):  0.069239795\n",
      "Test loss at epoch (638):  0.04000941\n",
      "Train loss at epoch (639):  0.06947408\n",
      "Test loss at epoch (639):  0.03996028\n",
      "Train loss at epoch (640):  0.069215275\n",
      "Test loss at epoch (640):  0.039974693\n",
      "Train loss at epoch (641):  0.06914162\n",
      "Test loss at epoch (641):  0.0399723\n",
      "Train loss at epoch (642):  0.06871407\n",
      "Test loss at epoch (642):  0.0398833\n",
      "Train loss at epoch (643):  0.069369584\n",
      "Test loss at epoch (643):  0.03989184\n",
      "Train loss at epoch (644):  0.069018826\n",
      "Test loss at epoch (644):  0.03989922\n",
      "Train loss at epoch (645):  0.06894339\n",
      "Test loss at epoch (645):  0.039802317\n",
      "Train loss at epoch (646):  0.06907559\n",
      "Test loss at epoch (646):  0.03985511\n",
      "Train loss at epoch (647):  0.0690619\n",
      "Test loss at epoch (647):  0.03979267\n",
      "Train loss at epoch (648):  0.06906932\n",
      "Test loss at epoch (648):  0.039758626\n",
      "Train loss at epoch (649):  0.069316484\n",
      "Test loss at epoch (649):  0.039761256\n",
      "Train loss at epoch (650):  0.06862364\n",
      "Test loss at epoch (650):  0.03977286\n",
      "Train loss at epoch (651):  0.069104634\n",
      "Test loss at epoch (651):  0.039761353\n",
      "Train loss at epoch (652):  0.06865045\n",
      "Test loss at epoch (652):  0.039668977\n",
      "Train loss at epoch (653):  0.06937843\n",
      "Test loss at epoch (653):  0.039648473\n",
      "Train loss at epoch (654):  0.06870446\n",
      "Test loss at epoch (654):  0.039657243\n",
      "Train loss at epoch (655):  0.06867412\n",
      "Test loss at epoch (655):  0.039546717\n",
      "Train loss at epoch (656):  0.069013245\n",
      "Test loss at epoch (656):  0.03958701\n",
      "Train loss at epoch (657):  0.06915749\n",
      "Test loss at epoch (657):  0.03965282\n",
      "Train loss at epoch (658):  0.068921804\n",
      "Test loss at epoch (658):  0.039480925\n",
      "Train loss at epoch (659):  0.06895619\n",
      "Test loss at epoch (659):  0.039548516\n",
      "Train loss at epoch (660):  0.068743795\n",
      "Test loss at epoch (660):  0.039518088\n",
      "Train loss at epoch (661):  0.06918916\n",
      "Test loss at epoch (661):  0.03953145\n",
      "Train loss at epoch (662):  0.069141634\n",
      "Test loss at epoch (662):  0.039549075\n",
      "Train loss at epoch (663):  0.0685423\n",
      "Test loss at epoch (663):  0.039461643\n",
      "Train loss at epoch (664):  0.06875582\n",
      "Test loss at epoch (664):  0.039469603\n",
      "Train loss at epoch (665):  0.06851947\n",
      "Test loss at epoch (665):  0.039451886\n",
      "Train loss at epoch (666):  0.068973914\n",
      "Test loss at epoch (666):  0.03947986\n",
      "Train loss at epoch (667):  0.06871456\n",
      "Test loss at epoch (667):  0.03944599\n",
      "Train loss at epoch (668):  0.0687273\n",
      "Test loss at epoch (668):  0.039330978\n",
      "Train loss at epoch (669):  0.068721615\n",
      "Test loss at epoch (669):  0.039373152\n",
      "Train loss at epoch (670):  0.06858288\n",
      "Test loss at epoch (670):  0.039353177\n",
      "Train loss at epoch (671):  0.06889038\n",
      "Test loss at epoch (671):  0.03937076\n",
      "Train loss at epoch (672):  0.06841047\n",
      "Test loss at epoch (672):  0.039323427\n",
      "Train loss at epoch (673):  0.06865311\n",
      "Test loss at epoch (673):  0.03930206\n",
      "Train loss at epoch (674):  0.06911936\n",
      "Test loss at epoch (674):  0.039381817\n",
      "Train loss at epoch (675):  0.06867059\n",
      "Test loss at epoch (675):  0.03938763\n",
      "Train loss at epoch (676):  0.06859437\n",
      "Test loss at epoch (676):  0.039354026\n",
      "Train loss at epoch (677):  0.06876306\n",
      "Test loss at epoch (677):  0.039363947\n",
      "Train loss at epoch (678):  0.06838055\n",
      "Test loss at epoch (678):  0.039262045\n",
      "Train loss at epoch (679):  0.06866835\n",
      "Test loss at epoch (679):  0.039213404\n",
      "Train loss at epoch (680):  0.06828943\n",
      "Test loss at epoch (680):  0.03918422\n",
      "Train loss at epoch (681):  0.06844469\n",
      "Test loss at epoch (681):  0.039141227\n",
      "Train loss at epoch (682):  0.068259634\n",
      "Test loss at epoch (682):  0.039205633\n",
      "Train loss at epoch (683):  0.06859347\n",
      "Test loss at epoch (683):  0.03919224\n",
      "Train loss at epoch (684):  0.06806101\n",
      "Test loss at epoch (684):  0.03915574\n",
      "Train loss at epoch (685):  0.068107426\n",
      "Test loss at epoch (685):  0.039098397\n",
      "Train loss at epoch (686):  0.06855252\n",
      "Test loss at epoch (686):  0.039069004\n",
      "Train loss at epoch (687):  0.06840352\n",
      "Test loss at epoch (687):  0.039088707\n",
      "Train loss at epoch (688):  0.0684763\n",
      "Test loss at epoch (688):  0.039048154\n",
      "Train loss at epoch (689):  0.06843123\n",
      "Test loss at epoch (689):  0.039060142\n",
      "Train loss at epoch (690):  0.068280436\n",
      "Test loss at epoch (690):  0.03910611\n",
      "Train loss at epoch (691):  0.06833355\n",
      "Test loss at epoch (691):  0.03911093\n",
      "Train loss at epoch (692):  0.06812419\n",
      "Test loss at epoch (692):  0.039064974\n",
      "Train loss at epoch (693):  0.068324886\n",
      "Test loss at epoch (693):  0.039032564\n",
      "Train loss at epoch (694):  0.06829851\n",
      "Test loss at epoch (694):  0.038996864\n",
      "Train loss at epoch (695):  0.068127155\n",
      "Test loss at epoch (695):  0.039004803\n",
      "Train loss at epoch (696):  0.068296015\n",
      "Test loss at epoch (696):  0.039071843\n",
      "Train loss at epoch (697):  0.06791424\n",
      "Test loss at epoch (697):  0.03905649\n",
      "Train loss at epoch (698):  0.06799463\n",
      "Test loss at epoch (698):  0.039096862\n",
      "Train loss at epoch (699):  0.068093866\n",
      "Test loss at epoch (699):  0.038941003\n",
      "Train loss at epoch (700):  0.06853852\n",
      "Test loss at epoch (700):  0.038930096\n",
      "Train loss at epoch (701):  0.06807548\n",
      "Test loss at epoch (701):  0.039028317\n",
      "Train loss at epoch (702):  0.06807308\n",
      "Test loss at epoch (702):  0.038910285\n",
      "Train loss at epoch (703):  0.067733586\n",
      "Test loss at epoch (703):  0.03886695\n",
      "Train loss at epoch (704):  0.068010844\n",
      "Test loss at epoch (704):  0.03884463\n",
      "Train loss at epoch (705):  0.06793346\n",
      "Test loss at epoch (705):  0.03879704\n",
      "Train loss at epoch (706):  0.06816624\n",
      "Test loss at epoch (706):  0.038799208\n",
      "Train loss at epoch (707):  0.06787653\n",
      "Test loss at epoch (707):  0.038794547\n",
      "Train loss at epoch (708):  0.06765799\n",
      "Test loss at epoch (708):  0.038842898\n",
      "Train loss at epoch (709):  0.06811963\n",
      "Test loss at epoch (709):  0.038781855\n",
      "Train loss at epoch (710):  0.06771595\n",
      "Test loss at epoch (710):  0.038777202\n",
      "Train loss at epoch (711):  0.06787051\n",
      "Test loss at epoch (711):  0.038774103\n",
      "Train loss at epoch (712):  0.06793524\n",
      "Test loss at epoch (712):  0.038807202\n",
      "Train loss at epoch (713):  0.067910135\n",
      "Test loss at epoch (713):  0.0388635\n",
      "Train loss at epoch (714):  0.06807685\n",
      "Test loss at epoch (714):  0.038742807\n",
      "Train loss at epoch (715):  0.06785109\n",
      "Test loss at epoch (715):  0.038764566\n",
      "Train loss at epoch (716):  0.06777783\n",
      "Test loss at epoch (716):  0.038786694\n",
      "Train loss at epoch (717):  0.067978494\n",
      "Test loss at epoch (717):  0.038685333\n",
      "Train loss at epoch (718):  0.0678738\n",
      "Test loss at epoch (718):  0.0386923\n",
      "Train loss at epoch (719):  0.06798628\n",
      "Test loss at epoch (719):  0.038758904\n",
      "Train loss at epoch (720):  0.06761956\n",
      "Test loss at epoch (720):  0.038806904\n",
      "Train loss at epoch (721):  0.06753347\n",
      "Test loss at epoch (721):  0.038830873\n",
      "Train loss at epoch (722):  0.067630865\n",
      "Test loss at epoch (722):  0.0387406\n",
      "Train loss at epoch (723):  0.067393236\n",
      "Test loss at epoch (723):  0.038665283\n",
      "Train loss at epoch (724):  0.06751948\n",
      "Test loss at epoch (724):  0.03869831\n",
      "Train loss at epoch (725):  0.06741714\n",
      "Test loss at epoch (725):  0.03858167\n",
      "Train loss at epoch (726):  0.06758127\n",
      "Test loss at epoch (726):  0.038597573\n",
      "Train loss at epoch (727):  0.06786964\n",
      "Test loss at epoch (727):  0.03864893\n",
      "Train loss at epoch (728):  0.06756672\n",
      "Test loss at epoch (728):  0.038608488\n",
      "Train loss at epoch (729):  0.06763488\n",
      "Test loss at epoch (729):  0.03864017\n",
      "Train loss at epoch (730):  0.06782056\n",
      "Test loss at epoch (730):  0.038618054\n",
      "Train loss at epoch (731):  0.067321\n",
      "Test loss at epoch (731):  0.038508784\n",
      "Train loss at epoch (732):  0.06738119\n",
      "Test loss at epoch (732):  0.038421396\n",
      "Train loss at epoch (733):  0.06760777\n",
      "Test loss at epoch (733):  0.038448665\n",
      "Train loss at epoch (734):  0.06742341\n",
      "Test loss at epoch (734):  0.03844029\n",
      "Train loss at epoch (735):  0.06769789\n",
      "Test loss at epoch (735):  0.03854775\n",
      "Train loss at epoch (736):  0.06757791\n",
      "Test loss at epoch (736):  0.0384528\n",
      "Train loss at epoch (737):  0.067245185\n",
      "Test loss at epoch (737):  0.038610823\n",
      "Train loss at epoch (738):  0.067556925\n",
      "Test loss at epoch (738):  0.03848027\n",
      "Train loss at epoch (739):  0.06733908\n",
      "Test loss at epoch (739):  0.03849151\n",
      "Train loss at epoch (740):  0.067473754\n",
      "Test loss at epoch (740):  0.038482677\n",
      "Train loss at epoch (741):  0.06719316\n",
      "Test loss at epoch (741):  0.03845147\n",
      "Train loss at epoch (742):  0.067746535\n",
      "Test loss at epoch (742):  0.038379997\n",
      "Train loss at epoch (743):  0.0677889\n",
      "Test loss at epoch (743):  0.038473174\n",
      "Train loss at epoch (744):  0.06706132\n",
      "Test loss at epoch (744):  0.038415022\n",
      "Train loss at epoch (745):  0.06739989\n",
      "Test loss at epoch (745):  0.03836052\n",
      "Train loss at epoch (746):  0.06736026\n",
      "Test loss at epoch (746):  0.038414683\n",
      "Train loss at epoch (747):  0.0671741\n",
      "Test loss at epoch (747):  0.038376\n",
      "Train loss at epoch (748):  0.06711619\n",
      "Test loss at epoch (748):  0.03829751\n",
      "Train loss at epoch (749):  0.06717898\n",
      "Test loss at epoch (749):  0.038298093\n",
      "Train loss at epoch (750):  0.06717894\n",
      "Test loss at epoch (750):  0.038281012\n",
      "Train loss at epoch (751):  0.06717827\n",
      "Test loss at epoch (751):  0.03834281\n",
      "Train loss at epoch (752):  0.0672755\n",
      "Test loss at epoch (752):  0.03825482\n",
      "Train loss at epoch (753):  0.06694368\n",
      "Test loss at epoch (753):  0.038246658\n",
      "Train loss at epoch (754):  0.06726522\n",
      "Test loss at epoch (754):  0.03824296\n",
      "Train loss at epoch (755):  0.06714173\n",
      "Test loss at epoch (755):  0.038237665\n",
      "Train loss at epoch (756):  0.06748475\n",
      "Test loss at epoch (756):  0.038178455\n",
      "Train loss at epoch (757):  0.06713885\n",
      "Test loss at epoch (757):  0.038181674\n",
      "Train loss at epoch (758):  0.06708007\n",
      "Test loss at epoch (758):  0.038225543\n",
      "Train loss at epoch (759):  0.06723522\n",
      "Test loss at epoch (759):  0.038304742\n",
      "Train loss at epoch (760):  0.06707204\n",
      "Test loss at epoch (760):  0.038284305\n",
      "Train loss at epoch (761):  0.067044556\n",
      "Test loss at epoch (761):  0.038240686\n",
      "Train loss at epoch (762):  0.06718406\n",
      "Test loss at epoch (762):  0.038157746\n",
      "Train loss at epoch (763):  0.06709623\n",
      "Test loss at epoch (763):  0.038204663\n",
      "Train loss at epoch (764):  0.066930965\n",
      "Test loss at epoch (764):  0.03818261\n",
      "Train loss at epoch (765):  0.067224875\n",
      "Test loss at epoch (765):  0.038273405\n",
      "Train loss at epoch (766):  0.06701753\n",
      "Test loss at epoch (766):  0.038188826\n",
      "Train loss at epoch (767):  0.067289166\n",
      "Test loss at epoch (767):  0.038194355\n",
      "Train loss at epoch (768):  0.0669998\n",
      "Test loss at epoch (768):  0.03822391\n",
      "Train loss at epoch (769):  0.06708806\n",
      "Test loss at epoch (769):  0.03816518\n",
      "Train loss at epoch (770):  0.06745649\n",
      "Test loss at epoch (770):  0.03813888\n",
      "Train loss at epoch (771):  0.06710041\n",
      "Test loss at epoch (771):  0.038073048\n",
      "Train loss at epoch (772):  0.06703787\n",
      "Test loss at epoch (772):  0.038101196\n",
      "Train loss at epoch (773):  0.06688569\n",
      "Test loss at epoch (773):  0.038165558\n",
      "Train loss at epoch (774):  0.06695849\n",
      "Test loss at epoch (774):  0.038125165\n",
      "Train loss at epoch (775):  0.066998914\n",
      "Test loss at epoch (775):  0.03802932\n",
      "Train loss at epoch (776):  0.06742019\n",
      "Test loss at epoch (776):  0.038067035\n",
      "Train loss at epoch (777):  0.067036316\n",
      "Test loss at epoch (777):  0.037974305\n",
      "Train loss at epoch (778):  0.06693348\n",
      "Test loss at epoch (778):  0.037953753\n",
      "Train loss at epoch (779):  0.06684811\n",
      "Test loss at epoch (779):  0.038029294\n",
      "Train loss at epoch (780):  0.0670269\n",
      "Test loss at epoch (780):  0.038046088\n",
      "Train loss at epoch (781):  0.06705326\n",
      "Test loss at epoch (781):  0.037998885\n",
      "Train loss at epoch (782):  0.06699228\n",
      "Test loss at epoch (782):  0.037924457\n",
      "Train loss at epoch (783):  0.06685152\n",
      "Test loss at epoch (783):  0.037922487\n",
      "Train loss at epoch (784):  0.06726862\n",
      "Test loss at epoch (784):  0.038051397\n",
      "Train loss at epoch (785):  0.06702254\n",
      "Test loss at epoch (785):  0.03804186\n",
      "Train loss at epoch (786):  0.06669683\n",
      "Test loss at epoch (786):  0.03796112\n",
      "Train loss at epoch (787):  0.06668801\n",
      "Test loss at epoch (787):  0.037993424\n",
      "Train loss at epoch (788):  0.06711752\n",
      "Test loss at epoch (788):  0.038020577\n",
      "Train loss at epoch (789):  0.06654818\n",
      "Test loss at epoch (789):  0.03792117\n",
      "Train loss at epoch (790):  0.06686009\n",
      "Test loss at epoch (790):  0.037889723\n",
      "Train loss at epoch (791):  0.066612504\n",
      "Test loss at epoch (791):  0.0379511\n",
      "Train loss at epoch (792):  0.066991724\n",
      "Test loss at epoch (792):  0.03790415\n",
      "Train loss at epoch (793):  0.0670376\n",
      "Test loss at epoch (793):  0.037918\n",
      "Train loss at epoch (794):  0.06686171\n",
      "Test loss at epoch (794):  0.037867453\n",
      "Train loss at epoch (795):  0.06695084\n",
      "Test loss at epoch (795):  0.037966635\n",
      "Train loss at epoch (796):  0.06689205\n",
      "Test loss at epoch (796):  0.037913904\n",
      "Train loss at epoch (797):  0.06660065\n",
      "Test loss at epoch (797):  0.03787129\n",
      "Train loss at epoch (798):  0.06656853\n",
      "Test loss at epoch (798):  0.037776288\n",
      "Train loss at epoch (799):  0.0667567\n",
      "Test loss at epoch (799):  0.037800565\n",
      "Train loss at epoch (800):  0.066573076\n",
      "Test loss at epoch (800):  0.037865233\n",
      "Train loss at epoch (801):  0.06688124\n",
      "Test loss at epoch (801):  0.037841536\n",
      "Train loss at epoch (802):  0.0667525\n",
      "Test loss at epoch (802):  0.0377934\n",
      "Train loss at epoch (803):  0.06647318\n",
      "Test loss at epoch (803):  0.037733275\n",
      "Train loss at epoch (804):  0.066540666\n",
      "Test loss at epoch (804):  0.03772464\n",
      "Train loss at epoch (805):  0.06637233\n",
      "Test loss at epoch (805):  0.037703544\n",
      "Train loss at epoch (806):  0.06613863\n",
      "Test loss at epoch (806):  0.037660655\n",
      "Train loss at epoch (807):  0.06655947\n",
      "Test loss at epoch (807):  0.037720133\n",
      "Train loss at epoch (808):  0.06666531\n",
      "Test loss at epoch (808):  0.03773983\n",
      "Train loss at epoch (809):  0.066489846\n",
      "Test loss at epoch (809):  0.03771193\n",
      "Train loss at epoch (810):  0.06618837\n",
      "Test loss at epoch (810):  0.037608676\n",
      "Train loss at epoch (811):  0.066588044\n",
      "Test loss at epoch (811):  0.03772309\n",
      "Train loss at epoch (812):  0.066703655\n",
      "Test loss at epoch (812):  0.037656497\n",
      "Train loss at epoch (813):  0.06664805\n",
      "Test loss at epoch (813):  0.037588708\n",
      "Train loss at epoch (814):  0.06658825\n",
      "Test loss at epoch (814):  0.037653875\n",
      "Train loss at epoch (815):  0.06656237\n",
      "Test loss at epoch (815):  0.03764529\n",
      "Train loss at epoch (816):  0.066371\n",
      "Test loss at epoch (816):  0.03757162\n",
      "Train loss at epoch (817):  0.06635134\n",
      "Test loss at epoch (817):  0.03759864\n",
      "Train loss at epoch (818):  0.06602115\n",
      "Test loss at epoch (818):  0.037577055\n",
      "Train loss at epoch (819):  0.066183016\n",
      "Test loss at epoch (819):  0.037605256\n",
      "Train loss at epoch (820):  0.06644265\n",
      "Test loss at epoch (820):  0.037588686\n",
      "Train loss at epoch (821):  0.06614406\n",
      "Test loss at epoch (821):  0.037535783\n",
      "Train loss at epoch (822):  0.06622885\n",
      "Test loss at epoch (822):  0.03755771\n",
      "Train loss at epoch (823):  0.06608169\n",
      "Test loss at epoch (823):  0.037577044\n",
      "Train loss at epoch (824):  0.06634992\n",
      "Test loss at epoch (824):  0.037547335\n",
      "Train loss at epoch (825):  0.06618971\n",
      "Test loss at epoch (825):  0.03753362\n",
      "Train loss at epoch (826):  0.06623692\n",
      "Test loss at epoch (826):  0.037550583\n",
      "Train loss at epoch (827):  0.066410944\n",
      "Test loss at epoch (827):  0.03757777\n",
      "Train loss at epoch (828):  0.066150516\n",
      "Test loss at epoch (828):  0.03758503\n",
      "Train loss at epoch (829):  0.066310324\n",
      "Test loss at epoch (829):  0.03755479\n",
      "Train loss at epoch (830):  0.066189006\n",
      "Test loss at epoch (830):  0.03757412\n",
      "Train loss at epoch (831):  0.06664334\n",
      "Test loss at epoch (831):  0.037513535\n",
      "Train loss at epoch (832):  0.06634938\n",
      "Test loss at epoch (832):  0.03758418\n",
      "Train loss at epoch (833):  0.066185296\n",
      "Test loss at epoch (833):  0.037492324\n",
      "Train loss at epoch (834):  0.06623595\n",
      "Test loss at epoch (834):  0.0374975\n",
      "Train loss at epoch (835):  0.066003285\n",
      "Test loss at epoch (835):  0.03757623\n",
      "Train loss at epoch (836):  0.06624745\n",
      "Test loss at epoch (836):  0.03745675\n",
      "Train loss at epoch (837):  0.06616316\n",
      "Test loss at epoch (837):  0.03751001\n",
      "Train loss at epoch (838):  0.06632428\n",
      "Test loss at epoch (838):  0.037434217\n",
      "Train loss at epoch (839):  0.06632282\n",
      "Test loss at epoch (839):  0.037405144\n",
      "Train loss at epoch (840):  0.06599409\n",
      "Test loss at epoch (840):  0.03750975\n",
      "Train loss at epoch (841):  0.06605676\n",
      "Test loss at epoch (841):  0.03743754\n",
      "Train loss at epoch (842):  0.06635893\n",
      "Test loss at epoch (842):  0.037519507\n",
      "Train loss at epoch (843):  0.06586588\n",
      "Test loss at epoch (843):  0.037462257\n",
      "Train loss at epoch (844):  0.06607233\n",
      "Test loss at epoch (844):  0.03742759\n",
      "Train loss at epoch (845):  0.06624376\n",
      "Test loss at epoch (845):  0.037435364\n",
      "Train loss at epoch (846):  0.06612784\n",
      "Test loss at epoch (846):  0.037425503\n",
      "Train loss at epoch (847):  0.06647069\n",
      "Test loss at epoch (847):  0.03739019\n",
      "Train loss at epoch (848):  0.066553056\n",
      "Test loss at epoch (848):  0.03739481\n",
      "Train loss at epoch (849):  0.06590607\n",
      "Test loss at epoch (849):  0.03741126\n",
      "Train loss at epoch (850):  0.065866366\n",
      "Test loss at epoch (850):  0.037355736\n",
      "Train loss at epoch (851):  0.06582655\n",
      "Test loss at epoch (851):  0.037326645\n",
      "Train loss at epoch (852):  0.066053584\n",
      "Test loss at epoch (852):  0.037316635\n",
      "Train loss at epoch (853):  0.06570834\n",
      "Test loss at epoch (853):  0.037322972\n",
      "Train loss at epoch (854):  0.065551005\n",
      "Test loss at epoch (854):  0.037288208\n",
      "Train loss at epoch (855):  0.0657885\n",
      "Test loss at epoch (855):  0.03735069\n",
      "Train loss at epoch (856):  0.06580889\n",
      "Test loss at epoch (856):  0.03728627\n",
      "Train loss at epoch (857):  0.06602877\n",
      "Test loss at epoch (857):  0.03726507\n",
      "Train loss at epoch (858):  0.06586258\n",
      "Test loss at epoch (858):  0.037278958\n",
      "Train loss at epoch (859):  0.06626264\n",
      "Test loss at epoch (859):  0.037335094\n",
      "Train loss at epoch (860):  0.06614207\n",
      "Test loss at epoch (860):  0.037375886\n",
      "Train loss at epoch (861):  0.06557528\n",
      "Test loss at epoch (861):  0.03722793\n",
      "Train loss at epoch (862):  0.06617413\n",
      "Test loss at epoch (862):  0.03724587\n",
      "Train loss at epoch (863):  0.065663\n",
      "Test loss at epoch (863):  0.037252743\n",
      "Train loss at epoch (864):  0.0661479\n",
      "Test loss at epoch (864):  0.037222784\n",
      "Train loss at epoch (865):  0.06595884\n",
      "Test loss at epoch (865):  0.037236553\n",
      "Train loss at epoch (866):  0.065697566\n",
      "Test loss at epoch (866):  0.037280053\n",
      "Train loss at epoch (867):  0.06582592\n",
      "Test loss at epoch (867):  0.03722978\n",
      "Train loss at epoch (868):  0.0659499\n",
      "Test loss at epoch (868):  0.037209556\n",
      "Train loss at epoch (869):  0.065820284\n",
      "Test loss at epoch (869):  0.03722453\n",
      "Train loss at epoch (870):  0.06571098\n",
      "Test loss at epoch (870):  0.03716045\n",
      "Train loss at epoch (871):  0.0654723\n",
      "Test loss at epoch (871):  0.037158385\n",
      "Train loss at epoch (872):  0.06618591\n",
      "Test loss at epoch (872):  0.03720357\n",
      "Train loss at epoch (873):  0.06569049\n",
      "Test loss at epoch (873):  0.037227582\n",
      "Train loss at epoch (874):  0.06587402\n",
      "Test loss at epoch (874):  0.037228823\n",
      "Train loss at epoch (875):  0.06590315\n",
      "Test loss at epoch (875):  0.0372176\n",
      "Train loss at epoch (876):  0.06613201\n",
      "Test loss at epoch (876):  0.03719243\n",
      "Train loss at epoch (877):  0.065766804\n",
      "Test loss at epoch (877):  0.037134957\n",
      "Train loss at epoch (878):  0.065663144\n",
      "Test loss at epoch (878):  0.03718402\n",
      "Train loss at epoch (879):  0.065129116\n",
      "Test loss at epoch (879):  0.03712023\n",
      "Train loss at epoch (880):  0.06633839\n",
      "Test loss at epoch (880):  0.037129372\n",
      "Train loss at epoch (881):  0.06584672\n",
      "Test loss at epoch (881):  0.037092276\n",
      "Train loss at epoch (882):  0.06573111\n",
      "Test loss at epoch (882):  0.037055183\n",
      "Train loss at epoch (883):  0.06587455\n",
      "Test loss at epoch (883):  0.037089694\n",
      "Train loss at epoch (884):  0.0655829\n",
      "Test loss at epoch (884):  0.037105173\n",
      "Train loss at epoch (885):  0.066161074\n",
      "Test loss at epoch (885):  0.03705642\n",
      "Train loss at epoch (886):  0.06591341\n",
      "Test loss at epoch (886):  0.037071493\n",
      "Train loss at epoch (887):  0.06611342\n",
      "Test loss at epoch (887):  0.037052933\n",
      "Train loss at epoch (888):  0.065523446\n",
      "Test loss at epoch (888):  0.03704175\n",
      "Train loss at epoch (889):  0.06590364\n",
      "Test loss at epoch (889):  0.037045594\n",
      "Train loss at epoch (890):  0.0656481\n",
      "Test loss at epoch (890):  0.0369779\n",
      "Train loss at epoch (891):  0.06584777\n",
      "Test loss at epoch (891):  0.03702413\n",
      "Train loss at epoch (892):  0.06567407\n",
      "Test loss at epoch (892):  0.03705049\n",
      "Train loss at epoch (893):  0.06590147\n",
      "Test loss at epoch (893):  0.037020236\n",
      "Train loss at epoch (894):  0.06567049\n",
      "Test loss at epoch (894):  0.037068386\n",
      "Train loss at epoch (895):  0.06569482\n",
      "Test loss at epoch (895):  0.037042435\n",
      "Train loss at epoch (896):  0.06554224\n",
      "Test loss at epoch (896):  0.036985993\n",
      "Train loss at epoch (897):  0.0656235\n",
      "Test loss at epoch (897):  0.03697256\n",
      "Train loss at epoch (898):  0.06599615\n",
      "Test loss at epoch (898):  0.036977023\n",
      "Train loss at epoch (899):  0.06551014\n",
      "Test loss at epoch (899):  0.037069052\n",
      "Train loss at epoch (900):  0.06582926\n",
      "Test loss at epoch (900):  0.036940053\n",
      "Train loss at epoch (901):  0.06556177\n",
      "Test loss at epoch (901):  0.036946665\n",
      "Train loss at epoch (902):  0.065924264\n",
      "Test loss at epoch (902):  0.03701126\n",
      "Train loss at epoch (903):  0.06563641\n",
      "Test loss at epoch (903):  0.036886342\n",
      "Train loss at epoch (904):  0.06562729\n",
      "Test loss at epoch (904):  0.036907785\n",
      "Train loss at epoch (905):  0.065614946\n",
      "Test loss at epoch (905):  0.03695901\n",
      "Train loss at epoch (906):  0.06550809\n",
      "Test loss at epoch (906):  0.036990747\n",
      "Train loss at epoch (907):  0.06577552\n",
      "Test loss at epoch (907):  0.036962613\n",
      "Train loss at epoch (908):  0.06555227\n",
      "Test loss at epoch (908):  0.03696966\n",
      "Train loss at epoch (909):  0.065687984\n",
      "Test loss at epoch (909):  0.03694253\n",
      "Train loss at epoch (910):  0.06554524\n",
      "Test loss at epoch (910):  0.03692026\n",
      "Train loss at epoch (911):  0.06560614\n",
      "Test loss at epoch (911):  0.036903333\n",
      "Train loss at epoch (912):  0.06528387\n",
      "Test loss at epoch (912):  0.03690235\n",
      "Train loss at epoch (913):  0.06561117\n",
      "Test loss at epoch (913):  0.03693795\n",
      "Train loss at epoch (914):  0.06551528\n",
      "Test loss at epoch (914):  0.03695831\n",
      "Train loss at epoch (915):  0.06589755\n",
      "Test loss at epoch (915):  0.03690279\n",
      "Train loss at epoch (916):  0.06529871\n",
      "Test loss at epoch (916):  0.036846466\n",
      "Train loss at epoch (917):  0.0654695\n",
      "Test loss at epoch (917):  0.03680228\n",
      "Train loss at epoch (918):  0.06521402\n",
      "Test loss at epoch (918):  0.036865383\n",
      "Train loss at epoch (919):  0.065189876\n",
      "Test loss at epoch (919):  0.036797963\n",
      "Train loss at epoch (920):  0.065747805\n",
      "Test loss at epoch (920):  0.03684023\n",
      "Train loss at epoch (921):  0.06555726\n",
      "Test loss at epoch (921):  0.036889087\n",
      "Train loss at epoch (922):  0.065364525\n",
      "Test loss at epoch (922):  0.03682828\n",
      "Train loss at epoch (923):  0.06550635\n",
      "Test loss at epoch (923):  0.03688362\n",
      "Train loss at epoch (924):  0.0651313\n",
      "Test loss at epoch (924):  0.036826134\n",
      "Train loss at epoch (925):  0.0656595\n",
      "Test loss at epoch (925):  0.036840722\n",
      "Train loss at epoch (926):  0.0651022\n",
      "Test loss at epoch (926):  0.036862027\n",
      "Train loss at epoch (927):  0.06527834\n",
      "Test loss at epoch (927):  0.036799524\n",
      "Train loss at epoch (928):  0.065166935\n",
      "Test loss at epoch (928):  0.036854237\n",
      "Train loss at epoch (929):  0.064978495\n",
      "Test loss at epoch (929):  0.03686128\n",
      "Train loss at epoch (930):  0.0652819\n",
      "Test loss at epoch (930):  0.03685042\n",
      "Train loss at epoch (931):  0.065285854\n",
      "Test loss at epoch (931):  0.03678621\n",
      "Train loss at epoch (932):  0.065129586\n",
      "Test loss at epoch (932):  0.036798935\n",
      "Train loss at epoch (933):  0.06502244\n",
      "Test loss at epoch (933):  0.036822807\n",
      "Train loss at epoch (934):  0.06549263\n",
      "Test loss at epoch (934):  0.036818612\n",
      "Train loss at epoch (935):  0.06545358\n",
      "Test loss at epoch (935):  0.03681761\n",
      "Train loss at epoch (936):  0.06544701\n",
      "Test loss at epoch (936):  0.036785815\n",
      "Train loss at epoch (937):  0.06532075\n",
      "Test loss at epoch (937):  0.036806062\n",
      "Train loss at epoch (938):  0.065412104\n",
      "Test loss at epoch (938):  0.03677747\n",
      "Train loss at epoch (939):  0.065602586\n",
      "Test loss at epoch (939):  0.0367994\n",
      "Train loss at epoch (940):  0.065147184\n",
      "Test loss at epoch (940):  0.036793735\n",
      "Train loss at epoch (941):  0.06517468\n",
      "Test loss at epoch (941):  0.03684278\n",
      "Train loss at epoch (942):  0.0654021\n",
      "Test loss at epoch (942):  0.03685072\n",
      "Train loss at epoch (943):  0.06521966\n",
      "Test loss at epoch (943):  0.036768764\n",
      "Train loss at epoch (944):  0.065186\n",
      "Test loss at epoch (944):  0.036769103\n",
      "Train loss at epoch (945):  0.065163404\n",
      "Test loss at epoch (945):  0.03666969\n",
      "Train loss at epoch (946):  0.065298565\n",
      "Test loss at epoch (946):  0.036730394\n",
      "Train loss at epoch (947):  0.065279335\n",
      "Test loss at epoch (947):  0.03678744\n",
      "Train loss at epoch (948):  0.065206766\n",
      "Test loss at epoch (948):  0.036679424\n",
      "Train loss at epoch (949):  0.06510685\n",
      "Test loss at epoch (949):  0.03665488\n",
      "Train loss at epoch (950):  0.0650245\n",
      "Test loss at epoch (950):  0.036682736\n",
      "Train loss at epoch (951):  0.065186255\n",
      "Test loss at epoch (951):  0.03668649\n",
      "Train loss at epoch (952):  0.06515918\n",
      "Test loss at epoch (952):  0.036683146\n",
      "Train loss at epoch (953):  0.064955436\n",
      "Test loss at epoch (953):  0.036682952\n",
      "Train loss at epoch (954):  0.06527505\n",
      "Test loss at epoch (954):  0.036678933\n",
      "Train loss at epoch (955):  0.06541357\n",
      "Test loss at epoch (955):  0.036681503\n",
      "Train loss at epoch (956):  0.06519603\n",
      "Test loss at epoch (956):  0.03666024\n",
      "Train loss at epoch (957):  0.06491103\n",
      "Test loss at epoch (957):  0.036637735\n",
      "Train loss at epoch (958):  0.065138936\n",
      "Test loss at epoch (958):  0.036680445\n",
      "Train loss at epoch (959):  0.065286\n",
      "Test loss at epoch (959):  0.03668446\n",
      "Train loss at epoch (960):  0.065157354\n",
      "Test loss at epoch (960):  0.03664049\n",
      "Train loss at epoch (961):  0.06522284\n",
      "Test loss at epoch (961):  0.03668519\n",
      "Train loss at epoch (962):  0.06505092\n",
      "Test loss at epoch (962):  0.036691755\n",
      "Train loss at epoch (963):  0.06490886\n",
      "Test loss at epoch (963):  0.03665864\n",
      "Train loss at epoch (964):  0.06495687\n",
      "Test loss at epoch (964):  0.036663633\n",
      "Train loss at epoch (965):  0.0653116\n",
      "Test loss at epoch (965):  0.036671676\n",
      "Train loss at epoch (966):  0.064957835\n",
      "Test loss at epoch (966):  0.03669863\n",
      "Train loss at epoch (967):  0.065158516\n",
      "Test loss at epoch (967):  0.036645025\n",
      "Train loss at epoch (968):  0.06512402\n",
      "Test loss at epoch (968):  0.0366366\n",
      "Train loss at epoch (969):  0.06497166\n",
      "Test loss at epoch (969):  0.03670321\n",
      "Train loss at epoch (970):  0.06496742\n",
      "Test loss at epoch (970):  0.036703583\n",
      "Train loss at epoch (971):  0.06501691\n",
      "Test loss at epoch (971):  0.036725007\n",
      "Train loss at epoch (972):  0.065148994\n",
      "Test loss at epoch (972):  0.036610004\n",
      "Train loss at epoch (973):  0.06518935\n",
      "Test loss at epoch (973):  0.03658365\n",
      "Train loss at epoch (974):  0.06499095\n",
      "Test loss at epoch (974):  0.036620777\n",
      "Train loss at epoch (975):  0.065075904\n",
      "Test loss at epoch (975):  0.03656316\n",
      "Train loss at epoch (976):  0.0649681\n",
      "Test loss at epoch (976):  0.036537234\n",
      "Train loss at epoch (977):  0.06491241\n",
      "Test loss at epoch (977):  0.03660294\n",
      "Train loss at epoch (978):  0.06499436\n",
      "Test loss at epoch (978):  0.036560424\n",
      "Train loss at epoch (979):  0.06512517\n",
      "Test loss at epoch (979):  0.036525946\n",
      "Train loss at epoch (980):  0.06522625\n",
      "Test loss at epoch (980):  0.03654493\n",
      "Train loss at epoch (981):  0.06468272\n",
      "Test loss at epoch (981):  0.036524307\n",
      "Train loss at epoch (982):  0.06505405\n",
      "Test loss at epoch (982):  0.03648868\n",
      "Train loss at epoch (983):  0.06531424\n",
      "Test loss at epoch (983):  0.036482196\n",
      "Train loss at epoch (984):  0.06482083\n",
      "Test loss at epoch (984):  0.03652278\n",
      "Train loss at epoch (985):  0.06494736\n",
      "Test loss at epoch (985):  0.036508463\n",
      "Train loss at epoch (986):  0.06465538\n",
      "Test loss at epoch (986):  0.036560014\n",
      "Train loss at epoch (987):  0.065318085\n",
      "Test loss at epoch (987):  0.036526375\n",
      "Train loss at epoch (988):  0.06491524\n",
      "Test loss at epoch (988):  0.036534656\n",
      "Train loss at epoch (989):  0.06474159\n",
      "Test loss at epoch (989):  0.036556717\n",
      "Train loss at epoch (990):  0.06480761\n",
      "Test loss at epoch (990):  0.036540307\n",
      "Train loss at epoch (991):  0.065138295\n",
      "Test loss at epoch (991):  0.03654037\n",
      "Train loss at epoch (992):  0.06497124\n",
      "Test loss at epoch (992):  0.036504555\n",
      "Train loss at epoch (993):  0.06470123\n",
      "Test loss at epoch (993):  0.036471542\n",
      "Train loss at epoch (994):  0.06465104\n",
      "Test loss at epoch (994):  0.03647594\n",
      "Train loss at epoch (995):  0.064758174\n",
      "Test loss at epoch (995):  0.036412653\n",
      "Train loss at epoch (996):  0.06506149\n",
      "Test loss at epoch (996):  0.036502033\n",
      "Train loss at epoch (997):  0.0652186\n",
      "Test loss at epoch (997):  0.036452286\n",
      "Train loss at epoch (998):  0.06475785\n",
      "Test loss at epoch (998):  0.03645408\n",
      "Train loss at epoch (999):  0.065006405\n",
      "Test loss at epoch (999):  0.036461003\n",
      "Train loss at epoch (1000):  0.06465757\n",
      "Test loss at epoch (1000):  0.03651799\n",
      "Train loss at epoch (1001):  0.06436397\n",
      "Test loss at epoch (1001):  0.03648904\n",
      "Train loss at epoch (1002):  0.0647979\n",
      "Test loss at epoch (1002):  0.03643953\n",
      "Train loss at epoch (1003):  0.06483872\n",
      "Test loss at epoch (1003):  0.036494743\n",
      "Train loss at epoch (1004):  0.06491911\n",
      "Test loss at epoch (1004):  0.03642845\n",
      "Train loss at epoch (1005):  0.06503228\n",
      "Test loss at epoch (1005):  0.036456194\n",
      "Train loss at epoch (1006):  0.06462815\n",
      "Test loss at epoch (1006):  0.036479894\n",
      "Train loss at epoch (1007):  0.064496994\n",
      "Test loss at epoch (1007):  0.036445986\n",
      "Train loss at epoch (1008):  0.064595014\n",
      "Test loss at epoch (1008):  0.036429964\n",
      "Train loss at epoch (1009):  0.064655855\n",
      "Test loss at epoch (1009):  0.036441155\n",
      "Train loss at epoch (1010):  0.06492859\n",
      "Test loss at epoch (1010):  0.036427677\n",
      "Train loss at epoch (1011):  0.06496475\n",
      "Test loss at epoch (1011):  0.036432758\n",
      "Train loss at epoch (1012):  0.06501964\n",
      "Test loss at epoch (1012):  0.036489557\n",
      "Train loss at epoch (1013):  0.064721316\n",
      "Test loss at epoch (1013):  0.03648758\n",
      "Train loss at epoch (1014):  0.06464934\n",
      "Test loss at epoch (1014):  0.03637052\n",
      "Train loss at epoch (1015):  0.064774945\n",
      "Test loss at epoch (1015):  0.036399014\n",
      "Train loss at epoch (1016):  0.06483896\n",
      "Test loss at epoch (1016):  0.03644778\n",
      "Train loss at epoch (1017):  0.06493018\n",
      "Test loss at epoch (1017):  0.036371704\n",
      "Train loss at epoch (1018):  0.064628996\n",
      "Test loss at epoch (1018):  0.036372125\n",
      "Train loss at epoch (1019):  0.06499689\n",
      "Test loss at epoch (1019):  0.03636212\n",
      "Train loss at epoch (1020):  0.064461485\n",
      "Test loss at epoch (1020):  0.036388416\n",
      "Train loss at epoch (1021):  0.06456852\n",
      "Test loss at epoch (1021):  0.0364165\n",
      "Train loss at epoch (1022):  0.06441056\n",
      "Test loss at epoch (1022):  0.036374845\n",
      "Train loss at epoch (1023):  0.06472496\n",
      "Test loss at epoch (1023):  0.036381934\n",
      "Train loss at epoch (1024):  0.06491111\n",
      "Test loss at epoch (1024):  0.036369286\n",
      "Train loss at epoch (1025):  0.06460424\n",
      "Test loss at epoch (1025):  0.03634043\n",
      "Train loss at epoch (1026):  0.06461123\n",
      "Test loss at epoch (1026):  0.036396604\n",
      "Train loss at epoch (1027):  0.06489595\n",
      "Test loss at epoch (1027):  0.036368042\n",
      "Train loss at epoch (1028):  0.06517065\n",
      "Test loss at epoch (1028):  0.036330156\n",
      "Train loss at epoch (1029):  0.06467707\n",
      "Test loss at epoch (1029):  0.03638199\n",
      "Train loss at epoch (1030):  0.06468312\n",
      "Test loss at epoch (1030):  0.03635128\n",
      "Train loss at epoch (1031):  0.06445748\n",
      "Test loss at epoch (1031):  0.03638054\n",
      "Train loss at epoch (1032):  0.06498572\n",
      "Test loss at epoch (1032):  0.036350783\n",
      "Train loss at epoch (1033):  0.06454655\n",
      "Test loss at epoch (1033):  0.036357936\n",
      "Train loss at epoch (1034):  0.06495976\n",
      "Test loss at epoch (1034):  0.03637139\n",
      "Train loss at epoch (1035):  0.06478785\n",
      "Test loss at epoch (1035):  0.03639219\n",
      "Train loss at epoch (1036):  0.0649727\n",
      "Test loss at epoch (1036):  0.036367115\n",
      "Train loss at epoch (1037):  0.06479845\n",
      "Test loss at epoch (1037):  0.03633891\n",
      "Train loss at epoch (1038):  0.064454935\n",
      "Test loss at epoch (1038):  0.036382105\n",
      "Train loss at epoch (1039):  0.06479484\n",
      "Test loss at epoch (1039):  0.036334965\n",
      "Train loss at epoch (1040):  0.06455408\n",
      "Test loss at epoch (1040):  0.036397953\n",
      "Train loss at epoch (1041):  0.06475168\n",
      "Test loss at epoch (1041):  0.03639191\n",
      "Train loss at epoch (1042):  0.06436188\n",
      "Test loss at epoch (1042):  0.036403883\n",
      "Train loss at epoch (1043):  0.0645498\n",
      "Test loss at epoch (1043):  0.036399774\n",
      "Train loss at epoch (1044):  0.06455252\n",
      "Test loss at epoch (1044):  0.036363374\n",
      "Train loss at epoch (1045):  0.064608395\n",
      "Test loss at epoch (1045):  0.036351997\n",
      "Train loss at epoch (1046):  0.06507867\n",
      "Test loss at epoch (1046):  0.036329076\n",
      "Train loss at epoch (1047):  0.064782076\n",
      "Test loss at epoch (1047):  0.03632047\n",
      "Train loss at epoch (1048):  0.06462001\n",
      "Test loss at epoch (1048):  0.03631226\n",
      "Train loss at epoch (1049):  0.064641364\n",
      "Test loss at epoch (1049):  0.036347132\n",
      "Train loss at epoch (1050):  0.06469105\n",
      "Test loss at epoch (1050):  0.036270767\n",
      "Train loss at epoch (1051):  0.064633235\n",
      "Test loss at epoch (1051):  0.036277037\n",
      "Train loss at epoch (1052):  0.06477801\n",
      "Test loss at epoch (1052):  0.036314454\n",
      "Train loss at epoch (1053):  0.06467275\n",
      "Test loss at epoch (1053):  0.03625787\n",
      "Train loss at epoch (1054):  0.06460518\n",
      "Test loss at epoch (1054):  0.036316015\n",
      "Train loss at epoch (1055):  0.0646337\n",
      "Test loss at epoch (1055):  0.036283147\n",
      "Train loss at epoch (1056):  0.06452134\n",
      "Test loss at epoch (1056):  0.0362498\n",
      "Train loss at epoch (1057):  0.06435509\n",
      "Test loss at epoch (1057):  0.03623953\n",
      "Train loss at epoch (1058):  0.06462375\n",
      "Test loss at epoch (1058):  0.03618151\n",
      "Train loss at epoch (1059):  0.06425435\n",
      "Test loss at epoch (1059):  0.036257476\n",
      "Train loss at epoch (1060):  0.064613275\n",
      "Test loss at epoch (1060):  0.036210943\n",
      "Train loss at epoch (1061):  0.06424961\n",
      "Test loss at epoch (1061):  0.036212943\n",
      "Train loss at epoch (1062):  0.06470499\n",
      "Test loss at epoch (1062):  0.036219947\n",
      "Train loss at epoch (1063):  0.064404055\n",
      "Test loss at epoch (1063):  0.036255628\n",
      "Train loss at epoch (1064):  0.06429057\n",
      "Test loss at epoch (1064):  0.036249656\n",
      "Train loss at epoch (1065):  0.06441877\n",
      "Test loss at epoch (1065):  0.036185503\n",
      "Train loss at epoch (1066):  0.06439502\n",
      "Test loss at epoch (1066):  0.03623001\n",
      "Train loss at epoch (1067):  0.064868264\n",
      "Test loss at epoch (1067):  0.036251534\n",
      "Train loss at epoch (1068):  0.064459845\n",
      "Test loss at epoch (1068):  0.036261827\n",
      "Train loss at epoch (1069):  0.06465054\n",
      "Test loss at epoch (1069):  0.036213003\n",
      "Train loss at epoch (1070):  0.06453894\n",
      "Test loss at epoch (1070):  0.036181364\n",
      "Train loss at epoch (1071):  0.06431985\n",
      "Test loss at epoch (1071):  0.036166858\n",
      "Train loss at epoch (1072):  0.06424542\n",
      "Test loss at epoch (1072):  0.036203805\n",
      "Train loss at epoch (1073):  0.06464219\n",
      "Test loss at epoch (1073):  0.03618329\n",
      "Train loss at epoch (1074):  0.06469481\n",
      "Test loss at epoch (1074):  0.036176458\n",
      "Train loss at epoch (1075):  0.06437447\n",
      "Test loss at epoch (1075):  0.036178052\n",
      "Train loss at epoch (1076):  0.06465419\n",
      "Test loss at epoch (1076):  0.03617487\n",
      "Train loss at epoch (1077):  0.06477908\n",
      "Test loss at epoch (1077):  0.036185533\n",
      "Train loss at epoch (1078):  0.0641212\n",
      "Test loss at epoch (1078):  0.036192805\n",
      "Train loss at epoch (1079):  0.064607084\n",
      "Test loss at epoch (1079):  0.036183976\n",
      "Train loss at epoch (1080):  0.0644852\n",
      "Test loss at epoch (1080):  0.036148693\n",
      "Train loss at epoch (1081):  0.06449254\n",
      "Test loss at epoch (1081):  0.036182035\n",
      "Train loss at epoch (1082):  0.06436489\n",
      "Test loss at epoch (1082):  0.03620418\n",
      "Train loss at epoch (1083):  0.0644435\n",
      "Test loss at epoch (1083):  0.036143303\n",
      "Train loss at epoch (1084):  0.06436441\n",
      "Test loss at epoch (1084):  0.036145937\n",
      "Train loss at epoch (1085):  0.064545095\n",
      "Test loss at epoch (1085):  0.036153153\n",
      "Train loss at epoch (1086):  0.06429835\n",
      "Test loss at epoch (1086):  0.036119293\n",
      "Train loss at epoch (1087):  0.064733095\n",
      "Test loss at epoch (1087):  0.0361552\n",
      "Train loss at epoch (1088):  0.0641968\n",
      "Test loss at epoch (1088):  0.036179937\n",
      "Train loss at epoch (1089):  0.06457062\n",
      "Test loss at epoch (1089):  0.036139645\n",
      "Train loss at epoch (1090):  0.0645744\n",
      "Test loss at epoch (1090):  0.036179524\n",
      "Train loss at epoch (1091):  0.064438745\n",
      "Test loss at epoch (1091):  0.036134176\n",
      "Train loss at epoch (1092):  0.06454231\n",
      "Test loss at epoch (1092):  0.03614925\n",
      "Train loss at epoch (1093):  0.06518223\n",
      "Test loss at epoch (1093):  0.036136582\n",
      "Train loss at epoch (1094):  0.064526476\n",
      "Test loss at epoch (1094):  0.036137253\n",
      "Train loss at epoch (1095):  0.06448886\n",
      "Test loss at epoch (1095):  0.036150303\n",
      "Train loss at epoch (1096):  0.064587735\n",
      "Test loss at epoch (1096):  0.03612406\n",
      "Train loss at epoch (1097):  0.06419109\n",
      "Test loss at epoch (1097):  0.036098577\n",
      "Train loss at epoch (1098):  0.064496934\n",
      "Test loss at epoch (1098):  0.036137186\n",
      "Train loss at epoch (1099):  0.064372584\n",
      "Test loss at epoch (1099):  0.036140636\n",
      "Train loss at epoch (1100):  0.06443155\n",
      "Test loss at epoch (1100):  0.03615655\n",
      "Train loss at epoch (1101):  0.064496495\n",
      "Test loss at epoch (1101):  0.03611629\n",
      "Train loss at epoch (1102):  0.064168066\n",
      "Test loss at epoch (1102):  0.03611503\n",
      "Train loss at epoch (1103):  0.06460053\n",
      "Test loss at epoch (1103):  0.03608291\n",
      "Train loss at epoch (1104):  0.06452991\n",
      "Test loss at epoch (1104):  0.036100868\n",
      "Train loss at epoch (1105):  0.06427646\n",
      "Test loss at epoch (1105):  0.036057107\n",
      "Train loss at epoch (1106):  0.06418059\n",
      "Test loss at epoch (1106):  0.03604646\n",
      "Train loss at epoch (1107):  0.064530104\n",
      "Test loss at epoch (1107):  0.03608973\n",
      "Train loss at epoch (1108):  0.06411122\n",
      "Test loss at epoch (1108):  0.03606817\n",
      "Train loss at epoch (1109):  0.06444228\n",
      "Test loss at epoch (1109):  0.036091328\n",
      "Train loss at epoch (1110):  0.064447775\n",
      "Test loss at epoch (1110):  0.036041986\n",
      "Train loss at epoch (1111):  0.064681314\n",
      "Test loss at epoch (1111):  0.036084868\n",
      "Train loss at epoch (1112):  0.064315304\n",
      "Test loss at epoch (1112):  0.0360581\n",
      "Train loss at epoch (1113):  0.064025596\n",
      "Test loss at epoch (1113):  0.03608459\n",
      "Train loss at epoch (1114):  0.06465433\n",
      "Test loss at epoch (1114):  0.03608434\n",
      "Train loss at epoch (1115):  0.064390436\n",
      "Test loss at epoch (1115):  0.03606182\n",
      "Train loss at epoch (1116):  0.06408741\n",
      "Test loss at epoch (1116):  0.03607623\n",
      "Train loss at epoch (1117):  0.0644044\n",
      "Test loss at epoch (1117):  0.035995565\n",
      "Train loss at epoch (1118):  0.0640862\n",
      "Test loss at epoch (1118):  0.036027443\n",
      "Train loss at epoch (1119):  0.06396973\n",
      "Test loss at epoch (1119):  0.036042713\n",
      "Train loss at epoch (1120):  0.064423874\n",
      "Test loss at epoch (1120):  0.03606539\n",
      "Train loss at epoch (1121):  0.06412346\n",
      "Test loss at epoch (1121):  0.036129396\n",
      "Train loss at epoch (1122):  0.06431597\n",
      "Test loss at epoch (1122):  0.036053665\n",
      "Train loss at epoch (1123):  0.064145595\n",
      "Test loss at epoch (1123):  0.03610344\n",
      "Train loss at epoch (1124):  0.0644068\n",
      "Test loss at epoch (1124):  0.036117684\n",
      "Train loss at epoch (1125):  0.06414969\n",
      "Test loss at epoch (1125):  0.036120795\n",
      "Train loss at epoch (1126):  0.06397654\n",
      "Test loss at epoch (1126):  0.036052037\n",
      "Train loss at epoch (1127):  0.06435854\n",
      "Test loss at epoch (1127):  0.036086768\n",
      "Train loss at epoch (1128):  0.06441608\n",
      "Test loss at epoch (1128):  0.03605099\n",
      "Train loss at epoch (1129):  0.06423323\n",
      "Test loss at epoch (1129):  0.03605531\n",
      "Train loss at epoch (1130):  0.064424194\n",
      "Test loss at epoch (1130):  0.036066644\n",
      "Train loss at epoch (1131):  0.064077996\n",
      "Test loss at epoch (1131):  0.03605257\n",
      "Train loss at epoch (1132):  0.064405024\n",
      "Test loss at epoch (1132):  0.036074802\n",
      "Train loss at epoch (1133):  0.06426786\n",
      "Test loss at epoch (1133):  0.036075164\n",
      "Train loss at epoch (1134):  0.06438987\n",
      "Test loss at epoch (1134):  0.036024377\n",
      "Train loss at epoch (1135):  0.06433522\n",
      "Test loss at epoch (1135):  0.03604734\n",
      "Train loss at epoch (1136):  0.064457536\n",
      "Test loss at epoch (1136):  0.03604066\n",
      "Train loss at epoch (1137):  0.064198814\n",
      "Test loss at epoch (1137):  0.036055952\n",
      "Train loss at epoch (1138):  0.064422846\n",
      "Test loss at epoch (1138):  0.036043197\n",
      "Train loss at epoch (1139):  0.06419357\n",
      "Test loss at epoch (1139):  0.036011267\n",
      "Train loss at epoch (1140):  0.06438041\n",
      "Test loss at epoch (1140):  0.03598858\n",
      "Train loss at epoch (1141):  0.064212784\n",
      "Test loss at epoch (1141):  0.036001783\n",
      "Train loss at epoch (1142):  0.064118154\n",
      "Test loss at epoch (1142):  0.036052816\n",
      "Train loss at epoch (1143):  0.06443737\n",
      "Test loss at epoch (1143):  0.036029886\n",
      "Train loss at epoch (1144):  0.0642048\n",
      "Test loss at epoch (1144):  0.035992414\n",
      "Train loss at epoch (1145):  0.06427691\n",
      "Test loss at epoch (1145):  0.036003787\n",
      "Train loss at epoch (1146):  0.064044066\n",
      "Test loss at epoch (1146):  0.036026597\n",
      "Train loss at epoch (1147):  0.06422018\n",
      "Test loss at epoch (1147):  0.03598974\n",
      "Train loss at epoch (1148):  0.06444425\n",
      "Test loss at epoch (1148):  0.036000572\n",
      "Train loss at epoch (1149):  0.06392728\n",
      "Test loss at epoch (1149):  0.036002513\n",
      "Train loss at epoch (1150):  0.06450254\n",
      "Test loss at epoch (1150):  0.035966475\n",
      "Train loss at epoch (1151):  0.06440428\n",
      "Test loss at epoch (1151):  0.03599021\n",
      "Train loss at epoch (1152):  0.06434324\n",
      "Test loss at epoch (1152):  0.03599741\n",
      "Train loss at epoch (1153):  0.064458966\n",
      "Test loss at epoch (1153):  0.035998795\n",
      "Train loss at epoch (1154):  0.06435704\n",
      "Test loss at epoch (1154):  0.036015652\n",
      "Train loss at epoch (1155):  0.06396292\n",
      "Test loss at epoch (1155):  0.03600069\n",
      "Train loss at epoch (1156):  0.06425425\n",
      "Test loss at epoch (1156):  0.03598409\n",
      "Train loss at epoch (1157):  0.064072415\n",
      "Test loss at epoch (1157):  0.03596132\n",
      "Train loss at epoch (1158):  0.06417661\n",
      "Test loss at epoch (1158):  0.035947494\n",
      "Train loss at epoch (1159):  0.06437074\n",
      "Test loss at epoch (1159):  0.035966244\n",
      "Train loss at epoch (1160):  0.06434785\n",
      "Test loss at epoch (1160):  0.035940524\n",
      "Train loss at epoch (1161):  0.06406378\n",
      "Test loss at epoch (1161):  0.035963327\n",
      "Train loss at epoch (1162):  0.064267404\n",
      "Test loss at epoch (1162):  0.03594332\n",
      "Train loss at epoch (1163):  0.06405126\n",
      "Test loss at epoch (1163):  0.035952\n",
      "Train loss at epoch (1164):  0.06414472\n",
      "Test loss at epoch (1164):  0.036007375\n",
      "Train loss at epoch (1165):  0.06437767\n",
      "Test loss at epoch (1165):  0.035960436\n",
      "Train loss at epoch (1166):  0.06401183\n",
      "Test loss at epoch (1166):  0.03596277\n",
      "Train loss at epoch (1167):  0.06430629\n",
      "Test loss at epoch (1167):  0.035951387\n",
      "Train loss at epoch (1168):  0.06430269\n",
      "Test loss at epoch (1168):  0.035942886\n",
      "Train loss at epoch (1169):  0.06427648\n",
      "Test loss at epoch (1169):  0.035956234\n",
      "Train loss at epoch (1170):  0.06400184\n",
      "Test loss at epoch (1170):  0.035923894\n",
      "Train loss at epoch (1171):  0.06440905\n",
      "Test loss at epoch (1171):  0.035937827\n",
      "Train loss at epoch (1172):  0.06395693\n",
      "Test loss at epoch (1172):  0.035923053\n",
      "Train loss at epoch (1173):  0.06436786\n",
      "Test loss at epoch (1173):  0.035900444\n",
      "Train loss at epoch (1174):  0.06399173\n",
      "Test loss at epoch (1174):  0.035910808\n",
      "Train loss at epoch (1175):  0.06429193\n",
      "Test loss at epoch (1175):  0.035935525\n",
      "Train loss at epoch (1176):  0.06371424\n",
      "Test loss at epoch (1176):  0.03596293\n",
      "Train loss at epoch (1177):  0.06421779\n",
      "Test loss at epoch (1177):  0.035945687\n",
      "Train loss at epoch (1178):  0.06411457\n",
      "Test loss at epoch (1178):  0.035902087\n",
      "Train loss at epoch (1179):  0.0643014\n",
      "Test loss at epoch (1179):  0.035918795\n",
      "Train loss at epoch (1180):  0.064022824\n",
      "Test loss at epoch (1180):  0.035887185\n",
      "Train loss at epoch (1181):  0.06422089\n",
      "Test loss at epoch (1181):  0.035917196\n",
      "Train loss at epoch (1182):  0.06425419\n",
      "Test loss at epoch (1182):  0.035886984\n",
      "Train loss at epoch (1183):  0.06406509\n",
      "Test loss at epoch (1183):  0.03588657\n",
      "Train loss at epoch (1184):  0.06432574\n",
      "Test loss at epoch (1184):  0.03594448\n",
      "Train loss at epoch (1185):  0.063782096\n",
      "Test loss at epoch (1185):  0.035922356\n",
      "Train loss at epoch (1186):  0.064132966\n",
      "Test loss at epoch (1186):  0.035900164\n",
      "Train loss at epoch (1187):  0.063821375\n",
      "Test loss at epoch (1187):  0.03593161\n",
      "Train loss at epoch (1188):  0.06415092\n",
      "Test loss at epoch (1188):  0.035915125\n",
      "Train loss at epoch (1189):  0.06419055\n",
      "Test loss at epoch (1189):  0.035913307\n",
      "Train loss at epoch (1190):  0.06432637\n",
      "Test loss at epoch (1190):  0.035909444\n",
      "Train loss at epoch (1191):  0.06384175\n",
      "Test loss at epoch (1191):  0.035907194\n",
      "Train loss at epoch (1192):  0.06442943\n",
      "Test loss at epoch (1192):  0.035910074\n",
      "Train loss at epoch (1193):  0.064192556\n",
      "Test loss at epoch (1193):  0.035920013\n",
      "Train loss at epoch (1194):  0.06425309\n",
      "Test loss at epoch (1194):  0.035928275\n",
      "Train loss at epoch (1195):  0.06392458\n",
      "Test loss at epoch (1195):  0.03589058\n",
      "Train loss at epoch (1196):  0.064252265\n",
      "Test loss at epoch (1196):  0.0359019\n",
      "Train loss at epoch (1197):  0.06424708\n",
      "Test loss at epoch (1197):  0.0358931\n",
      "Train loss at epoch (1198):  0.064289205\n",
      "Test loss at epoch (1198):  0.035906855\n",
      "Train loss at epoch (1199):  0.06429198\n",
      "Test loss at epoch (1199):  0.03589378\n",
      "Train loss at epoch (1200):  0.064218126\n",
      "Test loss at epoch (1200):  0.035914913\n",
      "Train loss at epoch (1201):  0.06417007\n",
      "Test loss at epoch (1201):  0.03592133\n",
      "Train loss at epoch (1202):  0.0638104\n",
      "Test loss at epoch (1202):  0.035892677\n",
      "Train loss at epoch (1203):  0.06427091\n",
      "Test loss at epoch (1203):  0.035898697\n",
      "Train loss at epoch (1204):  0.06428072\n",
      "Test loss at epoch (1204):  0.035921905\n",
      "Train loss at epoch (1205):  0.06390955\n",
      "Test loss at epoch (1205):  0.035878766\n",
      "Train loss at epoch (1206):  0.06398967\n",
      "Test loss at epoch (1206):  0.035958875\n",
      "Train loss at epoch (1207):  0.06386074\n",
      "Test loss at epoch (1207):  0.035879605\n",
      "Train loss at epoch (1208):  0.064184226\n",
      "Test loss at epoch (1208):  0.03590688\n",
      "Train loss at epoch (1209):  0.06392178\n",
      "Test loss at epoch (1209):  0.0359051\n",
      "Train loss at epoch (1210):  0.06394716\n",
      "Test loss at epoch (1210):  0.035896875\n",
      "Train loss at epoch (1211):  0.06396583\n",
      "Test loss at epoch (1211):  0.03588467\n",
      "Train loss at epoch (1212):  0.064323924\n",
      "Test loss at epoch (1212):  0.035879474\n",
      "Train loss at epoch (1213):  0.06384995\n",
      "Test loss at epoch (1213):  0.035905126\n",
      "Train loss at epoch (1214):  0.06410399\n",
      "Test loss at epoch (1214):  0.035895716\n",
      "Train loss at epoch (1215):  0.06419195\n",
      "Test loss at epoch (1215):  0.03586567\n",
      "Train loss at epoch (1216):  0.064157456\n",
      "Test loss at epoch (1216):  0.035944045\n",
      "Train loss at epoch (1217):  0.06412414\n",
      "Test loss at epoch (1217):  0.0358796\n",
      "Train loss at epoch (1218):  0.06406123\n",
      "Test loss at epoch (1218):  0.035895195\n",
      "Train loss at epoch (1219):  0.06379936\n",
      "Test loss at epoch (1219):  0.035870243\n",
      "Train loss at epoch (1220):  0.06419761\n",
      "Test loss at epoch (1220):  0.03588887\n",
      "Train loss at epoch (1221):  0.06388377\n",
      "Test loss at epoch (1221):  0.03586367\n",
      "Train loss at epoch (1222):  0.064092495\n",
      "Test loss at epoch (1222):  0.035882358\n",
      "Train loss at epoch (1223):  0.06431266\n",
      "Test loss at epoch (1223):  0.035871908\n",
      "Train loss at epoch (1224):  0.06405754\n",
      "Test loss at epoch (1224):  0.035895377\n",
      "Train loss at epoch (1225):  0.06413327\n",
      "Test loss at epoch (1225):  0.03584944\n",
      "Train loss at epoch (1226):  0.06408945\n",
      "Test loss at epoch (1226):  0.035863146\n",
      "Train loss at epoch (1227):  0.0642979\n",
      "Test loss at epoch (1227):  0.03589464\n",
      "Train loss at epoch (1228):  0.06389399\n",
      "Test loss at epoch (1228):  0.035926133\n",
      "Train loss at epoch (1229):  0.06428664\n",
      "Test loss at epoch (1229):  0.03590208\n",
      "Train loss at epoch (1230):  0.06398532\n",
      "Test loss at epoch (1230):  0.035902787\n",
      "Train loss at epoch (1231):  0.064118005\n",
      "Test loss at epoch (1231):  0.035879925\n",
      "Train loss at epoch (1232):  0.064215854\n",
      "Test loss at epoch (1232):  0.035882097\n",
      "Train loss at epoch (1233):  0.064099304\n",
      "Test loss at epoch (1233):  0.03588191\n",
      "Train loss at epoch (1234):  0.064003736\n",
      "Test loss at epoch (1234):  0.035860166\n",
      "Train loss at epoch (1235):  0.064154\n",
      "Test loss at epoch (1235):  0.035887226\n",
      "Train loss at epoch (1236):  0.063967645\n",
      "Test loss at epoch (1236):  0.035895582\n",
      "Train loss at epoch (1237):  0.06426369\n",
      "Test loss at epoch (1237):  0.035872396\n",
      "Train loss at epoch (1238):  0.06389927\n",
      "Test loss at epoch (1238):  0.035832584\n",
      "Train loss at epoch (1239):  0.06418043\n",
      "Test loss at epoch (1239):  0.03582368\n",
      "Train loss at epoch (1240):  0.06397334\n",
      "Test loss at epoch (1240):  0.035844333\n",
      "Train loss at epoch (1241):  0.06384913\n",
      "Test loss at epoch (1241):  0.03585871\n",
      "Train loss at epoch (1242):  0.06390166\n",
      "Test loss at epoch (1242):  0.035881456\n",
      "Train loss at epoch (1243):  0.06376269\n",
      "Test loss at epoch (1243):  0.035878412\n",
      "Train loss at epoch (1244):  0.06400613\n",
      "Test loss at epoch (1244):  0.035886716\n",
      "Train loss at epoch (1245):  0.06389081\n",
      "Test loss at epoch (1245):  0.035871934\n",
      "Train loss at epoch (1246):  0.06404451\n",
      "Test loss at epoch (1246):  0.035868134\n",
      "Train loss at epoch (1247):  0.06396324\n",
      "Test loss at epoch (1247):  0.035865713\n",
      "Train loss at epoch (1248):  0.064138606\n",
      "Test loss at epoch (1248):  0.035830423\n",
      "Train loss at epoch (1249):  0.06416397\n",
      "Test loss at epoch (1249):  0.0358619\n",
      "Train loss at epoch (1250):  0.063804604\n",
      "Test loss at epoch (1250):  0.03585797\n",
      "Train loss at epoch (1251):  0.06426003\n",
      "Test loss at epoch (1251):  0.035828248\n",
      "Train loss at epoch (1252):  0.06386192\n",
      "Test loss at epoch (1252):  0.035841547\n",
      "Train loss at epoch (1253):  0.06411388\n",
      "Test loss at epoch (1253):  0.035851754\n",
      "Train loss at epoch (1254):  0.06408381\n",
      "Test loss at epoch (1254):  0.03587009\n",
      "Train loss at epoch (1255):  0.0641566\n",
      "Test loss at epoch (1255):  0.03583033\n",
      "Train loss at epoch (1256):  0.06405117\n",
      "Test loss at epoch (1256):  0.035845328\n",
      "Train loss at epoch (1257):  0.06396896\n",
      "Test loss at epoch (1257):  0.035857245\n",
      "Train loss at epoch (1258):  0.063995175\n",
      "Test loss at epoch (1258):  0.035862505\n",
      "Train loss at epoch (1259):  0.06453705\n",
      "Test loss at epoch (1259):  0.03585309\n",
      "Train loss at epoch (1260):  0.06397794\n",
      "Test loss at epoch (1260):  0.03588147\n",
      "Train loss at epoch (1261):  0.0638096\n",
      "Test loss at epoch (1261):  0.035811156\n",
      "Train loss at epoch (1262):  0.06391627\n",
      "Test loss at epoch (1262):  0.035814375\n",
      "Train loss at epoch (1263):  0.06376153\n",
      "Test loss at epoch (1263):  0.035838436\n",
      "Train loss at epoch (1264):  0.06417856\n",
      "Test loss at epoch (1264):  0.035849106\n",
      "Train loss at epoch (1265):  0.06399434\n",
      "Test loss at epoch (1265):  0.035845138\n",
      "Train loss at epoch (1266):  0.06399786\n",
      "Test loss at epoch (1266):  0.035852198\n",
      "Train loss at epoch (1267):  0.06391818\n",
      "Test loss at epoch (1267):  0.03580819\n",
      "Train loss at epoch (1268):  0.06380775\n",
      "Test loss at epoch (1268):  0.03584692\n",
      "Train loss at epoch (1269):  0.06407575\n",
      "Test loss at epoch (1269):  0.03583165\n",
      "Train loss at epoch (1270):  0.06415327\n",
      "Test loss at epoch (1270):  0.035818502\n",
      "Train loss at epoch (1271):  0.06408075\n",
      "Test loss at epoch (1271):  0.035865538\n",
      "Train loss at epoch (1272):  0.06388702\n",
      "Test loss at epoch (1272):  0.035846088\n",
      "Train loss at epoch (1273):  0.06421662\n",
      "Test loss at epoch (1273):  0.03581943\n",
      "Train loss at epoch (1274):  0.06388723\n",
      "Test loss at epoch (1274):  0.035868794\n",
      "Train loss at epoch (1275):  0.06405962\n",
      "Test loss at epoch (1275):  0.035841733\n",
      "Train loss at epoch (1276):  0.064287476\n",
      "Test loss at epoch (1276):  0.035863712\n",
      "Train loss at epoch (1277):  0.06420018\n",
      "Test loss at epoch (1277):  0.035822816\n",
      "Train loss at epoch (1278):  0.06421191\n",
      "Test loss at epoch (1278):  0.035822704\n",
      "Train loss at epoch (1279):  0.06419751\n",
      "Test loss at epoch (1279):  0.03585711\n",
      "Train loss at epoch (1280):  0.06440903\n",
      "Test loss at epoch (1280):  0.035781275\n",
      "Train loss at epoch (1281):  0.06379295\n",
      "Test loss at epoch (1281):  0.035839427\n",
      "Train loss at epoch (1282):  0.06408134\n",
      "Test loss at epoch (1282):  0.03579783\n",
      "Train loss at epoch (1283):  0.06379288\n",
      "Test loss at epoch (1283):  0.035802342\n",
      "Train loss at epoch (1284):  0.06419814\n",
      "Test loss at epoch (1284):  0.03582628\n",
      "Train loss at epoch (1285):  0.06403006\n",
      "Test loss at epoch (1285):  0.03581677\n",
      "Train loss at epoch (1286):  0.06395653\n",
      "Test loss at epoch (1286):  0.035830148\n",
      "Train loss at epoch (1287):  0.0639717\n",
      "Test loss at epoch (1287):  0.035804275\n",
      "Train loss at epoch (1288):  0.06406791\n",
      "Test loss at epoch (1288):  0.035837606\n",
      "Train loss at epoch (1289):  0.06407636\n",
      "Test loss at epoch (1289):  0.035828024\n",
      "Train loss at epoch (1290):  0.06417113\n",
      "Test loss at epoch (1290):  0.035848804\n",
      "Train loss at epoch (1291):  0.06419977\n",
      "Test loss at epoch (1291):  0.03583484\n",
      "Train loss at epoch (1292):  0.064000264\n",
      "Test loss at epoch (1292):  0.035838507\n",
      "Train loss at epoch (1293):  0.06410506\n",
      "Test loss at epoch (1293):  0.03581316\n",
      "Train loss at epoch (1294):  0.06384032\n",
      "Test loss at epoch (1294):  0.035803065\n",
      "Train loss at epoch (1295):  0.06385683\n",
      "Test loss at epoch (1295):  0.035771534\n",
      "Train loss at epoch (1296):  0.06378439\n",
      "Test loss at epoch (1296):  0.035799965\n",
      "Train loss at epoch (1297):  0.06400269\n",
      "Test loss at epoch (1297):  0.03583185\n",
      "Train loss at epoch (1298):  0.06405147\n",
      "Test loss at epoch (1298):  0.035800733\n",
      "Train loss at epoch (1299):  0.06383604\n",
      "Test loss at epoch (1299):  0.03586088\n",
      "Train loss at epoch (1300):  0.06417186\n",
      "Test loss at epoch (1300):  0.03580542\n",
      "Train loss at epoch (1301):  0.06388727\n",
      "Test loss at epoch (1301):  0.03580283\n",
      "Train loss at epoch (1302):  0.06369945\n",
      "Test loss at epoch (1302):  0.035811145\n",
      "Train loss at epoch (1303):  0.06389378\n",
      "Test loss at epoch (1303):  0.035811763\n",
      "Train loss at epoch (1304):  0.06376048\n",
      "Test loss at epoch (1304):  0.035845708\n",
      "Train loss at epoch (1305):  0.06387731\n",
      "Test loss at epoch (1305):  0.035836563\n",
      "Train loss at epoch (1306):  0.06383815\n",
      "Test loss at epoch (1306):  0.035821382\n",
      "Train loss at epoch (1307):  0.064024776\n",
      "Test loss at epoch (1307):  0.0358163\n",
      "Train loss at epoch (1308):  0.06408507\n",
      "Test loss at epoch (1308):  0.035806548\n",
      "Train loss at epoch (1309):  0.06422594\n",
      "Test loss at epoch (1309):  0.03579073\n",
      "Train loss at epoch (1310):  0.063852295\n",
      "Test loss at epoch (1310):  0.035806786\n",
      "Train loss at epoch (1311):  0.06396337\n",
      "Test loss at epoch (1311):  0.035789408\n",
      "Train loss at epoch (1312):  0.06380644\n",
      "Test loss at epoch (1312):  0.035791837\n",
      "Train loss at epoch (1313):  0.063641004\n",
      "Test loss at epoch (1313):  0.035757158\n",
      "Train loss at epoch (1314):  0.06401925\n",
      "Test loss at epoch (1314):  0.035796233\n",
      "Train loss at epoch (1315):  0.063984044\n",
      "Test loss at epoch (1315):  0.035813514\n",
      "Train loss at epoch (1316):  0.06381153\n",
      "Test loss at epoch (1316):  0.035811428\n",
      "Train loss at epoch (1317):  0.06372109\n",
      "Test loss at epoch (1317):  0.035812348\n",
      "Train loss at epoch (1318):  0.06398316\n",
      "Test loss at epoch (1318):  0.035797566\n",
      "Train loss at epoch (1319):  0.063937366\n",
      "Test loss at epoch (1319):  0.035777513\n",
      "Train loss at epoch (1320):  0.06392293\n",
      "Test loss at epoch (1320):  0.035761356\n",
      "Train loss at epoch (1321):  0.064030305\n",
      "Test loss at epoch (1321):  0.035783965\n",
      "Train loss at epoch (1322):  0.06401649\n",
      "Test loss at epoch (1322):  0.035808593\n",
      "Train loss at epoch (1323):  0.0638068\n",
      "Test loss at epoch (1323):  0.03578521\n",
      "Train loss at epoch (1324):  0.06386461\n",
      "Test loss at epoch (1324):  0.035754073\n",
      "Train loss at epoch (1325):  0.06402218\n",
      "Test loss at epoch (1325):  0.035783354\n",
      "Train loss at epoch (1326):  0.063892744\n",
      "Test loss at epoch (1326):  0.035788924\n",
      "Train loss at epoch (1327):  0.064365104\n",
      "Test loss at epoch (1327):  0.035783276\n",
      "Train loss at epoch (1328):  0.06358544\n",
      "Test loss at epoch (1328):  0.035782002\n",
      "Train loss at epoch (1329):  0.063505605\n",
      "Test loss at epoch (1329):  0.035785682\n",
      "Train loss at epoch (1330):  0.06403898\n",
      "Test loss at epoch (1330):  0.035763297\n",
      "Train loss at epoch (1331):  0.063974336\n",
      "Test loss at epoch (1331):  0.035775464\n",
      "Train loss at epoch (1332):  0.06430468\n",
      "Test loss at epoch (1332):  0.0357952\n",
      "Train loss at epoch (1333):  0.06377858\n",
      "Test loss at epoch (1333):  0.03579171\n",
      "Train loss at epoch (1334):  0.063771956\n",
      "Test loss at epoch (1334):  0.035778955\n",
      "Train loss at epoch (1335):  0.063947916\n",
      "Test loss at epoch (1335):  0.03576194\n",
      "Train loss at epoch (1336):  0.06429889\n",
      "Test loss at epoch (1336):  0.035779003\n",
      "Train loss at epoch (1337):  0.06370222\n",
      "Test loss at epoch (1337):  0.035763174\n",
      "Train loss at epoch (1338):  0.06394999\n",
      "Test loss at epoch (1338):  0.035733894\n",
      "Train loss at epoch (1339):  0.06399725\n",
      "Test loss at epoch (1339):  0.0357924\n",
      "Train loss at epoch (1340):  0.064019054\n",
      "Test loss at epoch (1340):  0.03578452\n",
      "Train loss at epoch (1341):  0.06426709\n",
      "Test loss at epoch (1341):  0.035771057\n",
      "Train loss at epoch (1342):  0.0640214\n",
      "Test loss at epoch (1342):  0.0357662\n",
      "Train loss at epoch (1343):  0.06414856\n",
      "Test loss at epoch (1343):  0.035764117\n",
      "Train loss at epoch (1344):  0.06409741\n",
      "Test loss at epoch (1344):  0.035778318\n",
      "Train loss at epoch (1345):  0.06359245\n",
      "Test loss at epoch (1345):  0.035757713\n",
      "Train loss at epoch (1346):  0.06368658\n",
      "Test loss at epoch (1346):  0.03577597\n",
      "Train loss at epoch (1347):  0.06397682\n",
      "Test loss at epoch (1347):  0.03575075\n",
      "Train loss at epoch (1348):  0.06416623\n",
      "Test loss at epoch (1348):  0.035750993\n",
      "Train loss at epoch (1349):  0.06424653\n",
      "Test loss at epoch (1349):  0.035777636\n",
      "Train loss at epoch (1350):  0.064167395\n",
      "Test loss at epoch (1350):  0.035766553\n",
      "Train loss at epoch (1351):  0.06369482\n",
      "Test loss at epoch (1351):  0.035756975\n",
      "Train loss at epoch (1352):  0.06374892\n",
      "Test loss at epoch (1352):  0.035782382\n",
      "Train loss at epoch (1353):  0.064248994\n",
      "Test loss at epoch (1353):  0.035760336\n",
      "Train loss at epoch (1354):  0.06377101\n",
      "Test loss at epoch (1354):  0.03576684\n",
      "Train loss at epoch (1355):  0.06408425\n",
      "Test loss at epoch (1355):  0.03574561\n",
      "Train loss at epoch (1356):  0.06398566\n",
      "Test loss at epoch (1356):  0.035811853\n",
      "Train loss at epoch (1357):  0.064242445\n",
      "Test loss at epoch (1357):  0.03576217\n",
      "Train loss at epoch (1358):  0.06387125\n",
      "Test loss at epoch (1358):  0.035776626\n",
      "Train loss at epoch (1359):  0.06385805\n",
      "Test loss at epoch (1359):  0.035781395\n",
      "Train loss at epoch (1360):  0.06362033\n",
      "Test loss at epoch (1360):  0.03577851\n",
      "Train loss at epoch (1361):  0.064033754\n",
      "Test loss at epoch (1361):  0.035771456\n",
      "Train loss at epoch (1362):  0.06406004\n",
      "Test loss at epoch (1362):  0.03573514\n",
      "Train loss at epoch (1363):  0.06430641\n",
      "Test loss at epoch (1363):  0.035788022\n",
      "Train loss at epoch (1364):  0.06376647\n",
      "Test loss at epoch (1364):  0.035758123\n",
      "Train loss at epoch (1365):  0.06423502\n",
      "Test loss at epoch (1365):  0.03575926\n",
      "Train loss at epoch (1366):  0.06398781\n",
      "Test loss at epoch (1366):  0.03577446\n",
      "Train loss at epoch (1367):  0.06383003\n",
      "Test loss at epoch (1367):  0.035784025\n",
      "Train loss at epoch (1368):  0.063840136\n",
      "Test loss at epoch (1368):  0.035821408\n",
      "Train loss at epoch (1369):  0.06390157\n",
      "Test loss at epoch (1369):  0.03576383\n",
      "Train loss at epoch (1370):  0.06393487\n",
      "Test loss at epoch (1370):  0.03575269\n",
      "Train loss at epoch (1371):  0.063976176\n",
      "Test loss at epoch (1371):  0.035788428\n",
      "Train loss at epoch (1372):  0.06367234\n",
      "Test loss at epoch (1372):  0.03578102\n",
      "Train loss at epoch (1373):  0.063965864\n",
      "Test loss at epoch (1373):  0.035771284\n",
      "Train loss at epoch (1374):  0.06410923\n",
      "Test loss at epoch (1374):  0.03579936\n",
      "Train loss at epoch (1375):  0.06396433\n",
      "Test loss at epoch (1375):  0.035777546\n",
      "Train loss at epoch (1376):  0.06397671\n",
      "Test loss at epoch (1376):  0.035781693\n",
      "Train loss at epoch (1377):  0.06412394\n",
      "Test loss at epoch (1377):  0.03577638\n",
      "Train loss at epoch (1378):  0.063868605\n",
      "Test loss at epoch (1378):  0.035775285\n",
      "Train loss at epoch (1379):  0.064111255\n",
      "Test loss at epoch (1379):  0.035763197\n",
      "Train loss at epoch (1380):  0.06426752\n",
      "Test loss at epoch (1380):  0.03577991\n",
      "Train loss at epoch (1381):  0.06359382\n",
      "Test loss at epoch (1381):  0.035799567\n",
      "Train loss at epoch (1382):  0.063814506\n",
      "Test loss at epoch (1382):  0.03577166\n",
      "Train loss at epoch (1383):  0.06388644\n",
      "Test loss at epoch (1383):  0.035775892\n",
      "Train loss at epoch (1384):  0.06420287\n",
      "Test loss at epoch (1384):  0.03580745\n",
      "Train loss at epoch (1385):  0.06419319\n",
      "Test loss at epoch (1385):  0.035756793\n",
      "Train loss at epoch (1386):  0.06424563\n",
      "Test loss at epoch (1386):  0.035779383\n",
      "Train loss at epoch (1387):  0.06386603\n",
      "Test loss at epoch (1387):  0.03575126\n",
      "Train loss at epoch (1388):  0.0636907\n",
      "Test loss at epoch (1388):  0.035774793\n",
      "Train loss at epoch (1389):  0.063856095\n",
      "Test loss at epoch (1389):  0.03575401\n",
      "Train loss at epoch (1390):  0.063759886\n",
      "Test loss at epoch (1390):  0.03575658\n",
      "Train loss at epoch (1391):  0.06415518\n",
      "Test loss at epoch (1391):  0.03575504\n",
      "Train loss at epoch (1392):  0.063611224\n",
      "Test loss at epoch (1392):  0.03578494\n",
      "Train loss at epoch (1393):  0.06397998\n",
      "Test loss at epoch (1393):  0.03578493\n",
      "Train loss at epoch (1394):  0.06390688\n",
      "Test loss at epoch (1394):  0.035788525\n",
      "Train loss at epoch (1395):  0.064061806\n",
      "Test loss at epoch (1395):  0.035767525\n",
      "Train loss at epoch (1396):  0.063929655\n",
      "Test loss at epoch (1396):  0.035772145\n",
      "Train loss at epoch (1397):  0.06411715\n",
      "Test loss at epoch (1397):  0.035772085\n",
      "Train loss at epoch (1398):  0.06378251\n",
      "Test loss at epoch (1398):  0.03575585\n",
      "Train loss at epoch (1399):  0.06385387\n",
      "Test loss at epoch (1399):  0.03575408\n",
      "Train loss at epoch (1400):  0.064232215\n",
      "Test loss at epoch (1400):  0.035750765\n",
      "Train loss at epoch (1401):  0.063865475\n",
      "Test loss at epoch (1401):  0.03578661\n",
      "Train loss at epoch (1402):  0.06384132\n",
      "Test loss at epoch (1402):  0.035756815\n",
      "Train loss at epoch (1403):  0.064136885\n",
      "Test loss at epoch (1403):  0.03578785\n",
      "Train loss at epoch (1404):  0.06392212\n",
      "Test loss at epoch (1404):  0.035775583\n",
      "Train loss at epoch (1405):  0.063862205\n",
      "Test loss at epoch (1405):  0.03578303\n",
      "Train loss at epoch (1406):  0.06373261\n",
      "Test loss at epoch (1406):  0.035764612\n",
      "Train loss at epoch (1407):  0.06397011\n",
      "Test loss at epoch (1407):  0.03576849\n",
      "Train loss at epoch (1408):  0.0637396\n",
      "Test loss at epoch (1408):  0.035783246\n",
      "Train loss at epoch (1409):  0.06398119\n",
      "Test loss at epoch (1409):  0.03577541\n",
      "Train loss at epoch (1410):  0.06407611\n",
      "Test loss at epoch (1410):  0.035750963\n",
      "Train loss at epoch (1411):  0.06407178\n",
      "Test loss at epoch (1411):  0.035774894\n",
      "Train loss at epoch (1412):  0.063933715\n",
      "Test loss at epoch (1412):  0.03577976\n",
      "Train loss at epoch (1413):  0.06357589\n",
      "Test loss at epoch (1413):  0.035761796\n",
      "Train loss at epoch (1414):  0.06386593\n",
      "Test loss at epoch (1414):  0.03579308\n",
      "Train loss at epoch (1415):  0.06435938\n",
      "Test loss at epoch (1415):  0.03578273\n",
      "Train loss at epoch (1416):  0.063595414\n",
      "Test loss at epoch (1416):  0.035777073\n",
      "Train loss at epoch (1417):  0.06395878\n",
      "Test loss at epoch (1417):  0.035788447\n",
      "Train loss at epoch (1418):  0.06410853\n",
      "Test loss at epoch (1418):  0.035757214\n",
      "Train loss at epoch (1419):  0.063832715\n",
      "Test loss at epoch (1419):  0.03577205\n",
      "Train loss at epoch (1420):  0.06369798\n",
      "Test loss at epoch (1420):  0.035791464\n",
      "Train loss at epoch (1421):  0.064101554\n",
      "Test loss at epoch (1421):  0.03577178\n",
      "Train loss at epoch (1422):  0.06394095\n",
      "Test loss at epoch (1422):  0.03575867\n",
      "Train loss at epoch (1423):  0.063877515\n",
      "Test loss at epoch (1423):  0.035778683\n",
      "Train loss at epoch (1424):  0.0638376\n",
      "Test loss at epoch (1424):  0.03576792\n",
      "Train loss at epoch (1425):  0.06390803\n",
      "Test loss at epoch (1425):  0.035763998\n",
      "Train loss at epoch (1426):  0.063916035\n",
      "Test loss at epoch (1426):  0.03578434\n",
      "Train loss at epoch (1427):  0.063848324\n",
      "Test loss at epoch (1427):  0.035760295\n",
      "Train loss at epoch (1428):  0.0638595\n",
      "Test loss at epoch (1428):  0.035759598\n",
      "Train loss at epoch (1429):  0.06428337\n",
      "Test loss at epoch (1429):  0.035774685\n",
      "Train loss at epoch (1430):  0.063866384\n",
      "Test loss at epoch (1430):  0.03577758\n",
      "Train loss at epoch (1431):  0.06379936\n",
      "Test loss at epoch (1431):  0.035766847\n",
      "Train loss at epoch (1432):  0.06388433\n",
      "Test loss at epoch (1432):  0.035752106\n",
      "Train loss at epoch (1433):  0.063961394\n",
      "Test loss at epoch (1433):  0.035779305\n",
      "Train loss at epoch (1434):  0.064177774\n",
      "Test loss at epoch (1434):  0.03576201\n",
      "Train loss at epoch (1435):  0.063941255\n",
      "Test loss at epoch (1435):  0.035730876\n",
      "Train loss at epoch (1436):  0.06373577\n",
      "Test loss at epoch (1436):  0.03575035\n",
      "Train loss at epoch (1437):  0.0634201\n",
      "Test loss at epoch (1437):  0.03579973\n",
      "Train loss at epoch (1438):  0.06402467\n",
      "Test loss at epoch (1438):  0.035737783\n",
      "Train loss at epoch (1439):  0.06394094\n",
      "Test loss at epoch (1439):  0.035752762\n",
      "Train loss at epoch (1440):  0.06391949\n",
      "Test loss at epoch (1440):  0.035763763\n",
      "Train loss at epoch (1441):  0.064164974\n",
      "Test loss at epoch (1441):  0.03576814\n",
      "Train loss at epoch (1442):  0.06398998\n",
      "Test loss at epoch (1442):  0.035773147\n",
      "Train loss at epoch (1443):  0.06377394\n",
      "Test loss at epoch (1443):  0.03575095\n",
      "Train loss at epoch (1444):  0.063592725\n",
      "Test loss at epoch (1444):  0.035773095\n",
      "Train loss at epoch (1445):  0.06378576\n",
      "Test loss at epoch (1445):  0.035779133\n",
      "Train loss at epoch (1446):  0.06399971\n",
      "Test loss at epoch (1446):  0.03575089\n",
      "Train loss at epoch (1447):  0.06376063\n",
      "Test loss at epoch (1447):  0.03578505\n",
      "Train loss at epoch (1448):  0.06407435\n",
      "Test loss at epoch (1448):  0.03577101\n",
      "Train loss at epoch (1449):  0.0638201\n",
      "Test loss at epoch (1449):  0.035741355\n",
      "Train loss at epoch (1450):  0.0639173\n",
      "Test loss at epoch (1450):  0.035748094\n",
      "Train loss at epoch (1451):  0.063688785\n",
      "Test loss at epoch (1451):  0.035757955\n",
      "Train loss at epoch (1452):  0.063901424\n",
      "Test loss at epoch (1452):  0.035752404\n",
      "Train loss at epoch (1453):  0.06411234\n",
      "Test loss at epoch (1453):  0.035760183\n",
      "Train loss at epoch (1454):  0.0638353\n",
      "Test loss at epoch (1454):  0.03577585\n",
      "Train loss at epoch (1455):  0.06404852\n",
      "Test loss at epoch (1455):  0.035739183\n",
      "Train loss at epoch (1456):  0.06386336\n",
      "Test loss at epoch (1456):  0.035787653\n",
      "Train loss at epoch (1457):  0.06387839\n",
      "Test loss at epoch (1457):  0.03576637\n",
      "Train loss at epoch (1458):  0.063763626\n",
      "Test loss at epoch (1458):  0.035740327\n",
      "Train loss at epoch (1459):  0.063678354\n",
      "Test loss at epoch (1459):  0.035768587\n",
      "Train loss at epoch (1460):  0.06333384\n",
      "Test loss at epoch (1460):  0.03573572\n",
      "Train loss at epoch (1461):  0.06396931\n",
      "Test loss at epoch (1461):  0.03576312\n",
      "Train loss at epoch (1462):  0.064028494\n",
      "Test loss at epoch (1462):  0.03576991\n",
      "Train loss at epoch (1463):  0.064101204\n",
      "Test loss at epoch (1463):  0.03578605\n",
      "Train loss at epoch (1464):  0.06383036\n",
      "Test loss at epoch (1464):  0.035768952\n",
      "Train loss at epoch (1465):  0.06383321\n",
      "Test loss at epoch (1465):  0.03576322\n",
      "Train loss at epoch (1466):  0.06385257\n",
      "Test loss at epoch (1466):  0.03573908\n",
      "Train loss at epoch (1467):  0.06365802\n",
      "Test loss at epoch (1467):  0.03573782\n",
      "Train loss at epoch (1468):  0.06425131\n",
      "Test loss at epoch (1468):  0.035740882\n",
      "Train loss at epoch (1469):  0.06409829\n",
      "Test loss at epoch (1469):  0.035759766\n",
      "Train loss at epoch (1470):  0.063681394\n",
      "Test loss at epoch (1470):  0.035777763\n",
      "Train loss at epoch (1471):  0.063578606\n",
      "Test loss at epoch (1471):  0.03577215\n",
      "Train loss at epoch (1472):  0.06430112\n",
      "Test loss at epoch (1472):  0.035770316\n",
      "Train loss at epoch (1473):  0.063677855\n",
      "Test loss at epoch (1473):  0.035746668\n",
      "Train loss at epoch (1474):  0.06365795\n",
      "Test loss at epoch (1474):  0.03577186\n",
      "Train loss at epoch (1475):  0.06417901\n",
      "Test loss at epoch (1475):  0.0357677\n",
      "Train loss at epoch (1476):  0.06393721\n",
      "Test loss at epoch (1476):  0.035769552\n",
      "Train loss at epoch (1477):  0.06380776\n",
      "Test loss at epoch (1477):  0.03577445\n",
      "Train loss at epoch (1478):  0.06383882\n",
      "Test loss at epoch (1478):  0.03578602\n",
      "Train loss at epoch (1479):  0.06404834\n",
      "Test loss at epoch (1479):  0.035745203\n",
      "Train loss at epoch (1480):  0.0637891\n",
      "Test loss at epoch (1480):  0.03575964\n",
      "Train loss at epoch (1481):  0.06382006\n",
      "Test loss at epoch (1481):  0.03577149\n",
      "Train loss at epoch (1482):  0.06379462\n",
      "Test loss at epoch (1482):  0.0357541\n",
      "Train loss at epoch (1483):  0.06369424\n",
      "Test loss at epoch (1483):  0.035731424\n",
      "Train loss at epoch (1484):  0.063535854\n",
      "Test loss at epoch (1484):  0.035759877\n",
      "Train loss at epoch (1485):  0.06367248\n",
      "Test loss at epoch (1485):  0.03577866\n",
      "Train loss at epoch (1486):  0.063927926\n",
      "Test loss at epoch (1486):  0.03575572\n",
      "Train loss at epoch (1487):  0.06386077\n",
      "Test loss at epoch (1487):  0.03576979\n",
      "Train loss at epoch (1488):  0.06382442\n",
      "Test loss at epoch (1488):  0.035754308\n",
      "Train loss at epoch (1489):  0.064083084\n",
      "Test loss at epoch (1489):  0.035767376\n",
      "Train loss at epoch (1490):  0.06379507\n",
      "Test loss at epoch (1490):  0.03578355\n",
      "Train loss at epoch (1491):  0.06416107\n",
      "Test loss at epoch (1491):  0.035773624\n",
      "Train loss at epoch (1492):  0.06412438\n",
      "Test loss at epoch (1492):  0.035744276\n",
      "Train loss at epoch (1493):  0.06376633\n",
      "Test loss at epoch (1493):  0.03577758\n",
      "Train loss at epoch (1494):  0.063731894\n",
      "Test loss at epoch (1494):  0.035757404\n",
      "Train loss at epoch (1495):  0.063716725\n",
      "Test loss at epoch (1495):  0.035757612\n",
      "Train loss at epoch (1496):  0.06363715\n",
      "Test loss at epoch (1496):  0.03574344\n",
      "Train loss at epoch (1497):  0.06403554\n",
      "Test loss at epoch (1497):  0.0357575\n",
      "Train loss at epoch (1498):  0.06391033\n",
      "Test loss at epoch (1498):  0.03577123\n",
      "Train loss at epoch (1499):  0.06396235\n",
      "Test loss at epoch (1499):  0.03574749\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "EPOCHS = 1500\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=16, shuffle=True)\n",
    "cached_decoder = CachedTransformerDecoder(cfg)\n",
    "optimizer = SGD(cached_decoder.parameters(), lr=1e-4, momentum=0.9)\n",
    "lr_scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "trainer = Trainer(\n",
    "    train_data_loader=train_data_loader,\n",
    "    test_data_loader=test_data_loader,\n",
    "    # optimizer=AdamW(decoder.parameters(), lr=1e-5),\n",
    "    optimizer=optimizer,\n",
    "    model=cached_decoder,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    epochs=EPOCHS\n",
    ")\n",
    "\n",
    "trainer.train(loss_fn=nn.L1Loss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, n_tokens, inputs):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_len = inputs.size(-2)\n",
    "        for i in range(n_tokens):\n",
    "            inputs = torch.cat((inputs, model.predict(inputs)), dim=-2)\n",
    "        return inputs[:, input_len:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_sample, y_sample = test_dataset[np.random.randint(0, TEST_SIZE)]\n",
    "predictions = cached_decoder.predict(x_sample.unsqueeze(0)[:, :SOURCE_SEQ_LEN, :], TARGET_SEQ_LEN)\n",
    "labels = torch.cat((x_sample, y_sample[-1:]))\n",
    "\n",
    "plot_circle(\n",
    "    input=labels.detach().numpy()[0:],\n",
    "    prediction=torch.cat((labels[0:SOURCE_SEQ_LEN, :], predictions[0])).detach().numpy()[0:],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'decoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m x_sample, y_sample \u001b[38;5;241m=\u001b[39m test_dataset[np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, TEST_SIZE)]\n\u001b[0;32m----> 2\u001b[0m predictions \u001b[38;5;241m=\u001b[39m predict(\u001b[43mdecoder\u001b[49m, TARGET_SEQ_LEN, x_sample\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)[:, :SOURCE_SEQ_LEN, :])\n\u001b[1;32m      3\u001b[0m labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((x_sample, y_sample[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:]))\n\u001b[1;32m      5\u001b[0m plot_circle(\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mlabels\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m:],\n\u001b[1;32m      7\u001b[0m     prediction\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mcat((labels[\u001b[38;5;241m0\u001b[39m:SOURCE_SEQ_LEN, :], predictions[\u001b[38;5;241m0\u001b[39m]))\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m:],\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'decoder' is not defined"
     ]
    }
   ],
   "source": [
    "x_sample, y_sample = test_dataset[np.random.randint(0, TEST_SIZE)]\n",
    "predictions = predict(decoder, TARGET_SEQ_LEN, x_sample.unsqueeze(0)[:, :SOURCE_SEQ_LEN, :])\n",
    "labels = torch.cat((x_sample, y_sample[-1:]))\n",
    "\n",
    "plot_circle(\n",
    "    input=labels.detach().numpy()[0:],\n",
    "    prediction=torch.cat((labels[0:SOURCE_SEQ_LEN, :], predictions[0])).detach().numpy()[0:],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cached:  0.0032138898537959902 0.001621722942688389\n",
      "Cacheless:  0.003723135533509776 0.0011225037988922212\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "cached_time = []\n",
    "with torch.no_grad():\n",
    "    for i in range(1000):\n",
    "        s = time.perf_counter()\n",
    "        x_sample, y_sample = test_dataset[np.random.randint(0, TEST_SIZE)]\n",
    "        predictions = cached_decoder.predict(x_sample.unsqueeze(0)[:, :SOURCE_SEQ_LEN, :], TARGET_SEQ_LEN)\n",
    "        cached_time.append(time.perf_counter() - s)\n",
    "\n",
    "cacheless_time = []\n",
    "for i in range(1000):\n",
    "    s = time.perf_counter()\n",
    "    predictions = predict(decoder, TARGET_SEQ_LEN, x_sample.unsqueeze(0)[:, :SOURCE_SEQ_LEN, :])\n",
    "    labels = torch.cat((x_sample, y_sample[-1:]))\n",
    "    cacheless_time.append(time.perf_counter() - s)\n",
    "\n",
    "print(\"Cached: \", np.array(cached_time).mean(), np.array(cached_time).std())\n",
    "print(\"Cacheless: \", np.array(cacheless_time).mean(), np.array(cacheless_time).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
